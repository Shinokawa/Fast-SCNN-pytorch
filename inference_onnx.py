import onnxruntime as ort
import numpy as np
import cv2
import argparse
import os
import matplotlib.pyplot as plt

def main(args):
    """ä¸»å‡½æ•°ï¼Œç”¨äºåŠ è½½æ¨¡å‹ã€å›¾åƒå¹¶è¿›è¡Œæ¨ç†å’Œå¯è§†åŒ–"""
    # 1. æ£€æŸ¥è¾“å…¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(args.model):
        print(f"âŒ é”™è¯¯: ONNXæ¨¡å‹æ–‡ä»¶æœªæ‰¾åˆ°: {args.model}")
        return
    if not os.path.exists(args.image):
        print(f"âŒ é”™è¯¯: å›¾åƒæ–‡ä»¶æœªæ‰¾åˆ°: {args.image}")
        return

    print("ğŸš€ å¼€å§‹ONNXæ¨¡å‹æ¨ç†...")
    print(f"   - æ¨¡å‹: {args.model}")
    print(f"   - å›¾åƒ: {args.image}")

    # 2. åˆ›å»ºONNXæ¨ç†ä¼šè¯
    try:
        session = ort.InferenceSession(args.model, providers=['CUDAExecutionProvider', 'CPUExecutionProvider'])
        print(f"âœ… ONNXä¼šè¯åˆ›å»ºæˆåŠŸï¼Œä½¿ç”¨: {session.get_providers()[0]}")
    except Exception as e:
        print(f"âŒ åˆ›å»ºONNXä¼šè¯å¤±è´¥: {e}")
        return

    # 3. åŠ è½½å¹¶é¢„å¤„ç†å›¾åƒ
    # æ¨¡å‹è¾“å…¥å°ºå¯¸ä¸º 360x640
    input_shape = session.get_inputs()[0].shape # (1, 3, 360, 640)
    input_height, input_width = input_shape[2], input_shape[3]

    original_image = cv2.imread(args.image)
    original_image_rgb = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)
    
    # å‡†å¤‡è¾“å…¥å¼ é‡
    # æ³¨æ„ï¼šæ¨¡å‹æ˜¯ç«¯åˆ°ç«¯çš„ï¼Œå®ƒè‡ªå·±å¤„ç†resizeå’Œå½’ä¸€åŒ–ï¼Œæˆ‘ä»¬åªéœ€è¦é€å…¥åŸå§‹çš„uint8å›¾åƒæ•°æ®
    # ä½†ONNX Runtimeéœ€è¦float32è¾“å…¥ï¼Œæ‰€ä»¥æˆ‘ä»¬è¿›è¡Œç±»å‹è½¬æ¢
    input_tensor = cv2.resize(original_image, (input_width, input_height))
    input_tensor = cv2.cvtColor(input_tensor, cv2.COLOR_BGR2RGB)
    input_tensor = np.transpose(input_tensor, (2, 0, 1))  # HWC -> CHW
    input_tensor = np.expand_dims(input_tensor, axis=0).astype(np.float32) # Add batch dim and convert to float32

    print(f"âœ… å›¾åƒåŠ è½½å¹¶é¢„å¤„ç†å®Œæˆï¼Œè¾“å…¥å°ºå¯¸: {input_tensor.shape}")

    # 4. æ‰§è¡Œæ¨ç†
    input_name = session.get_inputs()[0].name
    output_name = session.get_outputs()[0].name
    
    print("ğŸ§  æ­£åœ¨æ‰§è¡Œæ¨ç†...")
    result = session.run([output_name], {input_name: input_tensor})[0]
    print("âœ… æ¨ç†å®Œæˆ!")
    print(f"   - è¾“å‡ºå°ºå¯¸: {result.shape}") # (1, 2, 360, 640)

    # 5. åå¤„ç†ï¼šè·å–åˆ†å‰²æ©ç 
    # resultæ˜¯softmaxçš„è¾“å‡ºæ¦‚ç‡ï¼Œæˆ‘ä»¬éœ€è¦æ‰¾åˆ°å“ªä¸ªç±»åˆ«æ¦‚ç‡æœ€å¤§
    predicted_mask = np.argmax(result, axis=1)[0] # (360, 640)
    
    # åˆ›å»ºä¸€ä¸ªå½©è‰²çš„å åŠ å±‚
    # å‡è®¾ç±»åˆ«1æ˜¯å¯è¡Œé©¶åŒºåŸŸï¼Œæˆ‘ä»¬å°†å…¶è®¾ä¸ºç»¿è‰²
    overlay = np.zeros((input_height, input_width, 3), dtype=np.uint8)
    overlay[predicted_mask == 1] = [0, 255, 0] # BGR for OpenCV

    # 6. å¯è§†åŒ–ç»“æœ
    print("ğŸ¨ æ­£åœ¨ç”Ÿæˆå¯è§†åŒ–ç»“æœ...")
    
    # å°†åŸå§‹å›¾åƒï¼ˆå·²ç¼©æ”¾ï¼‰å’Œå åŠ å±‚æ··åˆ
    # æˆ‘ä»¬éœ€è¦ä¸€ä¸ªä¸å åŠ å±‚ç›¸åŒå°ºå¯¸çš„åŸå§‹å›¾åƒ
    resized_original_image = cv2.resize(original_image_rgb, (input_width, input_height))
    
    # å°†RGBè½¬å›BGRä»¥ä¾›cv2ä½¿ç”¨
    resized_original_image_bgr = cv2.cvtColor(resized_original_image, cv2.COLOR_RGB2BGR)
    
    # æ··åˆå›¾åƒ
    blended_image = cv2.addWeighted(resized_original_image_bgr, 1, overlay, 0.5, 0)

    # åˆ›å»ºä¸€ä¸ªå¤§çš„ç”»å¸ƒæ¥å¹¶æ’æ˜¾ç¤º
    fig, axes = plt.subplots(1, 3, figsize=(18, 6))
    
    # åŸå§‹å›¾åƒ
    axes[0].imshow(resized_original_image)
    axes[0].set_title('Original Image (Resized)')
    axes[0].axis('off')

    # é¢„æµ‹çš„æ©ç 
    axes[1].imshow(predicted_mask, cmap='gray')
    axes[1].set_title('Predicted Mask (Class 1 is white)')
    axes[1].axis('off')

    # å åŠ æ•ˆæœ
    axes[2].imshow(cv2.cvtColor(blended_image, cv2.COLOR_BGR2RGB))
    axes[2].set_title('Prediction Overlay')
    axes[2].axis('off')
    
    plt.tight_layout()
    
    # ä¿å­˜ç»“æœ
    output_filename = os.path.join(os.path.dirname(args.model), "inference_result.png")
    plt.savefig(output_filename, dpi=150)
    print(f"âœ… ç»“æœå·²ä¿å­˜åˆ°: {output_filename}")
    plt.show()


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Run ONNX inference for Fast-SCNN and visualize results.")
    parser.add_argument('--model', type=str, 
                        default='./weights/fast_scnn_custom_e2e_360x640_simplified.onnx',
                        help='Path to the simplified ONNX model.')
    parser.add_argument('--image', type=str, 
                        default='./data/custom/images/0a0a0a0a-64a53900.jpg',
                        help='Path to the input image.')
    
    # è‡ªåŠ¨æŸ¥æ‰¾ä¸€ä¸ªæµ‹è¯•å›¾ç‰‡
    if not os.path.exists(parser.parse_args().image):
        print(f"è­¦å‘Š: é»˜è®¤å›¾ç‰‡ '{parser.parse_args().image}' ä¸å­˜åœ¨ã€‚")
        image_dir = './data/custom/images'
        if os.path.exists(image_dir) and len(os.listdir(image_dir)) > 0:
            found_image = [f for f in os.listdir(image_dir) if f.endswith(('.jpg', '.png'))][0]
            parser.set_defaults(image=os.path.join(image_dir, found_image))
            print(f"å°†ä½¿ç”¨æ‰¾åˆ°çš„ç¬¬ä¸€å¼ å›¾ç‰‡è¿›è¡Œæµ‹è¯•: {parser.parse_args().image}")
        else:
            print("é”™è¯¯: åœ¨ './data/custom/images' ç›®å½•ä¸‹æ‰¾ä¸åˆ°ä»»ä½•å›¾ç‰‡æ–‡ä»¶ã€‚è¯·æ‰‹åŠ¨æŒ‡å®š --image å‚æ•°ã€‚")
            exit()

    args = parser.parse_args()
    main(args)
