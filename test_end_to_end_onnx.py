"""
TUSimple Lane Segmentation - End-to-End ONNX Model Inference Test
ä½¿ç”¨ç«¯åˆ°ç«¯ONNXæ¨¡å‹è¿›è¡Œæ¨ç†æµ‹è¯•ï¼Œæ¨¡æ‹ŸAtlaså¼€å‘æ¿ä¸Šçš„å®é™…éƒ¨ç½²åœºæ™¯ã€‚
ç‰¹ç‚¹ï¼š
1. ç›´æ¥è¾“å…¥åŸå§‹å›¾åƒæ•°æ®ï¼ˆ0-255åƒç´ å€¼ï¼‰
2. æ— éœ€CPUé¢„å¤„ç†ï¼Œå……åˆ†åˆ©ç”¨NPUæ€§èƒ½
3. æ¨¡æ‹Ÿæ™ºèƒ½å°è½¦æ‘„åƒå¤´å®æ—¶æ¨ç†åœºæ™¯
"""
import os
os.environ['KMP_DUPLICATE_LIB_OK']='TRUE'
import random
import time
import numpy as np
import onnxruntime as ort
import torch
from PIL import Image
import matplotlib.pyplot as plt
import cv2

plt.rcParams['font.sans-serif'] = ['SimHei'] # è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['axes.unicode_minus'] = False # è§£å†³è´Ÿå·æ˜¾ç¤ºé—®é¢˜

class EndToEndONNXTester:
    """ç«¯åˆ°ç«¯ONNXæ¨¡å‹æ¨ç†æµ‹è¯•å™¨ - ä¸“ä¸ºAtlaså¼€å‘æ¿ä¼˜åŒ–"""
    
    def __init__(self, onnx_model_path):
        self.onnx_model_path = onnx_model_path
        self.device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
        
        # æ£€æŸ¥CUDAå¹¶è®¾ç½®ONNX Runtimeçš„æ‰§è¡Œæä¾›è€…
        if self.device.type == 'cuda' and ort.get_device() == 'GPU':
            self.providers = ['CUDAExecutionProvider', 'CPUExecutionProvider']
            print("ğŸš€ ONNX Runtime å°†ä½¿ç”¨ CUDAExecutionProvider (æ¨¡æ‹ŸNPUåŠ é€Ÿ)")
        else:
            self.providers = ['CPUExecutionProvider']
            print("âš ï¸  ONNX Runtime å°†ä½¿ç”¨ CPUExecutionProvider")

        # åŠ è½½ç«¯åˆ°ç«¯ONNXæ¨¡å‹
        print(f"ğŸ“¦ æ­£åœ¨ä» {self.onnx_model_path} åŠ è½½ç«¯åˆ°ç«¯ONNXæ¨¡å‹...")
        self.ort_session = ort.InferenceSession(self.onnx_model_path, providers=self.providers)
        self.input_name = self.ort_session.get_inputs()[0].name
        input_shape = self.ort_session.get_inputs()[0].shape
        self.input_height = input_shape[2]
        self.input_width = input_shape[3]
        print(f"âœ… ç«¯åˆ°ç«¯æ¨¡å‹åŠ è½½å®Œæ¯•")
        print(f"   ğŸ“Š è¾“å…¥åç§°: \'{self.input_name}\'")
        print(f"   ğŸ“Š è¾“å…¥å½¢çŠ¶ (N, C, H, W): {input_shape}")
        print(f"   âœ¨ é¢„æœŸè¾“å…¥: åŸå§‹å›¾åƒæ•°æ® [0-255] (HWCæ ¼å¼)")
        print(f"   ğŸ¯ å†…ç½®åŠŸèƒ½: è‡ªåŠ¨resizeè‡³ ({self.input_height}, {self.input_width}) + å½’ä¸€åŒ– + æ¨ç†")

        # æ•°æ®è·¯å¾„
        self.root = './manideep1108/tusimple/versions/5/TUSimple'
        self.test_clips_root = os.path.join(self.root, 'test_set', 'clips')
        self.seg_label_root = os.path.join(self.root, 'train_set', 'seg_label')

    def find_test_images(self, num_images=5):
        """ä»æµ‹è¯•é›†ä¸­æŸ¥æ‰¾éšæœºå›¾åƒ"""
        image_paths = []
        mask_paths = []
        
        if not os.path.exists(self.test_clips_root):
            print(f"âŒ é”™è¯¯: æµ‹è¯•é›†å›¾åƒç›®å½•æœªæ‰¾åˆ° {self.test_clips_root}")
            return [], []

        # æ”¶é›†æ‰€æœ‰æœ‰æ•ˆçš„å›¾åƒ/maskå¯¹
        for date_folder in os.listdir(self.test_clips_root):
            date_path = os.path.join(self.test_clips_root, date_folder)
            if os.path.isdir(date_path):
                for video_folder in os.listdir(date_path):
                    video_path = os.path.join(date_path, video_folder)
                    if os.path.isdir(video_path):
                        for i in range(1, 21): # æ£€æŸ¥ 1.jpg åˆ° 20.jpg
                            img_file = os.path.join(video_path, f'{i}.jpg')
                            if os.path.exists(img_file):
                                mask_file = os.path.join(self.seg_label_root, date_folder, video_folder, f'{i}.png')
                                if os.path.exists(mask_file):
                                    image_paths.append(img_file)
                                    mask_paths.append(mask_file)
        
        print(f"ğŸ“· åœ¨æµ‹è¯•é›†ä¸­å…±æ‰¾åˆ° {len(image_paths)} å¼ å›¾åƒ")
        
        # éšæœºé€‰æ‹© num_images å¼ 
        if len(image_paths) >= num_images:
            selected_pairs = random.sample(list(zip(image_paths, mask_paths)), num_images)
            image_paths, mask_paths = zip(*selected_pairs)
            return list(image_paths), list(mask_paths)
        else:
            print(f"âš ï¸  è­¦å‘Š: å›¾åƒæ•°é‡ä¸è¶³ã€‚æ‰¾åˆ° {len(image_paths)} å¼ , éœ€è¦ {num_images} å¼ ")
            return image_paths, mask_paths

    def load_raw_image(self, image_path):
        """åŠ è½½åŸå§‹å›¾åƒæ•°æ® - æ¨¡æ‹Ÿæ‘„åƒå¤´è¾“å…¥"""
        # ä½¿ç”¨OpenCVåŠ è½½ï¼Œä¿æŒåŸå§‹åƒç´ å€¼ [0-255]
        image_bgr = cv2.imread(image_path)
        image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)
        
        # PCä¸Šç®€å•resizeåˆ°æ¨¡å‹æœŸæœ›çš„è¾“å…¥å°ºå¯¸
        original_size = image_rgb.shape[:2] # (H, W)
        # æ³¨æ„ï¼šcv2.resizeçš„dsizeå‚æ•°æ˜¯(width, height)
        image_rgb_resized = cv2.resize(image_rgb, (self.input_width, self.input_height), interpolation=cv2.INTER_LINEAR)
        
        # è½¬æ¢ä¸ºæ¨¡å‹æœŸæœ›çš„CHWæ ¼å¼ (3, H, W) å¹¶ä¿æŒåŸå§‹æ•°æ®ç±»å‹
        image_chw = image_rgb_resized.transpose(2, 0, 1)  # HWC -> CHW
        image_batch = image_chw[np.newaxis, ...]  # æ·»åŠ batchç»´åº¦ -> (1, 3, H, W)
        
        # ç¡®ä¿æ•°æ®ç±»å‹ä¸ºfloat32ï¼ˆONNXæ¨ç†éœ€è¦ï¼‰
        image_input = image_batch.astype(np.float32)
        
        print(f"   ğŸ“· åŸå§‹å›¾åƒå°ºå¯¸: {original_size} -> 640x480 (åŒ¹é…å¼€å‘æ¿)")
        print(f"   ğŸ“Š æ¨¡å‹è¾“å…¥å°ºå¯¸: {image_input.shape} (NCHW)")
        print(f"   ğŸ¯ åƒç´ å€¼èŒƒå›´: [{image_input.min():.0f}, {image_input.max():.0f}]")
        
        return image_input, image_rgb

    def load_mask(self, mask_path):
        """åŠ è½½å¹¶äºŒå€¼åŒ–mask"""
        mask = Image.open(mask_path).convert('L')
        mask_array = np.array(mask)
        mask_binary = (mask_array > 0).astype(np.uint8)
        return mask_binary

    def predict_end_to_end(self, image_input):
        """ä½¿ç”¨ç«¯åˆ°ç«¯ONNXæ¨¡å‹è¿›è¡Œæ¨ç† - æ¨¡æ‹ŸAtlas NPUæ¨ç†"""
        print(f"   ğŸš€ å¼€å§‹ç«¯åˆ°ç«¯æ¨ç†...")
        print(f"   âœ¨ å†…ç½®æ“ä½œ: resize -> å½’ä¸€åŒ– -> åˆ†å‰²æ¨ç† -> softmax")
        
        start_time = time.time()
        ort_inputs = {self.input_name: image_input}
        ort_outs = self.ort_session.run(None, ort_inputs)
        inference_time = time.time() - start_time
        
        # ç«¯åˆ°ç«¯æ¨¡å‹è¾“å‡ºå·²ç»æ˜¯æ¦‚ç‡åˆ†å¸ƒï¼ˆç»è¿‡softmaxï¼‰
        pred_probs = ort_outs[0]  # Shape: (1, num_classes, H, W)
        pred_mask = np.argmax(pred_probs, axis=1).squeeze().astype(np.uint8)
        
        print(f"   âš¡ æ¨ç†å®Œæˆ: {inference_time*1000:.2f}ms")
        print(f"   ğŸ“Š è¾“å‡ºæ¦‚ç‡å½¢çŠ¶: {pred_probs.shape}")
        print(f"   ğŸ“Š é¢„æµ‹maskå½¢çŠ¶: {pred_mask.shape}")
        print(f"   ğŸ¯ é¢„æµ‹ç±»åˆ«æ•°: {pred_probs.shape[1]}")
        
        # è®¡ç®—ç½®ä¿¡åº¦
        max_probs = np.max(pred_probs, axis=1).squeeze()
        avg_confidence = np.mean(max_probs)
        print(f"   ğŸ“ˆ å¹³å‡ç½®ä¿¡åº¦: {avg_confidence:.3f}")
        
        return pred_mask, inference_time, avg_confidence

    def create_comparison_plot(self, original_img, gt_mask, pred_mask, save_path, inference_time, confidence):
        """åˆ›å»ºå¯¹æ¯”å›¾ - çªå‡ºç«¯åˆ°ç«¯ä¼˜åŠ¿"""
        fig, axes = plt.subplots(1, 3, figsize=(18, 6))
        fig.suptitle(f'ç«¯åˆ°ç«¯ONNXæ¨¡å‹æ¨ç† (Atlas NPUä¼˜åŒ–)\n' +
                    f'æ¨ç†æ—¶é—´: {inference_time*1000:.2f}ms | ç½®ä¿¡åº¦: {confidence:.3f} | ' +
                    f'ç†è®ºFPS: {1/inference_time:.1f}', fontsize=16)
        
        axes[0].imshow(original_img)
        axes[0].set_title('åŸå§‹æ‘„åƒå¤´è¾“å…¥\n(æ— é¢„å¤„ç†)')
        axes[0].axis('off')
        
        axes[1].imshow(gt_mask, cmap='gray')
        axes[1].set_title('çœŸå®è½¦é“çº¿')
        axes[1].axis('off')
        
        # ä¸ºé¢„æµ‹ç»“æœæ·»åŠ é¢œè‰²æ˜ å°„ï¼Œæ›´å¥½åœ°æ˜¾ç¤ºè½¦é“çº¿
        pred_colored = np.zeros((*pred_mask.shape, 3), dtype=np.uint8)
        pred_colored[pred_mask == 1] = [255, 0, 0]    # è½¦é“çº¿1 - çº¢è‰²
        pred_colored[pred_mask == 2] = [0, 255, 0]    # è½¦é“çº¿2 - ç»¿è‰²  
        pred_colored[pred_mask == 3] = [0, 0, 255]    # è½¦é“çº¿3 - è“è‰²
        pred_colored[pred_mask == 4] = [255, 255, 0]  # è½¦é“çº¿4 - é»„è‰²
        
        axes[2].imshow(pred_colored)
        axes[2].set_title('ç«¯åˆ°ç«¯é¢„æµ‹ç»“æœ\n(NPUåŠ é€Ÿ)')
        axes[2].axis('off')
        
        plt.tight_layout(rect=[0, 0.03, 1, 0.95])
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        plt.close()
        print(f"   ğŸ’¾ å¯¹æ¯”å›¾å·²ä¿å­˜: {save_path}")

    def run_performance_benchmark(self, image_input, runs=20):
        """è¿è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯• - æ¨¡æ‹ŸAtlaså¼€å‘æ¿æ€§èƒ½"""
        print(f"\nğŸ å¼€å§‹æ€§èƒ½åŸºå‡†æµ‹è¯• (æ¨¡æ‹ŸAtlas NPU)...")
        print(f"   ğŸ”„ é¢„çƒ­è¿è¡Œ: 5æ¬¡")
        print(f"   ğŸ“Š æµ‹è¯•è¿è¡Œ: {runs}æ¬¡")
        
        # é¢„çƒ­
        for _ in range(5):
            _ = self.ort_session.run(None, {self.input_name: image_input})
        
        # æ€§èƒ½æµ‹è¯•
        times = []
        for i in range(runs):
            start_time = time.time()
            _ = self.ort_session.run(None, {self.input_name: image_input})
            end_time = time.time()
            times.append(end_time - start_time)
            
            if (i + 1) % 5 == 0:
                print(f"   âš¡ å·²å®Œæˆ {i+1}/{runs} æ¬¡æµ‹è¯•...")
        
        # ç»Ÿè®¡åˆ†æ
        times = np.array(times)
        avg_time = np.mean(times)
        min_time = np.min(times)
        max_time = np.max(times)
        std_time = np.std(times)
        
        print(f"\nğŸ“ˆ æ€§èƒ½åŸºå‡†æµ‹è¯•ç»“æœ:")
        print(f"   âš¡ å¹³å‡æ¨ç†æ—¶é—´: {avg_time*1000:.2f}ms")
        print(f"   ğŸš€ æœ€å¿«æ¨ç†æ—¶é—´: {min_time*1000:.2f}ms") 
        print(f"   ğŸŒ æœ€æ…¢æ¨ç†æ—¶é—´: {max_time*1000:.2f}ms")
        print(f"   ğŸ“Š æ ‡å‡†å·®: {std_time*1000:.2f}ms")
        print(f"   ğŸ¯ ç†è®ºå¹³å‡FPS: {1/avg_time:.1f}")
        print(f"   ğŸ† ç†è®ºæœ€å¤§FPS: {1/min_time:.1f}")
        
        # Atlas NPUæ€§èƒ½å¯¹æ¯”
        print(f"\nğŸš— æ™ºèƒ½å°è½¦æ€§èƒ½åˆ†æ:")
        if avg_time < 0.04:  # < 40ms
            print(f"   ğŸ‰ ä¼˜ç§€! å®Œå…¨æ»¡è¶³å®æ—¶è‡ªåŠ¨é©¾é©¶éœ€æ±‚ (>25 FPS)")
        elif avg_time < 0.067:  # < 67ms  
            print(f"   âœ… è‰¯å¥½! æ»¡è¶³åŸºæœ¬è‡ªåŠ¨é©¾é©¶éœ€æ±‚ (15-25 FPS)")
        elif avg_time < 0.1:  # < 100ms
            print(f"   âš ï¸  ä¸€èˆ¬! å¯ç”¨ä½†ä¸å¤Ÿæµç•… (10-15 FPS)")
        else:
            print(f"   âŒ éœ€è¦ä¼˜åŒ–! FPSè¿‡ä½ï¼Œå½±å“å®‰å…¨æ€§ (<10 FPS)")
            
        return avg_time, min_time, max_time

    def run_test(self, num_images=5, benchmark=True):
        """è¿è¡Œå®Œæ•´çš„ç«¯åˆ°ç«¯æµ‹è¯•æµç¨‹"""
        print("\n" + "="*80)
        print("ğŸš€ ç«¯åˆ°ç«¯ONNXæ¨¡å‹æ¨ç†æµ‹è¯• - Atlas NPUä¼˜åŒ–ç‰ˆæœ¬")
        print("ğŸš— æ™ºèƒ½å°è½¦å®æ—¶è½¦é“çº¿æ£€æµ‹æ¨¡æ‹Ÿ")
        print("="*80)
        
        image_paths, mask_paths = self.find_test_images(num_images)
        
        if not image_paths:
            print("âŒ æœªæ‰¾åˆ°å¯ä¾›æµ‹è¯•çš„å›¾åƒï¼Œç¨‹åºé€€å‡º")
            return
            
        output_dir = './end_to_end_onnx_results'
        os.makedirs(output_dir, exist_ok=True)
        print(f"ğŸ“ ç»“æœå°†ä¿å­˜åˆ°: {output_dir}")
        
        inference_times = []
        confidences = []
        
        for i, (img_path, mask_path) in enumerate(zip(image_paths, mask_paths)):
            print(f"\n" + "-"*60)
            print(f"ğŸ–¼ï¸  æ­£åœ¨å¤„ç†å›¾åƒ {i+1}/{num_images}")
            print(f"ğŸ“‚ å›¾åƒè·¯å¾„: {os.path.basename(img_path)}")
            
            # åŠ è½½åŸå§‹å›¾åƒæ•°æ®ï¼ˆæ¨¡æ‹Ÿæ‘„åƒå¤´è¾“å…¥ï¼‰
            image_input, original_img = self.load_raw_image(img_path)
            gt_mask = self.load_mask(mask_path)
            
            # ç«¯åˆ°ç«¯æ¨ç†
            pred_mask, inference_time, confidence = self.predict_end_to_end(image_input)
            inference_times.append(inference_time)
            confidences.append(confidence)
            
            # è°ƒæ•´é¢„æµ‹ç»“æœå°ºå¯¸ï¼ˆå¦‚æœéœ€è¦ï¼‰
            if pred_mask.shape != gt_mask.shape:
                pred_mask = cv2.resize(pred_mask, (gt_mask.shape[1], gt_mask.shape[0]), 
                                     interpolation=cv2.INTER_NEAREST)

            # åˆ›å»ºå¯è§†åŒ–ç»“æœ
            save_path = os.path.join(output_dir, f'end_to_end_test_{i+1}.png')
            self.create_comparison_plot(original_img, gt_mask, pred_mask, save_path, 
                                      inference_time, confidence)
            
            # æ€§èƒ½åŸºå‡†æµ‹è¯•ï¼ˆä»…åœ¨ç¬¬ä¸€å¼ å›¾åƒä¸Šè¿›è¡Œï¼‰
            if benchmark and i == 0:
                avg_time, min_time, max_time = self.run_performance_benchmark(image_input)

        # æ€»ä½“æ€§èƒ½ç»Ÿè®¡
        print(f"\n" + "="*80)
        print(f"âœ… {len(image_paths)} å¼ å›¾åƒçš„ç«¯åˆ°ç«¯æ¨ç†æµ‹è¯•å®Œæˆ!")
        print(f"ğŸ“Š æ€»ä½“æ€§èƒ½ç»Ÿè®¡:")
        print(f"   âš¡ å¹³å‡æ¨ç†æ—¶é—´: {np.mean(inference_times)*1000:.2f}ms")
        print(f"   ğŸ“ˆ å¹³å‡ç½®ä¿¡åº¦: {np.mean(confidences):.3f}")
        print(f"   ğŸš€ å®é™…å¹³å‡FPS: {1/np.mean(inference_times):.1f}")
        print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {output_dir}")
        
        # Atlaså¼€å‘æ¿éƒ¨ç½²å»ºè®®
        print(f"\nğŸ¯ Atlaså¼€å‘æ¿éƒ¨ç½²ä¼˜åŠ¿:")
        print(f"   âœ¨ ç«¯åˆ°ç«¯æ¨ç†: æ— CPUé¢„å¤„ç†ç“¶é¢ˆ")
        print(f"   ğŸš€ NPUåŠ é€Ÿ: é¢„æœŸæ€§èƒ½æå‡ 2-3å€")
        print(f"   ğŸ’¾ å†…å­˜ä¼˜åŒ–: å‡å°‘CPU-NPUæ•°æ®ä¼ è¾“")
        print(f"   ğŸ® æ˜“äºé›†æˆ: å•æ¬¡æ¨ç†è°ƒç”¨å®Œæˆæ‰€æœ‰æ“ä½œ")
        print("="*80)

def main():
    # ç«¯åˆ°ç«¯ONNXæ¨¡å‹è·¯å¾„
    onnx_model_path = './weights/fast_scnn_tusimple_e2e_640x480.onnx'
    
    if not os.path.exists(onnx_model_path):
        print(f"âŒ é”™è¯¯: ç«¯åˆ°ç«¯ONNXæ¨¡å‹æ–‡ä»¶æœªæ‰¾åˆ° '{onnx_model_path}'")
        print("ğŸ’¡ è¯·å…ˆè¿è¡Œä»¥ä¸‹å‘½ä»¤ç”Ÿæˆç«¯åˆ°ç«¯æ¨¡å‹:")
        print("   python export_onnx_fixed.py --end-to-end --input-size 640,480 --output-path ./weights/fast_scnn_tusimple_e2e_640x480.onnx")
        return

    print("ğŸš€ å¯åŠ¨ç«¯åˆ°ç«¯ONNXæ¨ç†æµ‹è¯•...")
    print("ğŸ¯ æ¨¡æ‹ŸAtlaså¼€å‘æ¿æ™ºèƒ½å°è½¦åœºæ™¯")
    
    tester = EndToEndONNXTester(onnx_model_path)
    tester.run_test(num_images=5, benchmark=True)

if __name__ == '__main__':
    main()
