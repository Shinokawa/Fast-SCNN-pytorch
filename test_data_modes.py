#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æµ‹è¯•ä¸åŒæ•°æ®åŠ è½½æ¨¡å¼å¯¹ä¿¡æ¯ä¿ç•™çš„å½±å“
"""

import os
import matplotlib.pyplot as plt
import numpy as np
from PIL import Image
from torchvision import transforms
from data_loader import get_segmentation_dataset

def test_data_loading_modes():
    """æµ‹è¯•ä¸åŒçš„æ•°æ®åŠ è½½æ¨¡å¼"""
    
    # åˆ›å»ºä¸åŒçš„æ•°æ®åŠ è½½å™¨é…ç½®
    input_transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize([.485, .456, .406], [.229, .224, .225]),
    ])
    
    configs = [
        {
            'name': 'æ ‡å‡†æ¨¡å¼ (è£å‰ªåˆ°768x768)',
            'kwargs': {
                'transform': input_transform,
                'base_size': 1024,
                'crop_size': 768,
                'sample_ratio': 0.001,  # åªå–å¾ˆå°‘æ ·æœ¬ç”¨äºæµ‹è¯•
                'max_samples': 3
            }
        },
        {
            'name': 'åŸå°ºå¯¸ä¿æŒæ¨¡å¼',
            'kwargs': {
                'transform': None,  # ä¸ä½¿ç”¨transformä»¥ä¾¿æŸ¥çœ‹åŸå§‹å°ºå¯¸
                'keep_original_size': True,
                'sample_ratio': 0.001,
                'max_samples': 3
            }
        },
        {
            'name': 'å¤šå°ºåº¦æ¨¡å¼ (0.8-1.2x)',
            'kwargs': {
                'transform': None,
                'multi_scale': True,
                'min_scale': 0.8,
                'max_scale': 1.2,
                'sample_ratio': 0.001,
                'max_samples': 3
            }
        }
    ]
    
    print("=== æµ‹è¯•ä¸åŒæ•°æ®åŠ è½½æ¨¡å¼ ===\n")
    
    for config in configs:
        print(f"ğŸ“Š {config['name']}")
        try:
            dataset = get_segmentation_dataset('bdd100k', split='train', mode='train',
                                             subset='100k', label_type='binary',
                                             **config['kwargs'])
            print(f"   æ•°æ®é›†å¤§å°: {len(dataset)}")
            
            if len(dataset) > 0:
                img, mask = dataset[0]
                if hasattr(img, 'shape'):
                    print(f"   å›¾åƒå½¢çŠ¶: {img.shape}")
                else:
                    print(f"   å›¾åƒå°ºå¯¸: {img.size}")
                
                if hasattr(mask, 'shape'):
                    print(f"   æ©ç å½¢çŠ¶: {mask.shape}")
                else:
                    print(f"   æ©ç å°ºå¯¸: {mask.size}")
                
                # è®¡ç®—æœ‰æ•ˆåƒç´ æ¯”ä¾‹
                if hasattr(mask, 'numpy'):
                    mask_np = mask.numpy()
                elif hasattr(mask, 'shape'):
                    mask_np = mask
                else:
                    mask_np = np.array(mask)
                
                total_pixels = mask_np.size
                drivable_pixels = np.sum(mask_np == 1)
                drivable_ratio = drivable_pixels / total_pixels * 100
                print(f"   å¯é©¾é©¶åŒºåŸŸæ¯”ä¾‹: {drivable_ratio:.2f}%")
                
        except Exception as e:
            print(f"   âŒ é”™è¯¯: {str(e)}")
        
        print()

def visualize_size_comparison():
    """å¯è§†åŒ–ä¸åŒæ¨¡å¼ä¸‹çš„å°ºå¯¸å¯¹æ¯”"""
    
    configs = [
        ('æ ‡å‡†è£å‰ª', {'base_size': 1024, 'crop_size': 768}),
        ('åŸå°ºå¯¸', {'keep_original_size': True}),
        ('å¤šå°ºåº¦', {'multi_scale': True, 'min_scale': 0.9, 'max_scale': 1.1})
    ]
    
    plt.figure(figsize=(15, 5))
    
    for idx, (name, kwargs) in enumerate(configs):
        try:
            dataset = get_segmentation_dataset('bdd100k', split='train', mode='train',
                                             subset='100k', label_type='binary',
                                             sample_ratio=0.0005, max_samples=1, **kwargs)
            
            if len(dataset) > 0:
                img, mask = dataset[0]
                
                # è½¬æ¢ä¸ºå¯æ˜¾ç¤ºæ ¼å¼
                if hasattr(img, 'numpy'):
                    if img.shape[0] == 3:  # CHW format
                        img_display = img.numpy().transpose(1, 2, 0)
                    else:
                        img_display = img.numpy()
                else:
                    img_display = np.array(img)
                
                if hasattr(mask, 'numpy'):
                    mask_display = mask.numpy()
                else:
                    mask_display = np.array(mask)
                
                plt.subplot(2, 3, idx + 1)
                plt.imshow(img_display)
                plt.title(f'{name}\nå›¾åƒ: {img_display.shape}')
                plt.axis('off')
                
                plt.subplot(2, 3, idx + 4)
                plt.imshow(mask_display, cmap='gray')
                plt.title(f'æ©ç : {mask_display.shape}')
                plt.axis('off')
        
        except Exception as e:
            print(f"é…ç½® {name} å‡ºé”™: {e}")
    
    plt.tight_layout()
    plt.savefig('data_loading_comparison.png', dpi=150, bbox_inches='tight')
    print("å¯è§†åŒ–ç»“æœä¿å­˜åˆ° 'data_loading_comparison.png'")

if __name__ == '__main__':
    print("ğŸ” å¼€å§‹æµ‹è¯•æ•°æ®åŠ è½½æ¨¡å¼...")
    test_data_loading_modes()
    
    print("ğŸ¨ ç”Ÿæˆå¯è§†åŒ–å¯¹æ¯”...")
    try:
        visualize_size_comparison()
    except Exception as e:
        print(f"å¯è§†åŒ–ç”Ÿæˆå¤±è´¥: {e}")
    
    print("\nğŸ’¡ å»ºè®®:")
    print("1. å¯¹äºå®Œæ•´åœºæ™¯ç†è§£: ä½¿ç”¨ --keep-original-size")
    print("2. å¯¹äºå¤šå°ºåº¦é²æ£’æ€§: ä½¿ç”¨ --multi-scale")
    print("3. å¯¹äºå¿«é€Ÿè®­ç»ƒ: ä½¿ç”¨æ ‡å‡†è£å‰ªæ¨¡å¼")
    print("4. Fast-SCNNæ”¯æŒä»»æ„å°ºå¯¸ï¼Œå¯ä»¥æ··åˆä½¿ç”¨ä¸åŒå°ºå¯¸çš„æ•°æ®")
