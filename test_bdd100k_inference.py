#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
BDD100Kå¯é©¾é©¶åŒºåŸŸåˆ†å‰²æ¨ç†æµ‹è¯•è„šæœ¬
æµ‹è¯•è®­ç»ƒå¥½çš„æ¨¡å‹åœ¨æµ‹è¯•é›†ä¸Šçš„æ•ˆæœ
"""

import os
import time
import argparse
import numpy as np
import torch
import torch.nn.functional as F
from PIL import Image
import matplotlib.pyplot as plt
from torchvision import transforms

from models.fast_scnn import FastSCNN
from data_loader import get_segmentation_dataset

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

def test_bdd100k_inference():
    """BDD100Kæ¨ç†æµ‹è¯•"""
    print("ğŸš— BDD100Kå¯é©¾é©¶åŒºåŸŸåˆ†å‰²æ¨ç†æµ‹è¯•")
    print("=" * 50)
    
    # è®¾ç½®å‚æ•°
    model_path = './weights/fast_scnn_bdd100k_best_model.pth'
    output_dir = './bdd100k_inference_results'
    test_samples = 10
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    print(f"ğŸ”§ ä½¿ç”¨è®¾å¤‡: {device}")
    print(f"ğŸ“‚ æ¨¡å‹è·¯å¾„: {model_path}")
    print(f"ğŸ“‚ è¾“å‡ºç›®å½•: {output_dir}")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)
    
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
    if not os.path.exists(model_path):
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        print("è¯·ç¡®ä¿è®­ç»ƒå®Œæˆå¹¶ä¿å­˜äº†æ¨¡å‹æƒé‡")
        return
    
    # åŠ è½½æ¨¡å‹
    print(f"\nğŸ“¥ åŠ è½½æ¨¡å‹...")
    model = FastSCNN(num_classes=2, aux=False)  # äºŒåˆ†ç±»
    try:
        checkpoint = torch.load(model_path, map_location=device)
        model.load_state_dict(checkpoint)
        model.to(device)
        model.eval()
        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return
    
    # å›¾åƒé¢„å¤„ç†
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize([.485, .456, .406], [.229, .224, .225]),
    ])
    
    # åŠ è½½æµ‹è¯•æ•°æ®é›†
    print(f"\nğŸ“‚ åŠ è½½æµ‹è¯•æ•°æ®é›†...")
    try:
        test_dataset = get_segmentation_dataset(
            'bdd100k', split='val', mode='val',  # ä½¿ç”¨éªŒè¯é›†ä½œä¸ºæµ‹è¯•
            subset='100k', label_type='binary',
            keep_original_size=True,  # ä¿æŒåŸå°ºå¯¸
            max_samples=test_samples
        )
        print(f"âœ… åŠ è½½äº† {len(test_dataset)} ä¸ªæµ‹è¯•æ ·æœ¬")
    except Exception as e:
        print(f"âŒ æ•°æ®é›†åŠ è½½å¤±è´¥: {e}")
        return
    
    # å¼€å§‹æ¨ç†æµ‹è¯•
    print(f"\nğŸ” å¼€å§‹æ¨ç†æµ‹è¯•...")
    
    total_inference_time = 0
    results = []
    
    for i in range(min(test_samples, len(test_dataset))):
        print(f"\nğŸ“· å¤„ç†æ ·æœ¬ {i+1}/{test_samples}")
        
        # è·å–æµ‹è¯•æ ·æœ¬
        img_data, gt_mask = test_dataset[i]
        
        # å¤„ç†å›¾åƒæ•°æ®
        if isinstance(img_data, np.ndarray):
            # å¦‚æœæ˜¯numpyæ•°ç»„ï¼Œè½¬æ¢ä¸ºPILå›¾åƒ
            if len(img_data.shape) == 3:
                if img_data.shape[0] == 3:  # CHWæ ¼å¼
                    img_array = img_data.transpose(1, 2, 0)
                else:  # HWCæ ¼å¼
                    img_array = img_data
                # ç¡®ä¿æ•°æ®èŒƒå›´æ­£ç¡®
                if img_array.max() <= 1.0:
                    img_array = (img_array * 255).astype(np.uint8)
                original_img = Image.fromarray(img_array.astype(np.uint8))
            else:
                print(f"   âš ï¸  ä¸æ”¯æŒçš„å›¾åƒæ ¼å¼: {img_data.shape}")
                continue
        else:
            original_img = img_data
        
        # é¢„å¤„ç†å›¾åƒ
        img_tensor = transform(original_img).unsqueeze(0).to(device)
        
        # æ¨ç†
        with torch.no_grad():
            start_time = time.time()
            outputs = model(img_tensor)
            inference_time = time.time() - start_time
            
            # è·å–é¢„æµ‹ç»“æœ
            if isinstance(outputs, tuple):
                pred = outputs[0]  # ä¸»è¾“å‡º
            else:
                pred = outputs
            
            # è½¬æ¢ä¸ºæ¦‚ç‡å’Œé¢„æµ‹ç±»åˆ«
            prob = F.softmax(pred, dim=1)
            pred_class = torch.argmax(pred, dim=1)
            
            # è½¬æ¢ä¸ºnumpy
            prob_np = prob.squeeze().cpu().numpy()
            pred_np = pred_class.squeeze().cpu().numpy()
        
        total_inference_time += inference_time
        
        # è®¡ç®—å‡†ç¡®ç‡ (ä¸çœŸå®æ ‡ç­¾å¯¹æ¯”)
        if isinstance(gt_mask, torch.Tensor):
            gt_mask_np = gt_mask.numpy()
        else:
            gt_mask_np = np.array(gt_mask)
        
        # è®¡ç®—æŒ‡æ ‡
        correct_pixels = np.sum(pred_np == gt_mask_np)
        total_pixels = pred_np.size
        pixel_acc = correct_pixels / total_pixels
        
        # è®¡ç®—IoU
        intersection = np.sum((pred_np == 1) & (gt_mask_np == 1))
        union = np.sum((pred_np == 1) | (gt_mask_np == 1))
        iou = intersection / union if union > 0 else 0
        
        print(f"   æ¨ç†æ—¶é—´: {inference_time*1000:.1f}ms")
        print(f"   åƒç´ å‡†ç¡®ç‡: {pixel_acc*100:.2f}%")
        print(f"   IoU: {iou*100:.2f}%")
        
        results.append({
            'pixel_acc': pixel_acc,
            'iou': iou,
            'inference_time': inference_time
        })
        
        # å¯è§†åŒ–ç»“æœ
        try:
            fig, axes = plt.subplots(1, 4, figsize=(20, 5))
            
            # åŸå§‹å›¾åƒ
            axes[0].imshow(original_img)
            axes[0].set_title('åŸå§‹å›¾åƒ', fontsize=14)
            axes[0].axis('off')
            
            # çœŸå®æ ‡ç­¾
            axes[1].imshow(gt_mask_np, cmap='gray')
            axes[1].set_title('çœŸå®æ ‡ç­¾\n(ç™½è‰²=å¯é©¾é©¶)', fontsize=14)
            axes[1].axis('off')
            
            # é¢„æµ‹ç»“æœ
            axes[2].imshow(pred_np, cmap='gray')
            axes[2].set_title(f'é¢„æµ‹ç»“æœ\nIoU: {iou*100:.1f}%', fontsize=14)
            axes[2].axis('off')
            
            # å¯é©¾é©¶åŒºåŸŸæ¦‚ç‡çƒ­åŠ›å›¾
            if len(prob_np.shape) > 2:  # å¤šç±»åˆ«
                drivable_prob = prob_np[1]  # ç±»åˆ«1çš„æ¦‚ç‡
            else:
                drivable_prob = prob_np
            im = axes[3].imshow(drivable_prob, cmap='hot', vmin=0, vmax=1)
            axes[3].set_title(f'æ¦‚ç‡çƒ­åŠ›å›¾\næ¨ç†: {inference_time*1000:.1f}ms', fontsize=14)
            axes[3].axis('off')
            plt.colorbar(im, ax=axes[3], fraction=0.046, pad=0.04)
            
            plt.tight_layout()
            
            # ä¿å­˜ç»“æœ
            save_path = os.path.join(output_dir, f'inference_result_{i+1}.png')
            plt.savefig(save_path, dpi=150, bbox_inches='tight')
            plt.close(fig)
            print(f"   ğŸ’¾ ç»“æœå·²ä¿å­˜: {save_path}")
            
        except Exception as e:
            print(f"   âš ï¸  å¯è§†åŒ–å¤±è´¥: {e}")
    
    # ç»Ÿè®¡ç»“æœ
    print(f"\nğŸ“Š æ¨ç†æµ‹è¯•ç»“æœç»Ÿè®¡:")
    print("=" * 50)
    
    if results:
        avg_pixel_acc = np.mean([r['pixel_acc'] for r in results])
        avg_iou = np.mean([r['iou'] for r in results])
        avg_inference_time = np.mean([r['inference_time'] for r in results])
        fps = 1.0 / avg_inference_time
        
        print(f"å¹³å‡åƒç´ å‡†ç¡®ç‡: {avg_pixel_acc*100:.2f}%")
        print(f"å¹³å‡IoU: {avg_iou*100:.2f}%")
        print(f"å¹³å‡æ¨ç†æ—¶é—´: {avg_inference_time*1000:.1f}ms")
        print(f"ç†è®ºFPS: {fps:.1f}")
        print(f"æ€»æ¨ç†æ—¶é—´: {total_inference_time:.2f}s")
        
        # æ€§èƒ½è¯„ä¼°
        print(f"\nğŸ¯ æ€§èƒ½è¯„ä¼°:")
        if avg_iou > 0.75:
            print("âœ… IoUä¼˜ç§€ (>75%)")
        elif avg_iou > 0.60:
            print("ğŸŸ¡ IoUè‰¯å¥½ (>60%)")
        else:
            print("âš ï¸  IoUéœ€è¦æ”¹è¿› (<60%)")
        
        if fps > 30:
            print("âš¡ æ¨ç†é€Ÿåº¦ä¼˜ç§€ (>30 FPS)")
        elif fps > 15:
            print("ğŸŸ¡ æ¨ç†é€Ÿåº¦è‰¯å¥½ (>15 FPS)")
        else:
            print("âš ï¸  æ¨ç†é€Ÿåº¦è¾ƒæ…¢ (<15 FPS)")
        
        # æ™ºèƒ½å°è½¦é€‚ç”¨æ€§è¯„ä¼°
        print(f"\nğŸš— æ™ºèƒ½å°è½¦é€‚ç”¨æ€§:")
        if avg_iou > 0.7 and fps > 10:
            print("âœ… å®Œå…¨é€‚ç”¨äºæ™ºèƒ½å°è½¦!")
            print("   - ç²¾åº¦è¶³å¤Ÿå®‰å…¨é©¾é©¶")
            print("   - é€Ÿåº¦æ»¡è¶³å®æ—¶è¦æ±‚")
        elif avg_iou > 0.6:
            print("ğŸŸ¡ åŸºæœ¬é€‚ç”¨äºæ™ºèƒ½å°è½¦")
            print("   - ç²¾åº¦å¯æ¥å—ï¼Œå»ºè®®ä½é€Ÿè¡Œé©¶")
        else:
            print("âš ï¸  éœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–")
    
    print(f"\nğŸ’¾ æ¨ç†ç»“æœå·²ä¿å­˜åˆ°: {output_dir}")
    print("ğŸ‰ æ¨ç†æµ‹è¯•å®Œæˆ!")

if __name__ == '__main__':
    test_bdd100k_inference()
