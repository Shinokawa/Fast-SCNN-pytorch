#!/usr/bin/env python3
"""
ç®€åŒ–çš„ç›¸æœºé€è§†å˜æ¢æ ‡å®šå·¥å…· (å‘½ä»¤è¡Œç‰ˆæœ¬)

åŠŸèƒ½ç‰¹æ€§ï¼š
- æ‰‹åŠ¨è¾“å…¥å›¾åƒåæ ‡ç‚¹
- æ‰‹åŠ¨è¾“å…¥çœŸå®ä¸–ç•Œå¯¹åº”ç‚¹åæ ‡
- è®¡ç®—é€è§†å˜æ¢çŸ©é˜µ
- ç”Ÿæˆä¿¯è§†å›¾é¢„è§ˆ
- ä¿å­˜æ ‡å®šå‚æ•°

ä½¿ç”¨æ–¹æ³•ï¼š
python simple_camera_calibration.py --input kuruma/raw_collected_data/raw_images/raw_20250704_013409_372.jpg

æ“ä½œè¯´æ˜ï¼š
1. æ ¹æ®æç¤ºè¾“å…¥å›¾åƒä¸­4ä¸ªç‚¹çš„åæ ‡ï¼ˆåƒç´ åæ ‡ï¼‰
2. è¾“å…¥æ¯ä¸ªç‚¹åœ¨çœŸå®ä¸–ç•Œä¸­çš„åæ ‡ï¼ˆå•ä½ï¼šå˜ç±³ï¼‰
3. ç”Ÿæˆå¹¶ä¿å­˜æ ‡å®šå‚æ•°

æ³¨æ„ï¼šå»ºè®®é€‰æ‹©åœ°é¢ä¸Šçš„çŸ©å½¢æ ‡è®°ç‰©ï¼ˆå¦‚A4çº¸ï¼‰çš„å››ä¸ªè§’ç‚¹è¿›è¡Œæ ‡å®š
"""

import cv2
import numpy as np
import json
import argparse
import os
from pathlib import Path
import time

class SimpleCameraCalibrator:
    def __init__(self, image_path):
        """
        åˆå§‹åŒ–ç®€åŒ–ç›¸æœºæ ‡å®šå·¥å…·
        
        å‚æ•°ï¼š
            image_path: è¾“å…¥å›¾åƒè·¯å¾„
        """
        self.image_path = image_path
        self.image = None
        self.image_points = []  # å›¾åƒä¸­çš„ç‚¹
        self.world_points = []  # çœŸå®ä¸–ç•Œä¸­çš„ç‚¹
        self.transform_matrix = None
        
        # åŠ è½½å›¾åƒ
        self.load_image()
        
    def load_image(self):
        """åŠ è½½å¹¶å‡†å¤‡å›¾åƒ"""
        if not os.path.exists(self.image_path):
            raise FileNotFoundError(f"å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {self.image_path}")
        
        self.image = cv2.imread(self.image_path)
        if self.image is None:
            raise ValueError(f"æ— æ³•è¯»å–å›¾åƒ: {self.image_path}")
        
        # è·å–å›¾åƒå°ºå¯¸
        self.height, self.width = self.image.shape[:2]
        print(f"ğŸ“ å›¾åƒå°ºå¯¸: {self.width} Ã— {self.height}")
        
        # ä¿å­˜ä¸€ä¸ªå¸¦æ ‡è®°çš„å›¾åƒä¾›å‚è€ƒ
        self.save_reference_image()
    
    def save_reference_image(self):
        """ä¿å­˜å‚è€ƒå›¾åƒä¾›æŸ¥çœ‹"""
        reference_path = self.image_path.replace('.jpg', '_reference_for_calibration.jpg')
        reference_img = self.image.copy()
        
        # æ·»åŠ ä¸€äº›è¾…åŠ©çº¿å’Œæ ‡è®°
        # æ·»åŠ ä¸­å¿ƒåå­—çº¿
        center_x, center_y = self.width // 2, self.height // 2
        cv2.line(reference_img, (center_x - 20, center_y), (center_x + 20, center_y), (0, 255, 0), 1)
        cv2.line(reference_img, (center_x, center_y - 20), (center_x, center_y + 20), (0, 255, 0), 1)
        
        # æ·»åŠ åæ ‡æ ‡è®°
        for y in range(0, self.height, 50):
            for x in range(0, self.width, 50):
                cv2.circle(reference_img, (x, y), 2, (128, 128, 128), -1)
        
        # æ·»åŠ åæ ‡è½´æ ‡è®°
        for x in range(0, self.width, 100):
            cv2.putText(reference_img, str(x), (x, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)
        
        for y in range(0, self.height, 100):
            cv2.putText(reference_img, str(y), (5, y), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)
        
        cv2.imwrite(reference_path, reference_img)
        print(f"ğŸ“¸ å‚è€ƒå›¾åƒå·²ä¿å­˜: {reference_path}")
        print("ğŸ’¡ è¯·æ‰“å¼€æ­¤å›¾åƒæŸ¥çœ‹åæ ‡ç³»ï¼Œä»¥ä¾¿å‡†ç¡®è¾“å…¥åæ ‡")
    
    def input_image_coordinates(self):
        """è¾“å…¥å›¾åƒåæ ‡"""
        print("\n" + "="*60)
        print("ğŸ“ è¯·è¾“å…¥å›¾åƒåæ ‡")
        print("="*60)
        print("ğŸ“ è¯·æŒ‰ç…§é¡ºåºè¾“å…¥4ä¸ªç‚¹åœ¨å›¾åƒä¸­çš„åƒç´ åæ ‡")
        print("ğŸ“ åæ ‡ç³»ï¼šå·¦ä¸Šè§’ä¸º(0,0)ï¼ŒXè½´å‘å³ï¼ŒYè½´å‘ä¸‹")
        print("ğŸ“‹ å»ºè®®é¡ºåºï¼šå·¦ä¸Šè§’ â†’ å³ä¸Šè§’ â†’ å³ä¸‹è§’ â†’ å·¦ä¸‹è§’")
        print("ğŸ’¡ è¯·å‚è€ƒç”Ÿæˆçš„referenceå›¾åƒæ¥ç¡®å®šå‡†ç¡®åæ ‡")
        print("-"*60)
        
        point_names = ["å·¦ä¸Šè§’", "å³ä¸Šè§’", "å³ä¸‹è§’", "å·¦ä¸‹è§’"]
        
        for i in range(4):
            print(f"\nğŸ“ ç‚¹ {i+1} ({point_names[i]})")
            
            while True:
                try:
                    x_input = input(f"  è¯·è¾“å…¥ X åæ ‡ (0-{self.width-1}): ")
                    y_input = input(f"  è¯·è¾“å…¥ Y åæ ‡ (0-{self.height-1}): ")
                    
                    x_img = int(x_input)
                    y_img = int(y_input)
                    
                    # éªŒè¯åæ ‡èŒƒå›´
                    if 0 <= x_img < self.width and 0 <= y_img < self.height:
                        self.image_points.append((x_img, y_img))
                        print(f"  âœ… å›¾åƒåæ ‡: ({x_img}, {y_img})")
                        break
                    else:
                        print(f"  âŒ åæ ‡è¶…å‡ºèŒƒå›´ï¼Œè¯·è¾“å…¥æœ‰æ•ˆåæ ‡")
                        
                except ValueError:
                    print("  âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•´æ•°")
    
    def input_world_coordinates(self):
        """è¾“å…¥çœŸå®ä¸–ç•Œåæ ‡"""
        print("\n" + "="*60)
        print("ğŸŒ è¯·è¾“å…¥çœŸå®ä¸–ç•Œåæ ‡")
        print("="*60)
        print("ğŸ“ è¯·æŒ‰ç…§å›¾åƒç‚¹çš„é¡ºåºè¾“å…¥æ¯ä¸ªç‚¹åœ¨çœŸå®ä¸–ç•Œä¸­çš„åæ ‡")
        print("ğŸ“ å•ä½ï¼šå˜ç±³ (cm)")
        print("ğŸ“ å»ºè®®ï¼šä»¥A4çº¸çš„ä¸€ä¸ªè§’ä¸ºåŸç‚¹(0,0)å»ºç«‹åæ ‡ç³»")
        print("ğŸ“ A4çº¸å°ºå¯¸ï¼š21.0cm Ã— 29.7cm")
        print("ğŸ’¡ ç¤ºä¾‹åæ ‡ç³»ï¼ˆA4çº¸å·¦ä¸Šè§’ä¸ºåŸç‚¹ï¼‰ï¼š")
        print("    å·¦ä¸Šè§’: (0, 0)")
        print("    å³ä¸Šè§’: (21, 0)")
        print("    å³ä¸‹è§’: (21, 29.7)")
        print("    å·¦ä¸‹è§’: (0, 29.7)")
        print("-"*60)
        
        point_names = ["å·¦ä¸Šè§’", "å³ä¸Šè§’", "å³ä¸‹è§’", "å·¦ä¸‹è§’"]
        
        for i in range(4):
            print(f"\nğŸ“ ç‚¹ {i+1} ({point_names[i]}) - å›¾åƒåæ ‡: {self.image_points[i]}")
            
            while True:
                try:
                    x_input = input(f"  è¯·è¾“å…¥çœŸå®ä¸–ç•Œ X åæ ‡ (cm): ")
                    y_input = input(f"  è¯·è¾“å…¥çœŸå®ä¸–ç•Œ Y åæ ‡ (cm): ")
                    
                    x_world = float(x_input)
                    y_world = float(y_input)
                    
                    self.world_points.append((x_world, y_world))
                    print(f"  âœ… çœŸå®ä¸–ç•Œåæ ‡: ({x_world}, {y_world}) cm")
                    break
                    
                except ValueError:
                    print("  âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
        
        print("\nğŸ“Š æ ‡å®šç‚¹å¯¹åº”å…³ç³»:")
        print("-"*40)
        for i in range(4):
            img_pt = self.image_points[i]
            world_pt = self.world_points[i]
            print(f"{point_names[i]:8}: {img_pt} â†’ {world_pt}")
    
    def calculate_transform_matrix(self):
        """è®¡ç®—é€è§†å˜æ¢çŸ©é˜µ"""
        print("\nğŸ§® è®¡ç®—é€è§†å˜æ¢çŸ©é˜µ...")
        
        # è½¬æ¢ä¸ºnumpyæ•°ç»„
        src_points = np.float32(self.image_points)
        dst_points = np.float32(self.world_points)
        
        # è®¡ç®—é€è§†å˜æ¢çŸ©é˜µ
        self.transform_matrix = cv2.getPerspectiveTransform(src_points, dst_points)
        
        print("âœ… é€è§†å˜æ¢çŸ©é˜µè®¡ç®—å®Œæˆ!")
        print("\nğŸ“ é€è§†å˜æ¢çŸ©é˜µ:")
        print(self.transform_matrix)
        
        # è®¡ç®—é€†å˜æ¢çŸ©é˜µï¼ˆä»ä¸–ç•Œåæ ‡å›åˆ°å›¾åƒåæ ‡ï¼‰
        self.inverse_transform_matrix = cv2.getPerspectiveTransform(dst_points, src_points)
        
        return self.transform_matrix
    
    def generate_bird_eye_preview(self):
        """ç”Ÿæˆé¸Ÿç°å›¾é¢„è§ˆ"""
        if self.transform_matrix is None:
            print("âŒ è¯·å…ˆè®¡ç®—å˜æ¢çŸ©é˜µ")
            return
        
        print("\nğŸ¦… ç”Ÿæˆé¸Ÿç°å›¾é¢„è§ˆ...")
        
        # è®¡ç®—è¾“å‡ºå›¾åƒå°ºå¯¸
        world_points_array = np.array(self.world_points)
        min_x, min_y = world_points_array.min(axis=0)
        max_x, max_y = world_points_array.max(axis=0)
        
        # æ·»åŠ è¾¹è·
        margin = max(max_x - min_x, max_y - min_y) * 0.3
        min_x -= margin
        min_y -= margin
        max_x += margin
        max_y += margin
        
        # è®¡ç®—åƒç´ /å•ä½æ¯”ä¾‹
        pixels_per_unit = 20  # æ¯å˜ç±³20åƒç´ 
        
        output_width = int((max_x - min_x) * pixels_per_unit)
        output_height = int((max_y - min_y) * pixels_per_unit)
        
        print(f"ğŸ“ é¸Ÿç°å›¾å°ºå¯¸: {output_width} Ã— {output_height}")
        print(f"ğŸ“ èŒƒå›´: X({min_x:.1f} ~ {max_x:.1f}) cm, Y({min_y:.1f} ~ {max_y:.1f}) cm")
        
        # åˆ›å»ºå˜æ¢çŸ©é˜µï¼ˆä»å›¾åƒåˆ°é¸Ÿç°å›¾åƒç´ åæ ‡ï¼‰
        world_to_pixel = np.array([
            [pixels_per_unit, 0, -min_x * pixels_per_unit],
            [0, pixels_per_unit, -min_y * pixels_per_unit],
            [0, 0, 1]
        ], dtype=np.float32)
        
        # ç»„åˆå˜æ¢çŸ©é˜µ
        combined_transform = world_to_pixel @ self.transform_matrix
        
        # æ‰§è¡Œé€è§†å˜æ¢
        bird_eye_view = cv2.warpPerspective(self.image, combined_transform, 
                                          (output_width, output_height))
        
        # åœ¨é¸Ÿç°å›¾ä¸Šæ ‡è®°æ ‡å®šç‚¹
        for i, (x_world, y_world) in enumerate(self.world_points):
            pixel_x = int((x_world - min_x) * pixels_per_unit)
            pixel_y = int((y_world - min_y) * pixels_per_unit)
            
            cv2.circle(bird_eye_view, (pixel_x, pixel_y), 8, (0, 255, 255), -1)
            cv2.putText(bird_eye_view, str(i+1), (pixel_x + 12, pixel_y - 12),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)
        
        # æ·»åŠ ç½‘æ ¼
        grid_interval = 10  # æ¯10cmä¸€ä¸ªç½‘æ ¼
        grid_color = (128, 128, 128)
        
        # å‚ç›´çº¿
        x = min_x
        while x <= max_x:
            if abs(x % grid_interval) < 0.1:
                pixel_x = int((x - min_x) * pixels_per_unit)
                if 0 <= pixel_x < output_width:
                    cv2.line(bird_eye_view, (pixel_x, 0), (pixel_x, output_height-1), grid_color, 1)
            x += grid_interval
        
        # æ°´å¹³çº¿
        y = min_y
        while y <= max_y:
            if abs(y % grid_interval) < 0.1:
                pixel_y = int((y - min_y) * pixels_per_unit)
                if 0 <= pixel_y < output_height:
                    cv2.line(bird_eye_view, (0, pixel_y), (output_width-1, pixel_y), grid_color, 1)
            y += grid_interval
        
        # ä¿å­˜é¢„è§ˆå›¾
        preview_path = self.image_path.replace('.jpg', '_bird_eye_preview.jpg')
        cv2.imwrite(preview_path, bird_eye_view)
        print(f"ğŸ’¾ é¸Ÿç°å›¾é¢„è§ˆå·²ä¿å­˜: {preview_path}")
        
        return bird_eye_view, (min_x, min_y, max_x, max_y, pixels_per_unit)
    
    def save_calibration_data(self, output_path=None):
        """ä¿å­˜æ ‡å®šæ•°æ®"""
        if output_path is None:
            output_path = self.image_path.replace('.jpg', '_calibration.json')
        
        calibration_data = {
            'image_path': self.image_path,
            'image_size': [self.width, self.height],
            'image_points': self.image_points,
            'world_points': self.world_points,
            'transform_matrix': self.transform_matrix.tolist(),
            'inverse_transform_matrix': self.inverse_transform_matrix.tolist(),
            'calibration_time': time.strftime('%Y-%m-%d %H:%M:%S'),
            'description': 'ç›¸æœºé€è§†å˜æ¢æ ‡å®šæ•°æ® (ç®€åŒ–ç‰ˆ)',
            'units': 'centimeters'
        }
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(calibration_data, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ’¾ æ ‡å®šæ•°æ®å·²ä¿å­˜: {output_path}")
        return output_path
    
    def run_calibration(self):
        """è¿è¡Œå®Œæ•´çš„æ ‡å®šæµç¨‹"""
        print("ğŸ¯ ç®€åŒ–ç›¸æœºé€è§†å˜æ¢æ ‡å®šå·¥å…·")
        print("="*50)
        print("ğŸ“‹ æ ‡å®šæµç¨‹:")
        print("1. è¾“å…¥å›¾åƒä¸­4ä¸ªç‚¹çš„åƒç´ åæ ‡")
        print("2. è¾“å…¥å¯¹åº”çš„çœŸå®ä¸–ç•Œåæ ‡ï¼ˆå»ºè®®ä½¿ç”¨A4çº¸ï¼‰")
        print("3. è®¡ç®—é€è§†å˜æ¢çŸ©é˜µ")
        print("4. ç”Ÿæˆé¸Ÿç°å›¾é¢„è§ˆ")
        print("5. ä¿å­˜æ ‡å®šå‚æ•°")
        print("="*50)
        
        try:
            # è¾“å…¥å›¾åƒåæ ‡
            self.input_image_coordinates()
            
            # è¾“å…¥çœŸå®ä¸–ç•Œåæ ‡
            self.input_world_coordinates()
            
            # è®¡ç®—å˜æ¢çŸ©é˜µ
            self.calculate_transform_matrix()
            
            # ç”Ÿæˆé¸Ÿç°å›¾é¢„è§ˆ
            bird_eye_view, view_params = self.generate_bird_eye_preview()
            
            # è¯¢é—®æ˜¯å¦ä¿å­˜
            while True:
                save_choice = input("\nğŸ’¾ æ˜¯å¦ä¿å­˜æ ‡å®šæ•°æ®ï¼Ÿ (y/n): ").lower()
                if save_choice in ['y', 'yes', 'æ˜¯']:
                    calibration_file = self.save_calibration_data()
                    break
                elif save_choice in ['n', 'no', 'å¦']:
                    print("âŒ æ ‡å®šæ•°æ®æœªä¿å­˜")
                    calibration_file = None
                    break
                else:
                    print("è¯·è¾“å…¥ y æˆ– n")
            
            # æ˜¾ç¤ºæœ€ç»ˆç»“æœ
            print("\n" + "="*60)
            print("ğŸ‰ æ ‡å®šå®Œæˆ!")
            print("="*60)
            print("ğŸ“Š æ ‡å®šç»“æœæ‘˜è¦:")
            print(f"ğŸ–¼ï¸  è¾“å…¥å›¾åƒ: {self.image_path}")
            print(f"ğŸ“ å›¾åƒå°ºå¯¸: {self.width} Ã— {self.height}")
            print(f"ğŸ“ æ ‡å®šç‚¹æ•°: {len(self.image_points)}")
            
            if calibration_file:
                print(f"ğŸ’¾ æ ‡å®šæ–‡ä»¶: {calibration_file}")
                
                print("\nğŸ”§ ä½¿ç”¨ç¤ºä¾‹:")
                print("# ä½¿ç”¨æ ‡å®šæ•°æ®è¿›è¡Œæ¨ç†")
                print(f'python onnx_bird_eye_inference.py --input "ä½ çš„å›¾åƒ.jpg" --calibration "{calibration_file}" --bird_eye --save_control_map')
            
            return {
                'transform_matrix': self.transform_matrix,
                'inverse_transform_matrix': self.inverse_transform_matrix,
                'image_points': self.image_points,
                'world_points': self.world_points,
                'calibration_file': calibration_file,
                'view_params': view_params
            }
            
        except KeyboardInterrupt:
            print("\nâŒ ç”¨æˆ·ä¸­æ–­æ ‡å®š")
            return None
        except Exception as e:
            print(f"\nâŒ æ ‡å®šè¿‡ç¨‹å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
            return None

def main():
    parser = argparse.ArgumentParser(description="ç®€åŒ–ç›¸æœºé€è§†å˜æ¢æ ‡å®šå·¥å…·")
    parser.add_argument("--input", "-i", required=True, help="è¾“å…¥å›¾åƒè·¯å¾„")
    parser.add_argument("--output", "-o", help="è¾“å‡ºæ ‡å®šæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰")
    
    args = parser.parse_args()
    
    try:
        # åˆ›å»ºæ ‡å®šå·¥å…·
        calibrator = SimpleCameraCalibrator(args.input)
        
        # è¿è¡Œæ ‡å®š
        result = calibrator.run_calibration()
        
        if result:
            print("\nâœ… æ ‡å®šæˆåŠŸå®Œæˆ!")
            
            # å¦‚æœæŒ‡å®šäº†è¾“å‡ºè·¯å¾„ï¼Œå¤åˆ¶æ–‡ä»¶
            if args.output and result['calibration_file']:
                import shutil
                shutil.copy2(result['calibration_file'], args.output)
                print(f"ğŸ“„ æ ‡å®šæ–‡ä»¶å·²å¤åˆ¶åˆ°: {args.output}")
        else:
            print("âŒ æ ‡å®šè¢«å–æ¶ˆæˆ–å¤±è´¥")
            
    except Exception as e:
        print(f"âŒ æ ‡å®šè¿‡ç¨‹å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
