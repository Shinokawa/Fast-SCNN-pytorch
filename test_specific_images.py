"""
TUSimple Lane Segmentation - Test Specific Images (20.jpg)
é¢„æµ‹æ¯ä¸ªæ–‡ä»¶å¤¹ä¸­çš„20.jpgå¹¶ä¸çœŸå®maskå¯¹æ¯”åˆ†æ - éšæœºé€‰æ‹©50å¼ 
"""
import os
os.environ['KMP_DUPLICATE_LIB_OK']='TRUE'
import time
import random
import numpy as np
import torch
import torch.nn.functional as F
from torch.amp import autocast
from torchvision import transforms
import cv2
from PIL import Image
import matplotlib.pyplot as plt

from models.fast_scnn import get_fast_scnn
from utils.metric import SegmentationMetric


class TUSimpleSpecificTester:
    def __init__(self):
        self.device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
        
        # Image transforms (åŸå§‹å°ºå¯¸ï¼Œä¸resize)
        self.input_transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize([.485, .456, .406], [.229, .224, .225]),
        ])
        
        # Load model
        self.model = get_fast_scnn(dataset='tusimple', aux=False)
        model_path = './weights/fast_scnn_tusimple_best_model.pth'
        if os.path.isfile(model_path):
            print(f'Loading model from {model_path}...')
            state_dict = torch.load(model_path, map_location='cpu')
            # Handle DataParallel models
            if any(key.startswith('module.') for key in state_dict.keys()):
                state_dict = {k.replace('module.', ''): v for k, v in state_dict.items()}
            self.model.load_state_dict(state_dict)
        else:
            raise FileNotFoundError(f"Model file not found: {model_path}")
        
        self.model.to(self.device)
        self.model.eval()
        
        # Metrics
        self.metric = SegmentationMetric(2)  # 2 classes
        
        # æ•°æ®è·¯å¾„
        self.root = './manideep1108/tusimple/versions/5/TUSimple'
        self.test_clips_root = os.path.join(self.root, 'test_set', 'clips')
        self.seg_label_root = os.path.join(self.root, 'train_set', 'seg_label')
        
        print(f"Device: {self.device}")
        print(f"Model loaded successfully")
    
    def find_20jpg_images(self):
        """æŸ¥æ‰¾æ‰€æœ‰åŒ…å«20.jpgçš„æ–‡ä»¶å¤¹"""
        image_paths = []
        mask_paths = []
        
        # éå†test_set/clipsä¸‹çš„æ‰€æœ‰æ—¥æœŸæ–‡ä»¶å¤¹
        if os.path.exists(self.test_clips_root):
            for date_folder in os.listdir(self.test_clips_root):
                date_path = os.path.join(self.test_clips_root, date_folder)
                if os.path.isdir(date_path):
                    # éå†æ¯ä¸ªæ—¥æœŸä¸‹çš„è§†é¢‘æ–‡ä»¶å¤¹
                    for video_folder in os.listdir(date_path):
                        video_path = os.path.join(date_path, video_folder)
                        if os.path.isdir(video_path):
                            # æ£€æŸ¥æ˜¯å¦å­˜åœ¨20.jpg
                            img_file = os.path.join(video_path, '20.jpg')
                            if os.path.exists(img_file):
                                # æ„å»ºå¯¹åº”çš„maskè·¯å¾„
                                mask_file = os.path.join(self.seg_label_root, date_folder, 
                                                       video_folder, '20.png')
                                if os.path.exists(mask_file):
                                    image_paths.append(img_file)
                                    mask_paths.append(mask_file)
                                    print(f"Found pair: {video_folder}/20.jpg")
        
        print(f"Total found {len(image_paths)} valid 20.jpg images with masks")
        
        # éšæœºé€‰æ‹©50å¼ å›¾åƒ
        if len(image_paths) > 50:
            paired_data = list(zip(image_paths, mask_paths))
            random.shuffle(paired_data)
            selected_pairs = paired_data[:50]
            image_paths, mask_paths = zip(*selected_pairs)
            image_paths, mask_paths = list(image_paths), list(mask_paths)
            print(f"Randomly selected 50 images from {len(paired_data)} available")
        
        return image_paths, mask_paths
    
    def load_image(self, image_path):
        """åŠ è½½å¹¶é¢„å¤„ç†å›¾åƒ"""
        image = Image.open(image_path).convert('RGB')
        original_size = image.size  # (width, height)
        
        # åº”ç”¨transforms
        image_tensor = self.input_transform(image).unsqueeze(0)
        return image_tensor, image, original_size
    
    def load_mask(self, mask_path):
        """åŠ è½½å¹¶å¤„ç†mask"""
        mask = Image.open(mask_path).convert('L')
        mask_array = np.array(mask)
        
        # äºŒå€¼åŒ–ï¼šéé›¶å€¼è®¾ä¸º1ï¼ˆè½¦é“çº¿ï¼‰ï¼Œé›¶å€¼è®¾ä¸º0ï¼ˆèƒŒæ™¯ï¼‰
        mask_binary = (mask_array > 0).astype(np.uint8)
        return mask_binary
    
    def predict_image(self, image_tensor):
        """å¯¹å•å¼ å›¾åƒè¿›è¡Œé¢„æµ‹"""
        with torch.no_grad():
            image_input = image_tensor.to(self.device)
            
            start_time = time.time()
            with autocast(device_type=self.device.type):
                outputs = self.model(image_input)
            inference_time = time.time() - start_time
            
            # è·å–é¢„æµ‹ç»“æœ
            if isinstance(outputs, tuple):
                pred = outputs[0]
            else:
                pred = outputs
            
            pred = torch.argmax(pred, dim=1)
            pred_np = pred.squeeze().cpu().numpy()
            
            return pred_np, inference_time
    
    def calculate_metrics(self, pred, gt):
        """è®¡ç®—å•å¼ å›¾åƒçš„æŒ‡æ ‡"""
        # ç¡®ä¿predå’Œgtéƒ½æ˜¯numpyæ•°ç»„
        pred = np.array(pred)
        gt = np.array(gt)
        
        # è®¡ç®—åƒç´ å‡†ç¡®ç‡
        correct = (pred == gt).sum()
        total = pred.size
        pixel_acc = correct / total
        
        # è®¡ç®—IoU for each class
        ious = []
        for class_id in range(2):  # 0: background, 1: lane
            pred_mask = (pred == class_id)
            gt_mask = (gt == class_id)
            
            intersection = (pred_mask & gt_mask).sum()
            union = (pred_mask | gt_mask).sum()
            
            if union == 0:
                iou = 1.0 if intersection == 0 else 0.0
            else:
                iou = intersection / union
            ious.append(iou)
        
        miou = np.mean(ious)
        
        return pixel_acc, miou, ious
    
    def create_comparison_plot(self, original_img, gt_mask, pred_mask, metrics, save_path):
        """åˆ›å»ºå¯¹æ¯”å¯è§†åŒ–å›¾"""
        fig, axes = plt.subplots(2, 3, figsize=(15, 10))
        fig.suptitle(f'Lane Segmentation Results\nPixAcc: {metrics["pixel_acc"]*100:.2f}% | mIoU: {metrics["miou"]*100:.2f}%', 
                     fontsize=14, fontweight='bold')
        
        # åŸå§‹å›¾åƒ
        axes[0, 0].imshow(original_img)
        axes[0, 0].set_title('Original Image')
        axes[0, 0].axis('off')
        
        # çœŸå®mask
        axes[0, 1].imshow(gt_mask, cmap='gray')
        axes[0, 1].set_title('Ground Truth Mask')
        axes[0, 1].axis('off')
        
        # é¢„æµ‹mask
        axes[0, 2].imshow(pred_mask, cmap='gray')
        axes[0, 2].set_title('Predicted Mask')
        axes[0, 2].axis('off')
        
        # åŸå›¾+çœŸå®mask overlay
        gt_overlay = np.array(original_img).copy()
        gt_colored = np.zeros_like(gt_overlay)
        gt_colored[:, :, 1] = gt_mask * 255  # ç»¿è‰²è¡¨ç¤ºçœŸå®è½¦é“çº¿
        gt_result = cv2.addWeighted(gt_overlay, 0.7, gt_colored, 0.3, 0)
        axes[1, 0].imshow(gt_result)
        axes[1, 0].set_title('GT Overlay (Green)')
        axes[1, 0].axis('off')
        
        # åŸå›¾+é¢„æµ‹mask overlay
        pred_overlay = np.array(original_img).copy()
        pred_colored = np.zeros_like(pred_overlay)
        pred_colored[:, :, 0] = pred_mask * 255  # çº¢è‰²è¡¨ç¤ºé¢„æµ‹è½¦é“çº¿
        pred_result = cv2.addWeighted(pred_overlay, 0.7, pred_colored, 0.3, 0)
        axes[1, 1].imshow(pred_result)
        axes[1, 1].set_title('Prediction Overlay (Red)')
        axes[1, 1].axis('off')
        
        # è¯¯å·®åˆ†æ
        error_map = np.zeros_like(gt_mask)
        # True Positive: ç»¿è‰² (é¢„æµ‹å¯¹çš„è½¦é“çº¿)
        # False Positive: çº¢è‰² (é”™è¯¯é¢„æµ‹çš„è½¦é“çº¿) 
        # False Negative: è“è‰² (æ¼æ£€çš„è½¦é“çº¿)
        
        tp = (pred_mask == 1) & (gt_mask == 1)  # æ­£ç¡®é¢„æµ‹çš„è½¦é“çº¿
        fp = (pred_mask == 1) & (gt_mask == 0)  # é”™è¯¯é¢„æµ‹çš„è½¦é“çº¿
        fn = (pred_mask == 0) & (gt_mask == 1)  # æ¼æ£€çš„è½¦é“çº¿
        
        error_rgb = np.zeros((*error_map.shape, 3), dtype=np.uint8)
        error_rgb[tp] = [0, 255, 0]   # TP: ç»¿è‰²
        error_rgb[fp] = [255, 0, 0]   # FP: çº¢è‰²  
        error_rgb[fn] = [0, 0, 255]   # FN: è“è‰²
        
        axes[1, 2].imshow(error_rgb)
        axes[1, 2].set_title('Error Analysis\nGreen:TP, Red:FP, Blue:FN')
        axes[1, 2].axis('off')
        
        plt.tight_layout()
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        plt.close()
    
    def test_specific_images(self):
        """æµ‹è¯•æ‰€æœ‰20.jpgå›¾åƒ"""
        print("\nğŸ” Starting specific image testing...")
        
        # æŸ¥æ‰¾æ‰€æœ‰20.jpgå›¾åƒ
        image_paths, mask_paths = self.find_20jpg_images()
        
        if len(image_paths) == 0:
            print("âŒ No valid 20.jpg images found!")
            return
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_dir = './test_20jpg_random50_results'
        os.makedirs(output_dir, exist_ok=True)
        
        # ç»Ÿè®¡ä¿¡æ¯
        all_metrics = []
        total_inference_time = 0
        
        print(f"\nğŸ“Š Processing {len(image_paths)} images...")
        
        for i, (img_path, mask_path) in enumerate(zip(image_paths, mask_paths)):
            print(f"\nProcessing [{i+1}/{len(image_paths)}]: {os.path.basename(os.path.dirname(img_path))}/20.jpg")
            
            try:
                # åŠ è½½å›¾åƒå’Œmask
                image_tensor, original_img, original_size = self.load_image(img_path)
                gt_mask = self.load_mask(mask_path)
                
                # é¢„æµ‹
                pred_mask, inference_time = self.predict_image(image_tensor)
                total_inference_time += inference_time
                
                # è°ƒæ•´é¢„æµ‹ç»“æœå°ºå¯¸åˆ°åŸå§‹å°ºå¯¸
                if pred_mask.shape != gt_mask.shape:
                    pred_mask = cv2.resize(pred_mask.astype(np.uint8), 
                                         (gt_mask.shape[1], gt_mask.shape[0]), 
                                         interpolation=cv2.INTER_NEAREST)
                
                # è®¡ç®—æŒ‡æ ‡
                pixel_acc, miou, ious = self.calculate_metrics(pred_mask, gt_mask)
                
                metrics = {
                    'pixel_acc': pixel_acc,
                    'miou': miou,
                    'iou_bg': ious[0],
                    'iou_lane': ious[1],
                    'inference_time': inference_time
                }
                all_metrics.append(metrics)
                
                # åˆ›å»ºå¯è§†åŒ–
                folder_name = os.path.basename(os.path.dirname(img_path))
                save_path = os.path.join(output_dir, f'{folder_name}_20jpg_result.png')
                self.create_comparison_plot(original_img, gt_mask, pred_mask, metrics, save_path)
                
                print(f"   PixAcc: {pixel_acc*100:.2f}% | mIoU: {miou*100:.2f}% | Lane IoU: {ious[1]*100:.2f}% | Time: {inference_time*1000:.1f}ms")
                
            except Exception as e:
                print(f"   âŒ Error processing {img_path}: {str(e)}")
                continue
        
        # ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
        self.generate_report(all_metrics, output_dir)
        
        print(f"\nğŸ‰ Testing completed! Results saved to: {output_dir}")
    
    def generate_report(self, all_metrics, output_dir):
        """ç”Ÿæˆè¯¦ç»†çš„æµ‹è¯•æŠ¥å‘Š"""
        if not all_metrics:
            print("âŒ No valid results to generate report")
            return
        
        # è®¡ç®—ç»Ÿè®¡æ•°æ®
        pixel_accs = [m['pixel_acc'] for m in all_metrics]
        mious = [m['miou'] for m in all_metrics]
        lane_ious = [m['iou_lane'] for m in all_metrics]
        bg_ious = [m['iou_bg'] for m in all_metrics]
        inference_times = [m['inference_time'] for m in all_metrics]
        
        # ç»Ÿè®¡ç»“æœ
        stats = {
            'num_samples': len(all_metrics),
            'avg_pixel_acc': np.mean(pixel_accs),
            'std_pixel_acc': np.std(pixel_accs),
            'avg_miou': np.mean(mious),
            'std_miou': np.std(mious),
            'avg_lane_iou': np.mean(lane_ious),
            'std_lane_iou': np.std(lane_ious),
            'avg_bg_iou': np.mean(bg_ious),
            'std_bg_iou': np.std(bg_ious),
            'avg_inference_time': np.mean(inference_times),
            'total_inference_time': np.sum(inference_times),
            'fps': 1.0 / np.mean(inference_times)
        }
        
        # åˆ›å»ºç»Ÿè®¡å›¾è¡¨
        self.create_statistics_plot(stats, pixel_accs, mious, lane_ious, inference_times, output_dir)
        
        # ç”Ÿæˆæ–‡æœ¬æŠ¥å‘Š
        report_path = os.path.join(output_dir, 'test_report.md')
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("# TUSimple Lane Segmentation Test Report (Random 50 x 20.jpg)\n\n")
            f.write(f"## æµ‹è¯•æ¦‚è¿°\n")
            f.write(f"- æµ‹è¯•æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"- æµ‹è¯•æ ·æœ¬æ•°: {stats['num_samples']} (éšæœºé€‰æ‹©)\n")
            f.write(f"- æ¨¡å‹: Fast-SCNN\n")
            f.write(f"- æ•°æ®é›†: TUSimple (20.jpg specific frames)\n")
            f.write(f"- éšæœºç§å­: 42 (å¯é‡å¤ç»“æœ)\n\n")
            
            f.write(f"## æ€§èƒ½æŒ‡æ ‡\n")
            f.write(f"### åˆ†å‰²ç²¾åº¦\n")
            f.write(f"- **å¹³å‡åƒç´ å‡†ç¡®ç‡**: {stats['avg_pixel_acc']*100:.3f}% Â± {stats['std_pixel_acc']*100:.3f}%\n")
            f.write(f"- **å¹³å‡mIoU**: {stats['avg_miou']*100:.3f}% Â± {stats['std_miou']*100:.3f}%\n")
            f.write(f"- **è½¦é“çº¿IoU**: {stats['avg_lane_iou']*100:.3f}% Â± {stats['std_lane_iou']*100:.3f}%\n")
            f.write(f"- **èƒŒæ™¯IoU**: {stats['avg_bg_iou']*100:.3f}% Â± {stats['std_bg_iou']*100:.3f}%\n\n")
            
            f.write(f"### æ¨ç†æ€§èƒ½\n")
            f.write(f"- **å¹³å‡æ¨ç†æ—¶é—´**: {stats['avg_inference_time']*1000:.2f}ms\n")
            f.write(f"- **æ¨ç†FPS**: {stats['fps']:.1f}\n")
            f.write(f"- **æ€»æ¨ç†æ—¶é—´**: {stats['total_inference_time']:.2f}s\n\n")
            
            f.write(f"## è¯¦ç»†ç»“æœ\n")
            f.write(f"| åºå· | åƒç´ å‡†ç¡®ç‡(%) | mIoU(%) | è½¦é“çº¿IoU(%) | æ¨ç†æ—¶é—´(ms) |\n")
            f.write(f"|------|---------------|---------|--------------|-------------|\n")
            
            for i, m in enumerate(all_metrics):
                f.write(f"| {i+1:2d} | {m['pixel_acc']*100:11.2f} | {m['miou']*100:7.2f} | {m['iou_lane']*100:10.2f} | {m['inference_time']*1000:9.1f} |\n")
            
            f.write(f"\n## åˆ†æç»“è®º\n")
            if stats['avg_miou'] > 0.7:
                conclusion = "ä¼˜ç§€"
            elif stats['avg_miou'] > 0.6:
                conclusion = "è‰¯å¥½"
            else:
                conclusion = "ä¸€èˆ¬"
            
            f.write(f"- **æ€»ä½“è¯„ä»·**: {conclusion} (mIoU: {stats['avg_miou']*100:.2f}%)\n")
            f.write(f"- **è½¦é“çº¿æ£€æµ‹æ•ˆæœ**: {'ä¼˜ç§€' if stats['avg_lane_iou'] > 0.6 else 'è‰¯å¥½' if stats['avg_lane_iou'] > 0.4 else 'ä¸€èˆ¬'}\n")
            f.write(f"- **å®æ—¶æ€§**: {'æ»¡è¶³å®æ—¶è¦æ±‚' if stats['fps'] > 10 else 'æ¥è¿‘å®æ—¶' if stats['fps'] > 5 else 'éœ€è¦ä¼˜åŒ–'}\n")
            f.write(f"- **ç¨³å®šæ€§**: {'ç¨³å®š' if stats['std_miou'] < 0.1 else 'ä¸­ç­‰' if stats['std_miou'] < 0.2 else 'ä¸ç¨³å®š'}\n")
        
        print(f"\nğŸ“Š Test Statistics:")
        print(f"   Samples: {stats['num_samples']}")
        print(f"   Avg PixAcc: {stats['avg_pixel_acc']*100:.3f}% Â± {stats['std_pixel_acc']*100:.3f}%")
        print(f"   Avg mIoU: {stats['avg_miou']*100:.3f}% Â± {stats['std_miou']*100:.3f}%")
        print(f"   Avg Lane IoU: {stats['avg_lane_iou']*100:.3f}% Â± {stats['std_lane_iou']*100:.3f}%")
        print(f"   Avg Inference: {stats['avg_inference_time']*1000:.2f}ms ({stats['fps']:.1f} FPS)")
        print(f"   Report saved to: {report_path}")
    
    def create_statistics_plot(self, stats, pixel_accs, mious, lane_ious, inference_times, output_dir):
        """åˆ›å»ºç»Ÿè®¡å›¾è¡¨"""
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle('TUSimple Random 50x20.jpg Test Results Statistics', fontsize=16, fontweight='bold')
        
        # æŒ‡æ ‡åˆ†å¸ƒç›´æ–¹å›¾
        ax1.hist(np.array(mious)*100, bins=20, alpha=0.7, color='skyblue', edgecolor='black')
        ax1.axvline(stats['avg_miou']*100, color='red', linestyle='--', linewidth=2, label=f'Mean: {stats["avg_miou"]*100:.2f}%')
        ax1.set_xlabel('mIoU (%)')
        ax1.set_ylabel('Frequency')
        ax1.set_title('mIoU Distribution')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # åƒç´ å‡†ç¡®ç‡åˆ†å¸ƒ
        ax2.hist(np.array(pixel_accs)*100, bins=20, alpha=0.7, color='lightgreen', edgecolor='black')
        ax2.axvline(stats['avg_pixel_acc']*100, color='red', linestyle='--', linewidth=2, label=f'Mean: {stats["avg_pixel_acc"]*100:.2f}%')
        ax2.set_xlabel('Pixel Accuracy (%)')
        ax2.set_ylabel('Frequency')
        ax2.set_title('Pixel Accuracy Distribution')
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        
        # è½¦é“çº¿IoUåˆ†å¸ƒ
        ax3.hist(np.array(lane_ious)*100, bins=20, alpha=0.7, color='lightcoral', edgecolor='black')
        ax3.axvline(stats['avg_lane_iou']*100, color='red', linestyle='--', linewidth=2, label=f'Mean: {stats["avg_lane_iou"]*100:.2f}%')
        ax3.set_xlabel('Lane IoU (%)')
        ax3.set_ylabel('Frequency')
        ax3.set_title('Lane IoU Distribution')
        ax3.legend()
        ax3.grid(True, alpha=0.3)
        
        # æ¨ç†æ—¶é—´åˆ†å¸ƒ
        ax4.hist(np.array(inference_times)*1000, bins=20, alpha=0.7, color='orange', edgecolor='black')
        ax4.axvline(stats['avg_inference_time']*1000, color='red', linestyle='--', linewidth=2, label=f'Mean: {stats["avg_inference_time"]*1000:.1f}ms')
        ax4.set_xlabel('Inference Time (ms)')
        ax4.set_ylabel('Frequency')
        ax4.set_title('Inference Time Distribution')
        ax4.legend()
        ax4.grid(True, alpha=0.3)
        
        plt.tight_layout()
        stats_plot_path = os.path.join(output_dir, 'statistics_plot.png')
        plt.savefig(stats_plot_path, dpi=150, bbox_inches='tight')
        plt.close()
        
        print(f"   Statistics plot saved to: {stats_plot_path}")


def main():
    print("ğŸš— TUSimple Lane Segmentation - Random 50 Images Test (20.jpg)")
    print("=" * 65)
    
    # è®¾ç½®éšæœºç§å­ä»¥è·å¾—å¯é‡å¤çš„ç»“æœ
    random.seed(42)
    
    tester = TUSimpleSpecificTester()
    tester.test_specific_images()


if __name__ == '__main__':
    main()
