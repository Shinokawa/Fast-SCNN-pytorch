"""
Atlas NPUç«¯åˆ°ç«¯æ¨ç†ç¤ºä¾‹
å±•ç¤ºå¦‚ä½•ä½¿ç”¨é›†æˆé¢„å¤„ç†çš„ONNXæ¨¡å‹è¿›è¡Œé«˜æ•ˆè½¦é“çº¿æ£€æµ‹
"""
import cv2
import numpy as np
import time
import argparse
from pathlib import Path

try:
    import onnxruntime as ort
    ONNX_AVAILABLE = True
except ImportError:
    ONNX_AVAILABLE = False
    print("âš ï¸ onnxruntime not available. This is a demo script.")

class AtlasNPULaneDetector:
    """Atlas NPUè½¦é“çº¿æ£€æµ‹å™¨ï¼ˆç«¯åˆ°ç«¯ç‰ˆæœ¬ï¼‰"""
    
    def __init__(self, model_path, providers=None):
        """
        åˆå§‹åŒ–æ£€æµ‹å™¨
        Args:
            model_path: ONNXæ¨¡å‹è·¯å¾„
            providers: æ¨ç†æä¾›è€…åˆ—è¡¨
        """
        if not ONNX_AVAILABLE:
            print("âš ï¸ This is a demo class. Install onnxruntime for actual usage.")
            return
            
        if providers is None:
            # Atlas NPU: ä¼˜å…ˆä½¿ç”¨CUDA (NPU mapped to CUDA in some setups)
            providers = ['CUDAExecutionProvider', 'CPUExecutionProvider']
        
        self.session = ort.InferenceSession(model_path, providers=providers)
        self.input_name = self.session.get_inputs()[0].name
        self.output_name = self.session.get_outputs()[0].name
        
        # è·å–æ¨¡å‹è¾“å…¥è¾“å‡ºå°ºå¯¸
        input_shape = self.session.get_inputs()[0].shape
        output_shape = self.session.get_outputs()[0].shape
        
        self.input_height = input_shape[2]
        self.input_width = input_shape[3]
        self.num_classes = output_shape[1]
        
        print(f"âœ… Atlas NPUæ¨¡å‹åŠ è½½æˆåŠŸ!")
        print(f"   ğŸ“Š è¾“å…¥å°ºå¯¸: {self.input_height}x{self.input_width}")
        print(f"   ğŸ“Š è¾“å‡ºç±»åˆ«: {self.num_classes}")
        print(f"   ğŸ–¥ï¸ æ¨ç†æä¾›è€…: {self.session.get_providers()}")
    
    def preprocess_frame(self, frame):
        """
        é¢„å¤„ç†æ‘„åƒå¤´å¸§ (ç®€åŒ–ç‰ˆæœ¬ï¼Œå¤§éƒ¨åˆ†é¢„å¤„ç†å·²åœ¨æ¨¡å‹å†…éƒ¨)
        Args:
            frame: OpenCVå›¾åƒ (H, W, 3) BGRæ ¼å¼
        Returns:
            input_tensor: æ¨¡å‹è¾“å…¥å¼ é‡ (1, 3, H, W)
        """
        # è½¬æ¢BGR â†’ RGB
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        
        # è°ƒæ•´å°ºå¯¸ (å¦‚æœéœ€è¦)
        if frame_rgb.shape[:2] != (self.input_height, self.input_width):
            frame_rgb = cv2.resize(frame_rgb, (self.input_width, self.input_height))
        
        # è½¬æ¢ä¸ºå¼ é‡æ ¼å¼: (H, W, 3) â†’ (1, 3, H, W)
        input_tensor = frame_rgb.transpose(2, 0, 1)[np.newaxis].astype(np.float32)
        
        return input_tensor
    
    def postprocess_output(self, output):
        """
        åå¤„ç†æ¨¡å‹è¾“å‡º
        Args:
            output: æ¨¡å‹è¾“å‡º (1, num_classes, H, W)
        Returns:
            lane_mask: è½¦é“çº¿æ©ç  (H, W) [0-255]
            confidence: æ£€æµ‹ç½®ä¿¡åº¦
        """
        # è·å–æœ€å¤§æ¦‚ç‡ç±»åˆ«
        pred_mask = np.argmax(output[0], axis=0)  # (H, W)
        max_probs = np.max(output[0], axis=0)     # (H, W)
        
        # è½¬æ¢ä¸ºå¯è§†åŒ–æ ¼å¼
        lane_mask = np.zeros_like(pred_mask, dtype=np.uint8)
        lane_mask[pred_mask > 0] = 255  # éèƒŒæ™¯åŒºåŸŸè®¾ä¸º255
        
        # è®¡ç®—ç½®ä¿¡åº¦
        confidence = np.mean(max_probs)
        
        return lane_mask, confidence
    
    def detect_lanes(self, frame):
        """
        å•å¸§è½¦é“çº¿æ£€æµ‹
        Args:
            frame: OpenCVå›¾åƒ
        Returns:
            lane_mask: è½¦é“çº¿æ©ç 
            confidence: æ£€æµ‹ç½®ä¿¡åº¦
            inference_time: æ¨ç†æ—¶é—´(ms)
        """
        if not ONNX_AVAILABLE:
            # è¿”å›ç¤ºä¾‹ç»“æœ
            h, w = frame.shape[:2]
            lane_mask = np.zeros((h, w), dtype=np.uint8)
            return lane_mask, 0.5, 10.0
        
        # é¢„å¤„ç†
        input_tensor = self.preprocess_frame(frame)
        
        # NPUæ¨ç†
        start_time = time.time()
        output = self.session.run([self.output_name], {self.input_name: input_tensor})[0]
        inference_time = (time.time() - start_time) * 1000
        
        # åå¤„ç†
        lane_mask, confidence = self.postprocess_output(output)
        
        return lane_mask, confidence, inference_time
    
    def detect_batch(self, frames):
        """
        æ‰¹é‡æ£€æµ‹ï¼ˆå¦‚æœNPUæ”¯æŒï¼‰
        Args:
            frames: å¸§åˆ—è¡¨
        Returns:
            results: æ£€æµ‹ç»“æœåˆ—è¡¨
        """
        # æ‰¹é‡é¢„å¤„ç†
        batch_input = np.stack([self.preprocess_frame(frame)[0] for frame in frames])
        
        # æ‰¹é‡æ¨ç†
        start_time = time.time()
        batch_output = self.session.run([self.output_name], {self.input_name: batch_input})[0]
        total_time = (time.time() - start_time) * 1000
        
        # æ‰¹é‡åå¤„ç†
        results = []
        for i in range(len(frames)):
            lane_mask, confidence = self.postprocess_output(batch_output[i:i+1])
            results.append((lane_mask, confidence))
        
        avg_time = total_time / len(frames)
        return results, avg_time

def visualize_lanes(frame, lane_mask, confidence, inference_time):
    """
    å¯è§†åŒ–è½¦é“çº¿æ£€æµ‹ç»“æœ
    Args:
        frame: åŸå§‹å›¾åƒ
        lane_mask: è½¦é“çº¿æ©ç 
        confidence: æ£€æµ‹ç½®ä¿¡åº¦
        inference_time: æ¨ç†æ—¶é—´
    Returns:
        vis_frame: å¯è§†åŒ–ç»“æœ
    """
    vis_frame = frame.copy()
    
    # è°ƒæ•´æ©ç å°ºå¯¸åˆ°åŸå›¾å°ºå¯¸
    if lane_mask.shape != frame.shape[:2]:
        lane_mask = cv2.resize(lane_mask, (frame.shape[1], frame.shape[0]))
    
    # å åŠ è½¦é“çº¿ï¼ˆç»¿è‰²ï¼‰
    lane_overlay = np.zeros_like(frame)
    lane_overlay[lane_mask > 0] = [0, 255, 0]  # ç»¿è‰²è½¦é“çº¿
    vis_frame = cv2.addWeighted(vis_frame, 0.7, lane_overlay, 0.3, 0)
    
    # æ·»åŠ ä¿¡æ¯æ–‡æœ¬
    cv2.putText(vis_frame, f"Confidence: {confidence:.3f}", (10, 30), 
                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
    cv2.putText(vis_frame, f"Time: {inference_time:.1f}ms", (10, 60), 
                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
    cv2.putText(vis_frame, f"FPS: {1000/inference_time:.1f}", (10, 90), 
                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
    
    return vis_frame

def test_image_inference(detector, image_path, output_path=None):
    """æµ‹è¯•å•å¼ å›¾åƒæ¨ç†"""
    print(f"\nğŸ–¼ï¸ Testing image inference: {image_path}")
    
    # è¯»å–å›¾åƒ
    frame = cv2.imread(str(image_path))
    if frame is None:
        print(f"âŒ Failed to load image: {image_path}")
        return
    
    print(f"   ğŸ“Š Image size: {frame.shape}")
    
    # æ£€æµ‹è½¦é“çº¿
    lane_mask, confidence, inference_time = detector.detect_lanes(frame)
    
    print(f"âœ… Detection completed!")
    print(f"   âš¡ Inference time: {inference_time:.2f}ms")
    print(f"   ğŸ¯ Confidence: {confidence:.3f}")
    print(f"   ğŸš€ Theoretical FPS: {1000/inference_time:.1f}")
    
    # å¯è§†åŒ–ç»“æœ
    vis_frame = visualize_lanes(frame, lane_mask, confidence, inference_time)
    
    # ä¿å­˜ç»“æœ
    if output_path:
        cv2.imwrite(str(output_path), vis_frame)
        print(f"   ğŸ’¾ Result saved to: {output_path}")
    
    return vis_frame

def test_video_inference(detector, video_path, output_path=None, max_frames=None):
    """æµ‹è¯•è§†é¢‘æ¨ç†"""
    print(f"\nğŸ¥ Testing video inference: {video_path}")
    
    cap = cv2.VideoCapture(str(video_path))
    if not cap.isOpened():
        print(f"âŒ Failed to open video: {video_path}")
        return
    
    # è·å–è§†é¢‘ä¿¡æ¯
    fps = cap.get(cv2.CAP_PROP_FPS)
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    print(f"   ğŸ“Š Video info: {width}x{height}, {fps:.1f}FPS, {total_frames} frames")
    
    # è®¾ç½®è¾“å‡ºè§†é¢‘
    out = None
    if output_path:
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(str(output_path), fourcc, fps, (width, height))
    
    # å¤„ç†è§†é¢‘å¸§
    frame_count = 0
    total_time = 0
    confidences = []
    
    print("ğŸ”„ Processing frames...")
    
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        
        # æ£€æµ‹è½¦é“çº¿
        lane_mask, confidence, inference_time = detector.detect_lanes(frame)
        
        # ç»Ÿè®¡
        total_time += inference_time
        confidences.append(confidence)
        frame_count += 1
        
        # å¯è§†åŒ–
        vis_frame = visualize_lanes(frame, lane_mask, confidence, inference_time)
        
        # ä¿å­˜å¸§
        if out:
            out.write(vis_frame)
        
        # è¿›åº¦æ˜¾ç¤º
        if frame_count % 30 == 0:
            avg_time = total_time / frame_count
            print(f"   ğŸ“Š Processed {frame_count}/{total_frames} frames, "
                  f"Avg time: {avg_time:.1f}ms, Avg FPS: {1000/avg_time:.1f}")
        
        # é™åˆ¶å¤„ç†å¸§æ•°
        if max_frames and frame_count >= max_frames:
            break
    
    # æ¸…ç†èµ„æº
    cap.release()
    if out:
        out.release()
    
    # ç»Ÿè®¡ç»“æœ
    avg_time = total_time / frame_count
    avg_confidence = np.mean(confidences)
    
    print(f"âœ… Video processing completed!")
    print(f"   ğŸ“Š Processed frames: {frame_count}")
    print(f"   âš¡ Average inference time: {avg_time:.2f}ms")
    print(f"   ğŸš€ Average FPS: {1000/avg_time:.1f}")
    print(f"   ğŸ¯ Average confidence: {avg_confidence:.3f}")
    
    if output_path:
        print(f"   ğŸ’¾ Result video saved to: {output_path}")

def test_camera_inference(detector, camera_id=0, display=True):
    """æµ‹è¯•æ‘„åƒå¤´å®æ—¶æ¨ç†"""
    print(f"\nğŸ“· Testing camera inference (Camera ID: {camera_id})")
    
    cap = cv2.VideoCapture(camera_id)
    if not cap.isOpened():
        print(f"âŒ Failed to open camera: {camera_id}")
        return
    
    # è®¾ç½®æ‘„åƒå¤´å‚æ•°
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
    cap.set(cv2.CAP_PROP_FPS, 30)
    
    print("ğŸ”„ Starting real-time inference... Press 'q' to quit")
    
    frame_count = 0
    total_time = 0
    
    while True:
        ret, frame = cap.read()
        if not ret:
            continue
        
        # æ£€æµ‹è½¦é“çº¿
        lane_mask, confidence, inference_time = detector.detect_lanes(frame)
        
        # ç»Ÿè®¡
        total_time += inference_time
        frame_count += 1
        
        # å¯è§†åŒ–
        vis_frame = visualize_lanes(frame, lane_mask, confidence, inference_time)
        
        # æ˜¾ç¤º
        if display:
            cv2.imshow('Atlas NPU Lane Detection', vis_frame)
            
            # æŒ‰é”®æ§åˆ¶
            key = cv2.waitKey(1) & 0xFF
            if key == ord('q'):
                break
        
        # æ¯100å¸§è¾“å‡ºä¸€æ¬¡ç»Ÿè®¡
        if frame_count % 100 == 0:
            avg_time = total_time / frame_count
            print(f"   ğŸ“Š Frame {frame_count}: Avg time {avg_time:.1f}ms, Avg FPS {1000/avg_time:.1f}")
    
    # æ¸…ç†
    cap.release()
    if display:
        cv2.destroyAllWindows()
    
    avg_time = total_time / frame_count
    print(f"âœ… Camera inference completed!")
    print(f"   ğŸ“Š Total frames: {frame_count}")
    print(f"   âš¡ Average inference time: {avg_time:.2f}ms")
    print(f"   ğŸš€ Average FPS: {1000/avg_time:.1f}")

def main():
    parser = argparse.ArgumentParser(description='Atlas NPUç«¯åˆ°ç«¯è½¦é“çº¿æ£€æµ‹ç¤ºä¾‹')
    parser.add_argument('--model', type=str, required=True,
                        help='ç«¯åˆ°ç«¯ONNXæ¨¡å‹è·¯å¾„')
    parser.add_argument('--mode', type=str, choices=['image', 'video', 'camera'], 
                        default='image', help='æµ‹è¯•æ¨¡å¼')
    parser.add_argument('--input', type=str, help='è¾“å…¥æ–‡ä»¶è·¯å¾„ï¼ˆå›¾åƒæˆ–è§†é¢‘ï¼‰')
    parser.add_argument('--output', type=str, help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--camera-id', type=int, default=0, help='æ‘„åƒå¤´ID')
    parser.add_argument('--max-frames', type=int, help='æœ€å¤§å¤„ç†å¸§æ•°ï¼ˆè§†é¢‘æ¨¡å¼ï¼‰')
    parser.add_argument('--no-display', action='store_true', help='ä¸æ˜¾ç¤ºç»“æœ')
    
    args = parser.parse_args()
    
    print("ğŸš€ Atlas NPUç«¯åˆ°ç«¯è½¦é“çº¿æ£€æµ‹æµ‹è¯•")
    print("=" * 50)
    
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
    model_path = Path(args.model)
    if not model_path.exists():
        print(f"âŒ Model file not found: {model_path}")
        return
    
    # åˆå§‹åŒ–æ£€æµ‹å™¨
    print(f"ğŸ“¦ Loading model: {model_path.name}")
    detector = AtlasNPULaneDetector(str(model_path))
    
    # æ ¹æ®æ¨¡å¼è¿è¡Œæµ‹è¯•
    if args.mode == 'image':
        if not args.input:
            print("âŒ Image mode requires --input parameter")
            return
        test_image_inference(detector, args.input, args.output)
        
    elif args.mode == 'video':
        if not args.input:
            print("âŒ Video mode requires --input parameter")
            return
        test_video_inference(detector, args.input, args.output, args.max_frames)
        
    elif args.mode == 'camera':
        test_camera_inference(detector, args.camera_id, not args.no_display)
    
    print("\nğŸ‰ Test completed!")

if __name__ == '__main__':
    main()
