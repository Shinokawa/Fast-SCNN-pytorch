#!/usr/bin/env python3
"""
é€è§†å˜æ¢åº”ç”¨å·¥å…·

åŠŸèƒ½ç‰¹æ€§ï¼š
- åŠ è½½ç›¸æœºæ ‡å®šå‚æ•°
- å°†è¾“å…¥å›¾åƒè½¬æ¢ä¸ºé¸Ÿç°å›¾
- æ”¯æŒæ‰¹é‡å¤„ç†
- å¯è°ƒæ•´è¾“å‡ºå‚æ•°

ä½¿ç”¨æ–¹æ³•ï¼š
python perspective_transform.py --input image.jpg --calibration calibration.json --output bird_eye.jpg
python perspective_transform.py --input_dir images/ --calibration calibration.json --output_dir bird_eye_images/

ä½œè€…ï¼šç”¨äºè‡ªåŠ¨é©¾é©¶æ„ŸçŸ¥æ¨¡å—çš„é€è§†å˜æ¢
"""

import cv2
import numpy as np
import json
import argparse
import os
from pathlib import Path
import glob

class PerspectiveTransformer:
    def __init__(self, calibration_path):
        """
        åˆå§‹åŒ–é€è§†å˜æ¢å™¨
        
        å‚æ•°ï¼š
            calibration_path: æ ‡å®šæ–‡ä»¶è·¯å¾„
        """
        self.calibration_path = calibration_path
        self.load_calibration()
        
    def load_calibration(self):
        """åŠ è½½æ ‡å®šæ•°æ®"""
        if not os.path.exists(self.calibration_path):
            raise FileNotFoundError(f"æ ‡å®šæ–‡ä»¶ä¸å­˜åœ¨: {self.calibration_path}")
        
        with open(self.calibration_path, 'r', encoding='utf-8') as f:
            self.calibration_data = json.load(f)
        
        # æå–å…³é”®å‚æ•°
        self.transform_matrix = np.array(self.calibration_data['transform_matrix'], dtype=np.float32)
        self.inverse_transform_matrix = np.array(self.calibration_data['inverse_transform_matrix'], dtype=np.float32)
        self.image_points = self.calibration_data['image_points']
        self.world_points = self.calibration_data['world_points']
        self.original_image_size = self.calibration_data['image_size']
        
        print(f"âœ… æ ‡å®šæ•°æ®å·²åŠ è½½: {self.calibration_path}")
        print(f"ğŸ“ åŸå§‹å›¾åƒå°ºå¯¸: {self.original_image_size[0]} Ã— {self.original_image_size[1]}")
        print(f"ğŸ“ æ ‡å®šç‚¹æ•°: {len(self.image_points)}")
    
    def calculate_bird_eye_params(self, pixels_per_unit=20, margin_ratio=0.2):
        """
        è®¡ç®—é¸Ÿç°å›¾å‚æ•°
        
        å‚æ•°ï¼š
            pixels_per_unit: æ¯å•ä½çš„åƒç´ æ•°
            margin_ratio: è¾¹è·æ¯”ä¾‹
        
        è¿”å›ï¼š
            (output_width, output_height, combined_transform, view_bounds)
        """
        # è®¡ç®—ä¸–ç•Œåæ ‡èŒƒå›´
        world_points_array = np.array(self.world_points)
        min_x, min_y = world_points_array.min(axis=0)
        max_x, max_y = world_points_array.max(axis=0)
        
        # æ·»åŠ è¾¹è·
        range_x = max_x - min_x
        range_y = max_y - min_y
        margin = max(range_x, range_y) * margin_ratio
        
        min_x -= margin
        min_y -= margin
        max_x += margin
        max_y += margin
        
        # è®¡ç®—è¾“å‡ºå›¾åƒå°ºå¯¸
        output_width = int((max_x - min_x) * pixels_per_unit)
        output_height = int((max_y - min_y) * pixels_per_unit)
        
        # åˆ›å»ºä¸–ç•Œåæ ‡åˆ°åƒç´ åæ ‡çš„å˜æ¢çŸ©é˜µ
        world_to_pixel = np.array([
            [pixels_per_unit, 0, -min_x * pixels_per_unit],
            [0, pixels_per_unit, -min_y * pixels_per_unit],
            [0, 0, 1]
        ], dtype=np.float32)
        
        # ç»„åˆå˜æ¢çŸ©é˜µï¼šå›¾åƒåæ ‡ â†’ ä¸–ç•Œåæ ‡ â†’ åƒç´ åæ ‡
        combined_transform = world_to_pixel @ self.transform_matrix
        
        view_bounds = (min_x, min_y, max_x, max_y)
        
        return output_width, output_height, combined_transform, view_bounds
    
    def transform_image(self, image, pixels_per_unit=20, margin_ratio=0.2):
        """
        å°†å›¾åƒè½¬æ¢ä¸ºé¸Ÿç°å›¾
        
        å‚æ•°ï¼š
            image: è¾“å…¥å›¾åƒ (BGRæ ¼å¼)
            pixels_per_unit: æ¯å•ä½çš„åƒç´ æ•°
            margin_ratio: è¾¹è·æ¯”ä¾‹
        
        è¿”å›ï¼š
            bird_eye_image: é¸Ÿç°å›¾
            view_params: è§†å›¾å‚æ•°å­—å…¸
        """
        # è®¡ç®—é¸Ÿç°å›¾å‚æ•°
        output_width, output_height, combined_transform, view_bounds = \
            self.calculate_bird_eye_params(pixels_per_unit, margin_ratio)
        
        # å¦‚æœè¾“å…¥å›¾åƒå°ºå¯¸ä¸æ ‡å®šæ—¶ä¸åŒï¼Œéœ€è¦è°ƒæ•´å˜æ¢çŸ©é˜µ
        input_height, input_width = image.shape[:2]
        orig_width, orig_height = self.original_image_size
        
        if input_width != orig_width or input_height != orig_height:
            print(f"âš ï¸ å›¾åƒå°ºå¯¸ä¸åŒ¹é…: {input_width}Ã—{input_height} vs {orig_width}Ã—{orig_height}")
            print("ğŸ”„ è‡ªåŠ¨è°ƒæ•´å˜æ¢çŸ©é˜µ...")
            
            # è®¡ç®—ç¼©æ”¾å› å­
            scale_x = input_width / orig_width
            scale_y = input_height / orig_height
            
            # åˆ›å»ºç¼©æ”¾çŸ©é˜µ
            scale_matrix = np.array([
                [scale_x, 0, 0],
                [0, scale_y, 0],
                [0, 0, 1]
            ], dtype=np.float32)
            
            # è°ƒæ•´å˜æ¢çŸ©é˜µ
            adjusted_transform = combined_transform @ np.linalg.inv(scale_matrix)
            combined_transform = adjusted_transform
        
        # æ‰§è¡Œé€è§†å˜æ¢
        bird_eye_image = cv2.warpPerspective(
            image, combined_transform, 
            (output_width, output_height),
            flags=cv2.INTER_LINEAR,
            borderMode=cv2.BORDER_CONSTANT,
            borderValue=(0, 0, 0)
        )
        
        # å‡†å¤‡è§†å›¾å‚æ•°
        view_params = {
            'output_size': (output_width, output_height),
            'view_bounds': view_bounds,
            'pixels_per_unit': pixels_per_unit,
            'margin_ratio': margin_ratio,
            'transform_matrix': combined_transform.tolist()
        }
        
        return bird_eye_image, view_params
    
    def transform_point_to_bird_eye(self, image_x, image_y, pixels_per_unit=20, margin_ratio=0.2):
        """
        å°†å›¾åƒåæ ‡ç‚¹è½¬æ¢ä¸ºé¸Ÿç°å›¾åæ ‡
        
        å‚æ•°ï¼š
            image_x, image_y: å›¾åƒåæ ‡
            pixels_per_unit: æ¯å•ä½çš„åƒç´ æ•°
            margin_ratio: è¾¹è·æ¯”ä¾‹
        
        è¿”å›ï¼š
            (bird_x, bird_y): é¸Ÿç°å›¾åƒç´ åæ ‡
        """
        # è®¡ç®—é¸Ÿç°å›¾å‚æ•°
        _, _, combined_transform, _ = self.calculate_bird_eye_params(pixels_per_unit, margin_ratio)
        
        # å°†ç‚¹è½¬æ¢ä¸ºé½æ¬¡åæ ‡
        point_homo = np.array([[image_x, image_y, 1]], dtype=np.float32).T
        
        # åº”ç”¨å˜æ¢
        transformed_homo = combined_transform @ point_homo
        
        # è½¬æ¢å›ç¬›å¡å°”åæ ‡
        bird_x = int(transformed_homo[0, 0] / transformed_homo[2, 0])
        bird_y = int(transformed_homo[1, 0] / transformed_homo[2, 0])
        
        return bird_x, bird_y
    
    def add_grid_and_labels(self, bird_eye_image, view_params):
        """
        åœ¨é¸Ÿç°å›¾ä¸Šæ·»åŠ ç½‘æ ¼å’Œæ ‡ç­¾
        
        å‚æ•°ï¼š
            bird_eye_image: é¸Ÿç°å›¾
            view_params: è§†å›¾å‚æ•°
        
        è¿”å›ï¼š
            å¸¦ç½‘æ ¼çš„é¸Ÿç°å›¾
        """
        annotated_image = bird_eye_image.copy()
        
        min_x, min_y, max_x, max_y = view_params['view_bounds']
        pixels_per_unit = view_params['pixels_per_unit']
        output_width, output_height = view_params['output_size']
        
        # ç»˜åˆ¶ç½‘æ ¼
        grid_interval = 10  # ç½‘æ ¼é—´éš”ï¼ˆå•ä½ï¼‰
        grid_color = (128, 128, 128)  # ç°è‰²
        
        # å‚ç›´çº¿
        x = min_x
        while x <= max_x:
            if x % grid_interval == 0:
                pixel_x = int((x - min_x) * pixels_per_unit)
                if 0 <= pixel_x < output_width:
                    cv2.line(annotated_image, (pixel_x, 0), (pixel_x, output_height-1), grid_color, 1)
                    
                    # æ·»åŠ Xåæ ‡æ ‡ç­¾
                    if x != 0:  # é¿å…åœ¨åŸç‚¹é‡å¤æ ‡æ³¨
                        label = f"{int(x)}"
                        cv2.putText(annotated_image, label, (pixel_x + 2, 20),
                                   cv2.FONT_HERSHEY_SIMPLEX, 0.4, grid_color, 1)
            x += grid_interval / 2
        
        # æ°´å¹³çº¿
        y = min_y
        while y <= max_y:
            if y % grid_interval == 0:
                pixel_y = int((y - min_y) * pixels_per_unit)
                if 0 <= pixel_y < output_height:
                    cv2.line(annotated_image, (0, pixel_y), (output_width-1, pixel_y), grid_color, 1)
                    
                    # æ·»åŠ Yåæ ‡æ ‡ç­¾
                    if y != 0:  # é¿å…åœ¨åŸç‚¹é‡å¤æ ‡æ³¨
                        label = f"{int(y)}"
                        cv2.putText(annotated_image, label, (5, pixel_y - 5),
                                   cv2.FONT_HERSHEY_SIMPLEX, 0.4, grid_color, 1)
            y += grid_interval / 2
        
        # ç»˜åˆ¶åŸç‚¹
        origin_x = int((0 - min_x) * pixels_per_unit)
        origin_y = int((0 - min_y) * pixels_per_unit)
        
        if 0 <= origin_x < output_width and 0 <= origin_y < output_height:
            cv2.circle(annotated_image, (origin_x, origin_y), 5, (0, 0, 255), -1)
            cv2.putText(annotated_image, "O(0,0)", (origin_x + 8, origin_y - 8),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)
        
        # æ ‡è®°æ ‡å®šç‚¹
        for i, (world_x, world_y) in enumerate(self.world_points):
            pixel_x = int((world_x - min_x) * pixels_per_unit)
            pixel_y = int((world_y - min_y) * pixels_per_unit)
            
            if 0 <= pixel_x < output_width and 0 <= pixel_y < output_height:
                cv2.circle(annotated_image, (pixel_x, pixel_y), 3, (0, 255, 255), -1)
                cv2.putText(annotated_image, f"P{i+1}", (pixel_x + 5, pixel_y - 5),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 255, 255), 1)
        
        return annotated_image

def process_single_image(image_path, transformer, output_path=None, pixels_per_unit=20, 
                        margin_ratio=0.2, add_grid=False):
    """
    å¤„ç†å•å¼ å›¾åƒ
    
    å‚æ•°ï¼š
        image_path: è¾“å…¥å›¾åƒè·¯å¾„
        transformer: é€è§†å˜æ¢å™¨å¯¹è±¡
        output_path: è¾“å‡ºè·¯å¾„ï¼ˆå¯é€‰ï¼‰
        pixels_per_unit: æ¯å•ä½åƒç´ æ•°
        margin_ratio: è¾¹è·æ¯”ä¾‹
        add_grid: æ˜¯å¦æ·»åŠ ç½‘æ ¼
    
    è¿”å›ï¼š
        è¾“å‡ºæ–‡ä»¶è·¯å¾„
    """
    # è¯»å–å›¾åƒ
    image = cv2.imread(image_path)
    if image is None:
        raise ValueError(f"æ— æ³•è¯»å–å›¾åƒ: {image_path}")
    
    print(f"ğŸ”„ å¤„ç†å›¾åƒ: {image_path}")
    
    # æ‰§è¡Œé€è§†å˜æ¢
    bird_eye_image, view_params = transformer.transform_image(
        image, pixels_per_unit, margin_ratio)
    
    # æ·»åŠ ç½‘æ ¼ï¼ˆå¯é€‰ï¼‰
    if add_grid:
        bird_eye_image = transformer.add_grid_and_labels(bird_eye_image, view_params)
    
    # ç¡®å®šè¾“å‡ºè·¯å¾„
    if output_path is None:
        output_path = image_path.replace('.jpg', '_bird_eye.jpg').replace('.png', '_bird_eye.png')
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    output_dir = os.path.dirname(output_path)
    if output_dir and not os.path.exists(output_dir):
        os.makedirs(output_dir)
    
    # ä¿å­˜ç»“æœ
    cv2.imwrite(output_path, bird_eye_image)
    
    # æ‰“å°ä¿¡æ¯
    input_size = f"{image.shape[1]}Ã—{image.shape[0]}"
    output_size = f"{view_params['output_size'][0]}Ã—{view_params['output_size'][1]}"
    bounds = view_params['view_bounds']
    
    print(f"  ğŸ“ è¾“å…¥å°ºå¯¸: {input_size}")
    print(f"  ğŸ“ è¾“å‡ºå°ºå¯¸: {output_size}")
    print(f"  ğŸ“ ä¸–ç•ŒèŒƒå›´: X({bounds[0]:.1f}~{bounds[2]:.1f}), Y({bounds[1]:.1f}~{bounds[3]:.1f})")
    print(f"  ğŸ’¾ å·²ä¿å­˜: {output_path}")
    
    return output_path

def main():
    parser = argparse.ArgumentParser(description="é€è§†å˜æ¢åº”ç”¨å·¥å…·")
    parser.add_argument("--calibration", "-c", required=True, help="æ ‡å®šæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--input", "-i", help="è¾“å…¥å›¾åƒè·¯å¾„")
    parser.add_argument("--output", "-o", help="è¾“å‡ºå›¾åƒè·¯å¾„")
    parser.add_argument("--input_dir", help="è¾“å…¥ç›®å½•è·¯å¾„ï¼ˆæ‰¹é‡å¤„ç†ï¼‰")
    parser.add_argument("--output_dir", help="è¾“å‡ºç›®å½•è·¯å¾„ï¼ˆæ‰¹é‡å¤„ç†ï¼‰")
    parser.add_argument("--pixels_per_unit", type=int, default=20, help="æ¯å•ä½åƒç´ æ•° (é»˜è®¤: 20)")
    parser.add_argument("--margin_ratio", type=float, default=0.2, help="è¾¹è·æ¯”ä¾‹ (é»˜è®¤: 0.2)")
    parser.add_argument("--add_grid", action="store_true", help="æ·»åŠ ç½‘æ ¼å’Œæ ‡ç­¾")
    parser.add_argument("--preview", action="store_true", help="æ˜¾ç¤ºé¢„è§ˆçª—å£")
    
    args = parser.parse_args()
    
    try:
        # åˆ›å»ºé€è§†å˜æ¢å™¨
        print("ğŸ§® åŠ è½½é€è§†å˜æ¢å™¨...")
        transformer = PerspectiveTransformer(args.calibration)
        
        if args.input:
            # å•å›¾åƒå¤„ç†
            output_path = process_single_image(
                args.input, transformer, args.output,
                args.pixels_per_unit, args.margin_ratio, args.add_grid
            )
            
            # é¢„è§ˆï¼ˆå¯é€‰ï¼‰
            if args.preview:
                print("ğŸ‘ï¸ æ˜¾ç¤ºé¢„è§ˆ...")
                original = cv2.imread(args.input)
                bird_eye = cv2.imread(output_path)
                
                # ç¼©æ”¾ä»¥é€‚åº”å±å¹•
                max_width = 800
                if original.shape[1] > max_width:
                    scale = max_width / original.shape[1]
                    new_width = int(original.shape[1] * scale)
                    new_height = int(original.shape[0] * scale)
                    original = cv2.resize(original, (new_width, new_height))
                
                if bird_eye.shape[1] > max_width:
                    scale = max_width / bird_eye.shape[1]
                    new_width = int(bird_eye.shape[1] * scale)
                    new_height = int(bird_eye.shape[0] * scale)
                    bird_eye = cv2.resize(bird_eye, (new_width, new_height))
                
                cv2.imshow("Original Image", original)
                cv2.imshow("Bird's Eye View", bird_eye)
                print("æŒ‰ä»»æ„é”®å…³é—­é¢„è§ˆ...")
                cv2.waitKey(0)
                cv2.destroyAllWindows()
            
            print(f"âœ… å•å›¾åƒå¤„ç†å®Œæˆ: {output_path}")
            
        elif args.input_dir:
            # æ‰¹é‡å¤„ç†
            if not args.output_dir:
                args.output_dir = args.input_dir + "_bird_eye"
            
            print(f"ğŸ“ æ‰¹é‡å¤„ç†: {args.input_dir} â†’ {args.output_dir}")
            
            # æŸ¥æ‰¾å›¾åƒæ–‡ä»¶
            image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.bmp']
            image_files = []
            for ext in image_extensions:
                image_files.extend(glob.glob(os.path.join(args.input_dir, ext)))
                image_files.extend(glob.glob(os.path.join(args.input_dir, ext.upper())))
            
            if not image_files:
                print(f"âŒ åœ¨ç›®å½•ä¸­æœªæ‰¾åˆ°å›¾åƒæ–‡ä»¶: {args.input_dir}")
                return
            
            print(f"ğŸ“Š æ‰¾åˆ° {len(image_files)} ä¸ªå›¾åƒæ–‡ä»¶")
            
            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            if not os.path.exists(args.output_dir):
                os.makedirs(args.output_dir)
            
            # å¤„ç†æ¯ä¸ªå›¾åƒ
            for i, image_path in enumerate(image_files, 1):
                print(f"\n[{i}/{len(image_files)}]", end=" ")
                
                # ç¡®å®šè¾“å‡ºæ–‡ä»¶å
                input_name = os.path.basename(image_path)
                name, ext = os.path.splitext(input_name)
                output_name = f"{name}_bird_eye{ext}"
                output_path = os.path.join(args.output_dir, output_name)
                
                try:
                    process_single_image(
                        image_path, transformer, output_path,
                        args.pixels_per_unit, args.margin_ratio, args.add_grid
                    )
                except Exception as e:
                    print(f"  âŒ å¤„ç†å¤±è´¥: {e}")
            
            print(f"\nâœ… æ‰¹é‡å¤„ç†å®Œæˆï¼Œè¾“å‡ºç›®å½•: {args.output_dir}")
            
        else:
            print("âŒ è¯·æŒ‡å®šè¾“å…¥å›¾åƒ (--input) æˆ–è¾“å…¥ç›®å½• (--input_dir)")
            
    except Exception as e:
        print(f"âŒ å¤„ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
