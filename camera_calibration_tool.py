#!/usr/bin/env python3
"""
ç›¸æœºé€è§†å˜æ¢æ ‡å®šå·¥å…·

åŠŸèƒ½ç‰¹æ€§ï¼š
- äº¤äº’å¼é€‰æ‹©å›¾åƒä¸­çš„4ä¸ªç‚¹
- æ‰‹åŠ¨è¾“å…¥çœŸå®ä¸–ç•Œå¯¹åº”ç‚¹åæ ‡
- è®¡ç®—é€è§†å˜æ¢çŸ©é˜µ
- ç”Ÿæˆä¿¯è§†å›¾é¢„è§ˆ
- ä¿å­˜æ ‡å®šå‚æ•°

ä½¿ç”¨æ–¹æ³•ï¼š
python camera_calibration_tool.py --input kuruma/raw_collected_data/raw_images/raw_20250704_013409_372.jpg

æ“ä½œè¯´æ˜ï¼š
1. åœ¨å›¾åƒä¸Šç‚¹å‡»4ä¸ªç‚¹ï¼ˆæŒ‰é¡ºåºï¼šå·¦ä¸Šã€å³ä¸Šã€å³ä¸‹ã€å·¦ä¸‹ï¼‰
2. è¾“å…¥æ¯ä¸ªç‚¹åœ¨çœŸå®ä¸–ç•Œä¸­çš„åæ ‡ï¼ˆå•ä½ï¼šå˜ç±³æˆ–ç±³ï¼‰
3. é¢„è§ˆé€è§†å˜æ¢ç»“æœ
4. ä¿å­˜æ ‡å®šå‚æ•°åˆ°æ–‡ä»¶

æ³¨æ„ï¼šå»ºè®®é€‰æ‹©åœ°é¢ä¸Šçš„çŸ©å½¢æ ‡è®°ç‰©ï¼ˆå¦‚A4çº¸ï¼‰çš„å››ä¸ªè§’ç‚¹è¿›è¡Œæ ‡å®š
"""

import cv2
import numpy as np
import json
import argparse
import os
from pathlib import Path
import time

class CameraCalibrationTool:
    def __init__(self, image_path):
        """
        åˆå§‹åŒ–ç›¸æœºæ ‡å®šå·¥å…·
        
        å‚æ•°ï¼š
            image_path: è¾“å…¥å›¾åƒè·¯å¾„
        """
        self.image_path = image_path
        self.image = None
        self.display_image = None
        self.image_points = []  # å›¾åƒä¸­çš„ç‚¹
        self.world_points = []  # çœŸå®ä¸–ç•Œä¸­çš„ç‚¹
        self.transform_matrix = None
        self.window_name = "Camera Calibration Tool"
        
        # åŠ è½½å›¾åƒ
        self.load_image()
        
        # è®¾ç½®æ˜¾ç¤ºå‚æ•°
        self.point_color = (0, 0, 255)  # çº¢è‰²
        self.line_color = (0, 255, 0)   # ç»¿è‰²
        self.point_radius = 8
        self.line_thickness = 2
        
    def load_image(self):
        """åŠ è½½å¹¶å‡†å¤‡å›¾åƒ"""
        if not os.path.exists(self.image_path):
            raise FileNotFoundError(f"å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {self.image_path}")
        
        self.image = cv2.imread(self.image_path)
        if self.image is None:
            raise ValueError(f"æ— æ³•è¯»å–å›¾åƒ: {self.image_path}")
        
        # åˆ›å»ºæ˜¾ç¤ºå›¾åƒçš„å‰¯æœ¬
        self.display_image = self.image.copy()
        
        # è·å–å›¾åƒå°ºå¯¸
        self.height, self.width = self.image.shape[:2]
        print(f"ğŸ“ å›¾åƒå°ºå¯¸: {self.width} Ã— {self.height}")
        
        # å¦‚æœå›¾åƒå¤ªå¤§ï¼Œç¼©æ”¾ä»¥é€‚åº”å±å¹•
        max_display_width = 1200
        max_display_height = 800
        
        if self.width > max_display_width or self.height > max_display_height:
            scale_w = max_display_width / self.width
            scale_h = max_display_height / self.height
            self.display_scale = min(scale_w, scale_h)
            
            display_width = int(self.width * self.display_scale)
            display_height = int(self.height * self.display_scale)
            
            self.display_image = cv2.resize(self.display_image, (display_width, display_height))
            print(f"ğŸ“º æ˜¾ç¤ºå°ºå¯¸: {display_width} Ã— {display_height} (ç¼©æ”¾æ¯”ä¾‹: {self.display_scale:.2f})")
        else:
            self.display_scale = 1.0
            print("ğŸ“º æ˜¾ç¤ºå°ºå¯¸: åŸå§‹å°ºå¯¸")
    
    def mouse_callback(self, event, x, y, flags, param):
        """é¼ æ ‡ç‚¹å‡»å›è°ƒå‡½æ•°"""
        if event == cv2.EVENT_LBUTTONDOWN:
            if len(self.image_points) < 4:
                # å°†æ˜¾ç¤ºåæ ‡è½¬æ¢å›åŸå§‹å›¾åƒåæ ‡
                actual_x = int(x / self.display_scale)
                actual_y = int(y / self.display_scale)
                
                self.image_points.append((actual_x, actual_y))
                
                # åœ¨æ˜¾ç¤ºå›¾åƒä¸Šç»˜åˆ¶ç‚¹
                display_x = int(actual_x * self.display_scale)
                display_y = int(actual_y * self.display_scale)
                
                cv2.circle(self.display_image, (display_x, display_y), 
                          self.point_radius, self.point_color, -1)
                
                # æ·»åŠ ç‚¹åºå·æ ‡ç­¾
                point_num = len(self.image_points)
                cv2.putText(self.display_image, str(point_num), 
                           (display_x + 15, display_y - 15),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.8, self.point_color, 2)
                
                print(f"âœ… å·²é€‰æ‹©ç‚¹ {point_num}: ({actual_x}, {actual_y})")
                
                # å¦‚æœé€‰æ‹©äº†4ä¸ªç‚¹ï¼Œç»˜åˆ¶è¿çº¿
                if len(self.image_points) == 4:
                    self.draw_polygon()
                    print("ğŸ¯ å·²é€‰æ‹©4ä¸ªç‚¹ï¼Œè¯·æŒ‰ä»»æ„é”®ç»§ç»­è¾“å…¥çœŸå®ä¸–ç•Œåæ ‡...")
                
                cv2.imshow(self.window_name, self.display_image)
    
    def draw_polygon(self):
        """ç»˜åˆ¶é€‰ä¸­çš„4ä¸ªç‚¹æ„æˆçš„å¤šè¾¹å½¢"""
        if len(self.image_points) >= 4:
            # è½¬æ¢ä¸ºæ˜¾ç¤ºåæ ‡
            display_points = []
            for x, y in self.image_points[:4]:
                display_x = int(x * self.display_scale)
                display_y = int(y * self.display_scale)
                display_points.append((display_x, display_y))
            
            # ç»˜åˆ¶å¤šè¾¹å½¢
            pts = np.array(display_points, np.int32)
            pts = pts.reshape((-1, 1, 2))
            cv2.polylines(self.display_image, [pts], True, self.line_color, self.line_thickness)
    
    def input_world_coordinates(self):
        """è¾“å…¥çœŸå®ä¸–ç•Œåæ ‡"""
        print("\n" + "="*60)
        print("ğŸŒ è¯·è¾“å…¥çœŸå®ä¸–ç•Œåæ ‡")
        print("="*60)
        print("ğŸ“ è¯·æŒ‰ç…§é€‰æ‹©ç‚¹çš„é¡ºåºè¾“å…¥æ¯ä¸ªç‚¹åœ¨çœŸå®ä¸–ç•Œä¸­çš„åæ ‡")
        print("ğŸ“ å•ä½å¯ä»¥æ˜¯å˜ç±³(cm)æˆ–ç±³(m)ï¼Œè¯·ä¿æŒä¸€è‡´")
        print("ğŸ“ å»ºè®®ä½¿ç”¨çŸ©å½¢æ ‡è®°ç‰©ï¼ˆå¦‚A4çº¸ï¼š21cm Ã— 29.7cmï¼‰")
        print("-"*60)
        
        point_names = ["å·¦ä¸Šè§’", "å³ä¸Šè§’", "å³ä¸‹è§’", "å·¦ä¸‹è§’"]
        
        for i in range(4):
            print(f"\nğŸ“ ç‚¹ {i+1} ({point_names[i]}) - å›¾åƒåæ ‡: {self.image_points[i]}")
            
            while True:
                try:
                    x_input = input(f"  è¯·è¾“å…¥ X åæ ‡ (æ¨ªå‘): ")
                    y_input = input(f"  è¯·è¾“å…¥ Y åæ ‡ (çºµå‘): ")
                    
                    x_world = float(x_input)
                    y_world = float(y_input)
                    
                    self.world_points.append((x_world, y_world))
                    print(f"  âœ… çœŸå®ä¸–ç•Œåæ ‡: ({x_world}, {y_world})")
                    break
                    
                except ValueError:
                    print("  âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
        
        print("\nğŸ“Š æ ‡å®šç‚¹å¯¹åº”å…³ç³»:")
        print("-"*40)
        for i in range(4):
            img_pt = self.image_points[i]
            world_pt = self.world_points[i]
            print(f"{point_names[i]:8}: {img_pt} â†’ {world_pt}")
    
    def calculate_transform_matrix(self):
        """è®¡ç®—é€è§†å˜æ¢çŸ©é˜µ"""
        print("\nğŸ§® è®¡ç®—é€è§†å˜æ¢çŸ©é˜µ...")
        
        # è½¬æ¢ä¸ºnumpyæ•°ç»„
        src_points = np.float32(self.image_points)
        dst_points = np.float32(self.world_points)
        
        # è®¡ç®—é€è§†å˜æ¢çŸ©é˜µ
        self.transform_matrix = cv2.getPerspectiveTransform(src_points, dst_points)
        
        print("âœ… é€è§†å˜æ¢çŸ©é˜µè®¡ç®—å®Œæˆ!")
        print("\nğŸ“ é€è§†å˜æ¢çŸ©é˜µ:")
        print(self.transform_matrix)
        
        # è®¡ç®—é€†å˜æ¢çŸ©é˜µï¼ˆä»ä¸–ç•Œåæ ‡å›åˆ°å›¾åƒåæ ‡ï¼‰
        self.inverse_transform_matrix = cv2.getPerspectiveTransform(dst_points, src_points)
        
        return self.transform_matrix
    
    def preview_bird_eye_view(self):
        """é¢„è§ˆé¸Ÿç°å›¾æ•ˆæœ"""
        if self.transform_matrix is None:
            print("âŒ è¯·å…ˆè®¡ç®—å˜æ¢çŸ©é˜µ")
            return
        
        print("\nğŸ¦… ç”Ÿæˆé¸Ÿç°å›¾é¢„è§ˆ...")
        
        # è®¡ç®—è¾“å‡ºå›¾åƒå°ºå¯¸
        world_points_array = np.array(self.world_points)
        min_x, min_y = world_points_array.min(axis=0)
        max_x, max_y = world_points_array.max(axis=0)
        
        # æ·»åŠ è¾¹è·
        margin = max(max_x - min_x, max_y - min_y) * 0.2
        min_x -= margin
        min_y -= margin
        max_x += margin
        max_y += margin
        
        # è®¡ç®—åƒç´ /å•ä½æ¯”ä¾‹
        pixels_per_unit = 20  # æ¯å•ä½20åƒç´ 
        
        output_width = int((max_x - min_x) * pixels_per_unit)
        output_height = int((max_y - min_y) * pixels_per_unit)
        
        print(f"ğŸ“ é¸Ÿç°å›¾å°ºå¯¸: {output_width} Ã— {output_height}")
        print(f"ğŸ“ èŒƒå›´: X({min_x:.1f} ~ {max_x:.1f}), Y({min_y:.1f} ~ {max_y:.1f})")
        
        # åˆ›å»ºå˜æ¢çŸ©é˜µï¼ˆä»å›¾åƒåˆ°é¸Ÿç°å›¾åƒç´ åæ ‡ï¼‰
        # éœ€è¦å…ˆå˜æ¢åˆ°ä¸–ç•Œåæ ‡ï¼Œå†å˜æ¢åˆ°åƒç´ åæ ‡
        world_to_pixel = np.array([
            [pixels_per_unit, 0, -min_x * pixels_per_unit],
            [0, pixels_per_unit, -min_y * pixels_per_unit],
            [0, 0, 1]
        ], dtype=np.float32)
        
        # ç»„åˆå˜æ¢çŸ©é˜µ
        combined_transform = world_to_pixel @ self.transform_matrix
        
        # æ‰§è¡Œé€è§†å˜æ¢
        bird_eye_view = cv2.warpPerspective(self.image, combined_transform, 
                                          (output_width, output_height))
        
        # åœ¨é¸Ÿç°å›¾ä¸Šæ ‡è®°æ ‡å®šç‚¹
        for i, (x_world, y_world) in enumerate(self.world_points):
            pixel_x = int((x_world - min_x) * pixels_per_unit)
            pixel_y = int((y_world - min_y) * pixels_per_unit)
            
            cv2.circle(bird_eye_view, (pixel_x, pixel_y), 5, (0, 255, 255), -1)
            cv2.putText(bird_eye_view, str(i+1), (pixel_x + 10, pixel_y - 10),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
        
        # æ˜¾ç¤ºé¸Ÿç°å›¾
        cv2.imshow("Bird's Eye View Preview", bird_eye_view)
        
        # ä¿å­˜é¢„è§ˆå›¾
        preview_path = self.image_path.replace('.jpg', '_bird_eye_preview.jpg')
        cv2.imwrite(preview_path, bird_eye_view)
        print(f"ğŸ’¾ é¸Ÿç°å›¾é¢„è§ˆå·²ä¿å­˜: {preview_path}")
        
        return bird_eye_view, (min_x, min_y, max_x, max_y, pixels_per_unit)
    
    def save_calibration_data(self, output_path=None):
        """ä¿å­˜æ ‡å®šæ•°æ®"""
        if output_path is None:
            output_path = self.image_path.replace('.jpg', '_calibration.json')
        
        calibration_data = {
            'image_path': self.image_path,
            'image_size': [self.width, self.height],
            'image_points': self.image_points,
            'world_points': self.world_points,
            'transform_matrix': self.transform_matrix.tolist(),
            'inverse_transform_matrix': self.inverse_transform_matrix.tolist(),
            'calibration_time': time.strftime('%Y-%m-%d %H:%M:%S'),
            'description': 'ç›¸æœºé€è§†å˜æ¢æ ‡å®šæ•°æ®'
        }
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(calibration_data, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ’¾ æ ‡å®šæ•°æ®å·²ä¿å­˜: {output_path}")
        return output_path
    
    def run_calibration(self):
        """è¿è¡Œå®Œæ•´çš„æ ‡å®šæµç¨‹"""
        print("ğŸ¯ ç›¸æœºé€è§†å˜æ¢æ ‡å®šå·¥å…·")
        print("="*50)
        print("ğŸ“‹ æ“ä½œè¯´æ˜:")
        print("1. åœ¨å›¾åƒä¸Šä¾æ¬¡ç‚¹å‡»4ä¸ªç‚¹ï¼ˆå»ºè®®é€‰æ‹©çŸ©å½¢æ ‡è®°ç‰©çš„å››ä¸ªè§’ï¼‰")
        print("2. ç‚¹å‡»é¡ºåºï¼šå·¦ä¸Š â†’ å³ä¸Š â†’ å³ä¸‹ â†’ å·¦ä¸‹")
        print("3. è¾“å…¥æ¯ä¸ªç‚¹åœ¨çœŸå®ä¸–ç•Œä¸­çš„åæ ‡")
        print("4. é¢„è§ˆé¸Ÿç°å›¾æ•ˆæœ")
        print("5. ä¿å­˜æ ‡å®šå‚æ•°")
        print("-"*50)
        print("ğŸ’¡ æç¤ºï¼šå»ºè®®ä½¿ç”¨A4çº¸ç­‰çŸ©å½¢æ ‡è®°ç‰©è¿›è¡Œæ ‡å®š")
        print("ğŸ’¡ A4çº¸å°ºå¯¸ï¼š21.0cm Ã— 29.7cm")
        print("ğŸ’¡ æŒ‰ESCé”®é€€å‡ºï¼ŒæŒ‰Ré”®é‡æ–°å¼€å§‹")
        print("="*50)
        
        # è®¾ç½®é¼ æ ‡å›è°ƒ
        cv2.namedWindow(self.window_name, cv2.WINDOW_AUTOSIZE)
        cv2.setMouseCallback(self.window_name, self.mouse_callback)
        
        # æ˜¾ç¤ºå›¾åƒ
        cv2.imshow(self.window_name, self.display_image)
        
        # ç­‰å¾…ç”¨æˆ·é€‰æ‹©4ä¸ªç‚¹
        while len(self.image_points) < 4:
            key = cv2.waitKey(1) & 0xFF
            if key == 27:  # ESCé”®
                print("âŒ ç”¨æˆ·å–æ¶ˆæ ‡å®š")
                cv2.destroyAllWindows()
                return None
            elif key == ord('r') or key == ord('R'):  # Ré”®é‡æ–°å¼€å§‹
                print("ğŸ”„ é‡æ–°å¼€å§‹æ ‡å®š...")
                self.image_points = []
                self.world_points = []
                self.display_image = self.image.copy()
                if self.display_scale != 1.0:
                    display_width = int(self.width * self.display_scale)
                    display_height = int(self.height * self.display_scale)
                    self.display_image = cv2.resize(self.display_image, (display_width, display_height))
                cv2.imshow(self.window_name, self.display_image)
        
        # ç­‰å¾…ç”¨æˆ·æŒ‰é”®ç»§ç»­
        cv2.waitKey(0)
        cv2.destroyWindow(self.window_name)
        
        # è¾“å…¥çœŸå®ä¸–ç•Œåæ ‡
        self.input_world_coordinates()
        
        # è®¡ç®—å˜æ¢çŸ©é˜µ
        self.calculate_transform_matrix()
        
        # é¢„è§ˆé¸Ÿç°å›¾
        bird_eye_view, view_params = self.preview_bird_eye_view()
        
        # è¯¢é—®æ˜¯å¦ä¿å­˜
        while True:
            save_choice = input("\nğŸ’¾ æ˜¯å¦ä¿å­˜æ ‡å®šæ•°æ®ï¼Ÿ (y/n): ").lower()
            if save_choice in ['y', 'yes', 'æ˜¯']:
                calibration_file = self.save_calibration_data()
                break
            elif save_choice in ['n', 'no', 'å¦']:
                print("âŒ æ ‡å®šæ•°æ®æœªä¿å­˜")
                calibration_file = None
                break
            else:
                print("è¯·è¾“å…¥ y æˆ– n")
        
        # æ˜¾ç¤ºæœ€ç»ˆç»“æœ
        print("\n" + "="*60)
        print("ğŸ‰ æ ‡å®šå®Œæˆ!")
        print("="*60)
        print("ğŸ“Š æ ‡å®šç»“æœæ‘˜è¦:")
        print(f"ğŸ–¼ï¸  è¾“å…¥å›¾åƒ: {self.image_path}")
        print(f"ğŸ“ å›¾åƒå°ºå¯¸: {self.width} Ã— {self.height}")
        print(f"ğŸ“ æ ‡å®šç‚¹æ•°: {len(self.image_points)}")
        
        if calibration_file:
            print(f"ğŸ’¾ æ ‡å®šæ–‡ä»¶: {calibration_file}")
        
        print("\nğŸ”§ ç”¨æ³•ç¤ºä¾‹:")
        print("# åŠ è½½æ ‡å®šæ•°æ®")
        print("import json")
        print("import cv2")
        print("import numpy as np")
        print(f"with open('{calibration_file}', 'r') as f:")
        print("    calib = json.load(f)")
        print("transform_matrix = np.array(calib['transform_matrix'])")
        print("")
        print("# å°†å›¾åƒè½¬æ¢ä¸ºé¸Ÿç°å›¾")
        print("bird_eye = cv2.warpPerspective(image, combined_transform, (width, height))")
        
        # ç­‰å¾…ç”¨æˆ·æŸ¥çœ‹é¢„è§ˆ
        print("\næŒ‰ä»»æ„é”®å…³é—­é¢„è§ˆçª—å£...")
        cv2.waitKey(0)
        cv2.destroyAllWindows()
        
        return {
            'transform_matrix': self.transform_matrix,
            'inverse_transform_matrix': self.inverse_transform_matrix,
            'image_points': self.image_points,
            'world_points': self.world_points,
            'calibration_file': calibration_file,
            'view_params': view_params
        }

def main():
    parser = argparse.ArgumentParser(description="ç›¸æœºé€è§†å˜æ¢æ ‡å®šå·¥å…·")
    parser.add_argument("--input", "-i", required=True, help="è¾“å…¥å›¾åƒè·¯å¾„")
    parser.add_argument("--output", "-o", help="è¾“å‡ºæ ‡å®šæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰")
    
    args = parser.parse_args()
    
    try:
        # åˆ›å»ºæ ‡å®šå·¥å…·
        calibrator = CameraCalibrationTool(args.input)
        
        # è¿è¡Œæ ‡å®š
        result = calibrator.run_calibration()
        
        if result:
            print("\nâœ… æ ‡å®šæˆåŠŸå®Œæˆ!")
            
            # å¦‚æœæŒ‡å®šäº†è¾“å‡ºè·¯å¾„ï¼Œå¤åˆ¶æ–‡ä»¶
            if args.output and result['calibration_file']:
                import shutil
                shutil.copy2(result['calibration_file'], args.output)
                print(f"ğŸ“„ æ ‡å®šæ–‡ä»¶å·²å¤åˆ¶åˆ°: {args.output}")
        else:
            print("âŒ æ ‡å®šè¢«å–æ¶ˆæˆ–å¤±è´¥")
            
    except Exception as e:
        print(f"âŒ æ ‡å®šè¿‡ç¨‹å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
