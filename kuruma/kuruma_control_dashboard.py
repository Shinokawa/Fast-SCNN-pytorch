#!/usr/bin/env python3
"""
é›†æˆæ„ŸçŸ¥ä¸ç¯å¢ƒå»ºæ¨¡çš„è½¦é“çº¿åˆ†å‰²æ¨ç†è„šæœ¬ - Atlasç‰ˆæœ¬

åŠŸèƒ½ç‰¹æ€§ï¼š
- ä½¿ç”¨Atlas NPU (åä¸ºæ˜‡è…¾) è¿›è¡Œè½¦é“çº¿åˆ†å‰²æ¨ç†
- æ”¯æŒé€è§†å˜æ¢ï¼Œç”Ÿæˆé¸Ÿç°å›¾
- å¯è§†åŒ–å¯é©¾é©¶åŒºåŸŸçš„é¸Ÿç°å›¾
- ä¸ºè·¯å¾„è§„åˆ’æä¾›2Dåœ°å›¾æ•°æ®
- ğŸš— é›†æˆè§†è§‰æ¨ªå‘è¯¯å·®çš„æ¯”ä¾‹-é€Ÿåº¦è‡ªé€‚åº”å·®é€Ÿæ§åˆ¶ç®—æ³•
- å†…ç½®æ ‡å®šå‚æ•°ï¼Œå³å¼€å³ç”¨
- ğŸš€ å®æ—¶å¤„ç†æ€§èƒ½ä¼˜åŒ–ï¼Œæ”¯æŒæ—¥å¿—è¾“å‡º

ä½¿ç”¨æ–¹æ³•ï¼š
# åŸºç¡€æ¨ç†ï¼ˆä»…åˆ†å‰²ï¼‰
python kuruma_control_dashboard.py --input image.jpg --output result.jpg

# æ·»åŠ é€è§†å˜æ¢ç”Ÿæˆé¸Ÿç°å›¾
python kuruma_control_dashboard.py --input image.jpg --output result.jpg --bird_eye

# ç”Ÿæˆæ§åˆ¶ç”¨çš„é¸Ÿç°å›¾å’Œè·¯å¾„è§„åˆ’
python kuruma_control_dashboard.py --input image.jpg --bird_eye --save_control_map

# å¯ç”¨å®Œæ•´çš„è§†è§‰æ§åˆ¶ç®—æ³•
python kuruma_control_dashboard.py --input image.jpg --bird_eye --save_control_map --enable_control

# å®æ—¶æ‘„åƒå¤´æ¨¡å¼ï¼ˆæ¨èï¼‰
python kuruma_control_dashboard.py --realtime --log_file realtime_control.log

ä½œè€…ï¼šåŸºäºåŸç‰ˆæ‰©å±•ï¼Œé›†æˆAtlas NPUæ¨ç†å’Œå®æ—¶æ§åˆ¶
"""

import os
import sys
import cv2
import time
import numpy as np
import argparse
import json
import logging
from pathlib import Path
from threading import Thread, Lock
import queue
import base64
import io
from datetime import datetime

# Webç•Œé¢ç›¸å…³å¯¼å…¥
try:
    from flask import Flask, render_template_string, jsonify, request
    FLASK_AVAILABLE = True
except ImportError:
    FLASK_AVAILABLE = False
    print("âš ï¸ Flaskæœªå®‰è£…ï¼ŒWebç•Œé¢åŠŸèƒ½ä¸å¯ç”¨")

# å¯¼å…¥scipyç”¨äºè·¯å¾„å¹³æ»‘
try:
    from scipy.optimize import curve_fit
    from scipy.interpolate import UnivariateSpline
    SCIPY_AVAILABLE = True
except ImportError:
    print("âš ï¸ è­¦å‘Šï¼šæœªæ‰¾åˆ°scipyåº“ï¼Œè·¯å¾„å¹³æ»‘åŠŸèƒ½å°†ä¸å¯ç”¨")
    print("å®‰è£…å‘½ä»¤: pip install scipy")
    SCIPY_AVAILABLE = False

# å¯¼å…¥Atlasæ¨ç†åº“
try:
    from ais_bench.infer.interface import InferSession
    ATLAS_AVAILABLE = True
    print("âœ… Atlasæ¨ç†åº“åŠ è½½æˆåŠŸ")
except ImportError:
    print("âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ°ais_benchåº“ï¼Œè¯·å®‰è£…Atlasæ¨ç†ç¯å¢ƒ")
    print("å®‰è£…å‘½ä»¤: pip install ais_bench")
    sys.exit(1)

# ---------------------------------------------------------------------------------
# --- ğŸ”§ å†…ç½®æ ‡å®šå‚æ•° (åŸºäºç”¨æˆ·æä¾›çš„æ ‡å®šç‚¹) ---
# ---------------------------------------------------------------------------------

def get_builtin_calibration():
    """
    è·å–å†…ç½®çš„æ ‡å®šå‚æ•° (åŸºäºç”¨æˆ·æ ‡å®šçš„A4çº¸)
    
    æ ‡å®šä¿¡æ¯ï¼š
    - å›¾åƒå°ºå¯¸: 640Ã—360
    - æ ‡è®°ç‰©: A4çº¸ (21.0cm Ã— 29.7cm)
    - å›¾åƒç‚¹: [(260, 87), (378, 87), (410, 217), (231, 221)]
    - ä¸–ç•Œç‚¹: [(0, 0), (21, 0), (21, 29.7), (0, 29.7)]  # A4çº¸å››ä¸ªè§’
    """
    # å›¾åƒä¸­çš„4ä¸ªç‚¹ (åƒç´ åæ ‡)
    image_points = [(260, 87), (378, 87), (410, 217), (231, 221)]
    
    # çœŸå®ä¸–ç•Œä¸­çš„å¯¹åº”ç‚¹ (å˜ç±³) - A4çº¸çš„å››ä¸ªè§’
    world_points = [(0, 0), (21, 0), (21, 29.7), (0, 29.7)]
    
    # è®¡ç®—é€è§†å˜æ¢çŸ©é˜µ
    src_points = np.float32(image_points)
    dst_points = np.float32(world_points)
    
    transform_matrix = cv2.getPerspectiveTransform(src_points, dst_points)
    inverse_transform_matrix = cv2.getPerspectiveTransform(dst_points, src_points)
    
    calibration_data = {
        'image_size': [640, 360],
        'image_points': image_points,
        'world_points': world_points,
        'transform_matrix': transform_matrix.tolist(),
        'inverse_transform_matrix': inverse_transform_matrix.tolist(),
        'description': 'åŸºäºA4çº¸æ ‡å®šçš„é€è§†å˜æ¢å‚æ•°',
        'units': 'centimeters'
    }
    
    return calibration_data

def get_corrected_calibration():
    """
    è·å–æ ¡æ­£åçš„æ ‡å®šå‚æ•°ï¼Œç¡®ä¿640Ã—360åŸå§‹å›¾åƒåœ¨é¸Ÿç°å›¾ä¸­ä¸Šä¸‹è¾¹ç•Œå¹³è¡Œ
    
    æ ¸å¿ƒæ€è·¯ï¼š
    1. ä½¿ç”¨A4çº¸çš„4ä¸ªæ ‡å®šç‚¹ä½œä¸ºå‚è€ƒ
    2. è®¡ç®—æ•´ä¸ª640Ã—360å›¾åƒçš„4ä¸ªè§’ç‚¹åœ¨ä¸–ç•Œåæ ‡ä¸­çš„ä½ç½®
    3. å¼ºåˆ¶å›¾åƒçš„ä¸Šè¾¹ç•Œå’Œä¸‹è¾¹ç•Œåœ¨ä¸–ç•Œåæ ‡ä¸­Yå€¼ç›¸ç­‰ï¼ˆå¹³è¡Œï¼‰
    4. é‡æ–°è®¡ç®—æ ¡æ­£åçš„é€è§†å˜æ¢çŸ©é˜µ
    """
    # è·å–åŸå§‹æ ‡å®š
    original_cal = get_builtin_calibration()
    original_transform = np.array(original_cal['transform_matrix'], dtype=np.float32)
    
    # 640Ã—360å›¾åƒçš„å››ä¸ªè§’ç‚¹ï¼ˆåƒç´ åæ ‡ï¼‰
    img_corners = np.array([
        [0, 0, 1],           # å·¦ä¸Šè§’
        [639, 0, 1],         # å³ä¸Šè§’  
        [639, 359, 1],       # å³ä¸‹è§’
        [0, 359, 1]          # å·¦ä¸‹è§’
    ], dtype=np.float32)
    
    # ä½¿ç”¨åŸå§‹å˜æ¢å°†å›¾åƒè§’ç‚¹æŠ•å½±åˆ°ä¸–ç•Œåæ ‡
    world_corners = []
    for corner in img_corners:
        world_pt = original_transform @ corner
        world_x = world_pt[0] / world_pt[2]
        world_y = world_pt[1] / world_pt[2]
        world_corners.append([world_x, world_y])
    
    world_corners = np.array(world_corners)
    
    # æ ¡æ­£ä¸–ç•Œåæ ‡ï¼šå¼ºåˆ¶ä¸Šä¸‹è¾¹ç•Œå¹³è¡Œ
    # ä¸Šè¾¹ç•Œï¼šå·¦ä¸Šè§’å’Œå³ä¸Šè§’çš„Yåæ ‡å–å¹³å‡å€¼
    # ä¸‹è¾¹ç•Œï¼šå·¦ä¸‹è§’å’Œå³ä¸‹è§’çš„Yåæ ‡å–å¹³å‡å€¼
    top_y = (world_corners[0][1] + world_corners[1][1]) / 2  # ä¸Šè¾¹ç•ŒY
    bottom_y = (world_corners[2][1] + world_corners[3][1]) / 2  # ä¸‹è¾¹ç•ŒY
    
    # ä¿æŒXåæ ‡ä¸å˜ï¼Œåªæ ¡æ­£Yåæ ‡
    corrected_world_corners = [
        [world_corners[0][0], top_y],     # å·¦ä¸Šè§’
        [world_corners[1][0], top_y],     # å³ä¸Šè§’ - Yä¸å·¦ä¸Šè§’ç›¸åŒ
        [world_corners[2][0], bottom_y],  # å³ä¸‹è§’
        [world_corners[3][0], bottom_y]   # å·¦ä¸‹è§’ - Yä¸å³ä¸‹è§’ç›¸åŒ
    ]
    
    # é‡æ–°è®¡ç®—é€è§†å˜æ¢çŸ©é˜µ
    # ä»640Ã—360å›¾åƒè§’ç‚¹åˆ°æ ¡æ­£åçš„ä¸–ç•Œåæ ‡
    src_points = np.float32([[0, 0], [639, 0], [639, 359], [0, 359]])
    dst_points = np.float32(corrected_world_corners);
    
    transform_matrix = cv2.getPerspectiveTransform(src_points, dst_points)
    inverse_transform_matrix = cv2.getPerspectiveTransform(dst_points, src_points)
    
    # ä¿æŒåŸå§‹A4çº¸æ ‡å®šç‚¹ç”¨äºæ˜¾ç¤º
    corrected_calibration = {
        'image_size': [640, 360],
        'image_points': original_cal['image_points'],  # ä¿æŒA4çº¸æ ‡å®šç‚¹
        'world_points': original_cal['world_points'],  # ä¿æŒA4çº¸ä¸–ç•Œåæ ‡
        'transform_matrix': transform_matrix.tolist(),
        'inverse_transform_matrix': inverse_transform_matrix.tolist(),
        'corrected_world_corners': corrected_world_corners,
        'original_world_corners': world_corners.tolist(),
        'description': 'æ ¡æ­£åçš„é€è§†å˜æ¢å‚æ•°ï¼ˆç¡®ä¿640Ã—360å›¾åƒä¸Šä¸‹è¾¹ç•Œå¹³è¡Œï¼‰',
        'units': 'centimeters'
    }
    
    print(f"ğŸ”§ é€è§†æ ¡æ­£å®Œæˆ:")
    print(f"   - åŸå§‹ä¸Šè¾¹ç•ŒY: {world_corners[0][1]:.2f} ~ {world_corners[1][1]:.2f} cm")
    print(f"   - æ ¡æ­£ä¸Šè¾¹ç•ŒY: {top_y:.2f} cm (å¹³è¡Œ)")
    print(f"   - åŸå§‹ä¸‹è¾¹ç•ŒY: {world_corners[2][1]:.2f} ~ {world_corners[3][1]:.2f} cm") 
    print(f"   - æ ¡æ­£ä¸‹è¾¹ç•ŒY: {bottom_y:.2f} cm (å¹³è¡Œ)")
    
    return corrected_calibration

# ---------------------------------------------------------------------------------
# --- ğŸš€ğŸš€ğŸš€ å®Œç¾åŒ¹é…çš„é¢„å¤„ç† (640Ã—360 = 640Ã—360ï¼Œä¸Atlaså®Œå…¨ä¸€è‡´) ğŸš€ğŸš€ğŸš€ ---
# ---------------------------------------------------------------------------------

def preprocess_matched_resolution(img_bgr, target_width=640, target_height=360, dtype=np.float32):
    """
    å›¾ç‰‡é¢„å¤„ç†ï¼Œä¸atlas_single_image_inference.pyå’Œlane_dashboard_e2e.pyå®Œå…¨ä¸€è‡´
    
    è¾“å…¥ï¼šBGRå›¾åƒ (ä»»æ„å°ºå¯¸)
    è¾“å‡ºï¼šFloat32/Float16 NCHWå¼ é‡ (1, 3, 360, 640)
    
    å¤„ç†æµç¨‹ï¼š
    1. å¦‚æœè¾“å…¥å°ºå¯¸ä¸æ˜¯640Ã—360ï¼Œå…ˆresizeåˆ°640Ã—360
    2. BGR â†’ RGB
    3. uint8 â†’ float32/float16 (ä¿æŒ[0-255]èŒƒå›´)
    4. HWC â†’ CHWï¼Œæ·»åŠ batchç»´åº¦
    """
    # 1. è°ƒæ•´å°ºå¯¸åˆ°æ¨¡å‹è¾“å…¥è¦æ±‚
    height, width = img_bgr.shape[:2]
    if width != target_width or height != target_height:
        print(f"ğŸ“ Resize: {width}Ã—{height} â†’ {target_width}Ã—{target_height}")
        img_bgr = cv2.resize(img_bgr, (target_width, target_height), interpolation=cv2.INTER_LINEAR)
    else:
        print(f"ğŸ¯ å®Œç¾åŒ¹é…: {width}Ã—{height} = {target_width}Ã—{target_height}ï¼Œæ— éœ€resize!")
    
    # 2. è½¬æ¢é¢œè‰²é€šé“ (BGR â†’ RGB)
    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)
    
    # 3. è½¬æ¢æ•°æ®ç±»å‹ (uint8 â†’ float16ï¼Œä¿æŒ[0-255]èŒƒå›´)
    img_typed = img_rgb.astype(dtype)
    
    # 4. è½¬æ¢ä¸ºCHWæ ¼å¼å¹¶æ·»åŠ batchç»´åº¦ (H,W,C) â†’ (1,C,H,W)
    img_transposed = np.transpose(img_typed, (2, 0, 1))
    return np.ascontiguousarray(img_transposed[np.newaxis, :, :, :])

# ---------------------------------------------------------------------------------
# --- ğŸš€ğŸš€ğŸš€ æç®€åå¤„ç† (å°ºå¯¸å®Œç¾åŒ¹é…ï¼Œä¸Atlaså®Œå…¨ä¸€è‡´) ğŸš€ğŸš€ğŸš€ ---
# ---------------------------------------------------------------------------------

def postprocess_matched_resolution(output_tensor, original_width, original_height):
    """
    åå¤„ç†ï¼Œä¸atlas_single_image_inference.pyå’Œlane_dashboard_e2e.pyå®Œå…¨ä¸€è‡´
    
    è¾“å…¥ï¼šæ¨¡å‹è¾“å‡ºå¼ é‡ (1, num_classes, 360, 640)
    è¾“å‡ºï¼šåˆ†å‰²æ©ç  (original_height, original_width)
    
    å¤„ç†æµç¨‹ï¼š
    1. Argmaxè·å–åˆ†å‰²æ©ç 
    2. è½¬æ¢ä¸ºå¯è§†åŒ–æ ¼å¼
    3. å¦‚éœ€è¦ï¼Œresizeå›åŸå§‹å°ºå¯¸
    """
    # 1. Argmaxè·å–åˆ†å‰²æ©ç  (1, num_classes, H, W) â†’ (H, W)
    pred_mask = np.argmax(output_tensor, axis=1).squeeze()
    
    # 2. è½¬æ¢ä¸ºå¯è§†åŒ–æ ¼å¼ (0/1 â†’ 0/255)
    vis_mask = (pred_mask * 255).astype(np.uint8)
    
    # 3. å¦‚æœéœ€è¦ï¼Œresizeå›åŸå§‹å°ºå¯¸
    model_height, model_width = vis_mask.shape
    if original_width != model_width or original_height != model_height:
        print(f"ğŸ“ Resize back: {model_width}Ã—{model_height} â†’ {original_width}Ã—{original_height}")
        vis_mask = cv2.resize(vis_mask, (original_width, original_height), interpolation=cv2.INTER_NEAREST)
    else:
        print(f"ğŸ¯ è¾“å‡ºå°ºå¯¸åŒ¹é…: {model_width}Ã—{model_height} = {original_width}Ã—{original_height}")
    
    return vis_mask

# ---------------------------------------------------------------------------------
# --- ğŸ¨ å¯è§†åŒ–ç”Ÿæˆ (ä¸Atlaså®Œå…¨ä¸€è‡´) ---
# ---------------------------------------------------------------------------------

def create_visualization(original_img, mask, alpha=0.5):
    """
    åˆ›å»ºè½¦é“çº¿åˆ†å‰²å¯è§†åŒ–å›¾åƒï¼Œä¸atlas_single_image_inference.pyå®Œå…¨ä¸€è‡´
    
    å‚æ•°ï¼š
        original_img: åŸå§‹BGRå›¾åƒ
        mask: åˆ†å‰²æ©ç  (0/255)
        alpha: é€æ˜åº¦
    
    è¿”å›ï¼š
        å¯è§†åŒ–å›¾åƒ (BGRæ ¼å¼)
    """
    # åˆ›å»ºç»¿è‰²è¦†ç›–å±‚
    green_overlay = np.zeros_like(original_img, dtype=np.uint8)
    green_overlay[mask > 0] = [0, 255, 0]  # BGRæ ¼å¼çš„ç»¿è‰²
    
    # èåˆåŸå›¾å’Œè¦†ç›–å±‚
    vis_img = cv2.addWeighted(original_img, 1.0, green_overlay, alpha, 0)
    
    return vis_img

# ---------------------------------------------------------------------------------
# --- ğŸ§  Atlas NPUæ¨ç†ä¼šè¯ ---
# ---------------------------------------------------------------------------------

class AtlasInferSession:
    """Atlas NPUæ¨ç†ä¼šè¯ï¼Œå®Œå…¨å…¼å®¹åŸæœ‰æ¥å£"""
    
    def __init__(self, device_id, model_path):
        """
        åˆå§‹åŒ–Atlasæ¨ç†ä¼šè¯
        
        å‚æ•°ï¼š
            device_id: NPUè®¾å¤‡ID (é€šå¸¸ä¸º0)
            model_path: OMæ¨¡å‹è·¯å¾„
        """
        self.device_id = device_id
        self.model_path = model_path
        
        print(f"ğŸ§  ä½¿ç”¨Atlas NPUè®¾å¤‡: {device_id}")
        print(f"ğŸ“Š åŠ è½½OMæ¨¡å‹: {model_path}")
        
        # åˆ›å»ºæ¨ç†ä¼šè¯
        self.session = InferSession(device_id, model_path)
        
        print(f"âœ… Atlasæ¨ç†ä¼šè¯åˆå§‹åŒ–å®Œæˆ")
    
    def infer(self, inputs):
        """
        æ‰§è¡Œæ¨ç†ï¼Œä¸åŸæœ‰ONNXæ¥å£å®Œå…¨ä¸€è‡´
        
        å‚æ•°ï¼š
            inputs: è¾“å…¥å¼ é‡åˆ—è¡¨
        
        è¿”å›ï¼š
            outputs: è¾“å‡ºå¼ é‡åˆ—è¡¨
        """
        input_tensor = inputs[0]
        
        # æ‰§è¡ŒAtlasæ¨ç†
        outputs = self.session.infer([input_tensor])
        
        return outputs

# ---------------------------------------------------------------------------------
# --- ğŸ“Š æ€§èƒ½åˆ†æ (ä¸Atlaså®Œå…¨ä¸€è‡´) ---
# ---------------------------------------------------------------------------------

def print_performance_analysis(times_dict, input_tensor, model_path, device_info):
    """æ‰“å°è¯¦ç»†çš„æ€§èƒ½åˆ†ææŠ¥å‘Š"""
    total_time = sum(times_dict.values())
    
    print("\n" + "="*60)
    print("ğŸ§  Atlas NPU + é€è§†å˜æ¢ æ€§èƒ½åˆ†æ")
    print("="*60)
    print(f"ğŸ§  æ¨¡å‹: {Path(model_path).name}")
    print(f"âš¡ æ¨ç†è®¾å¤‡: {device_info}")
    print(f"ğŸ“ è¾“å…¥å°ºå¯¸: {input_tensor.shape[3]}Ã—{input_tensor.shape[2]} (WÃ—H)")
    print(f"ğŸ¯ æ•°æ®ç±»å‹: {str(input_tensor.dtype).upper()}")
    print("-"*60)
    
    for stage, time_ms in times_dict.items():
        percentage = (time_ms / total_time) * 100
        print(f"â±ï¸  {stage:15}: {time_ms:6.1f}ms ({percentage:5.1f}%)")
    
    print("-"*60)
    print(f"ğŸ æ€»è€—æ—¶: {total_time:.1f}ms")
    print(f"âš¡ ç†è®ºFPS: {1000/total_time:.1f}")
    print("="*60)

# ---------------------------------------------------------------------------------
# --- ğŸ“± ä¸»æ¨ç†å‡½æ•° (ä¸Atlasæµç¨‹å®Œå…¨ä¸€è‡´) ---
# ---------------------------------------------------------------------------------

def inference_single_image(image_path, model_path, device_id=0, 
                          save_visualization=True, save_mask=False, 
                          bird_eye=False, save_control_map=False,
                          pixels_per_unit=20, margin_ratio=0.1, full_image_bird_eye=False,
                          path_smooth_method='polynomial', path_degree=3, 
                          num_waypoints=20, min_road_width=10, edge_computing=False,
                          force_bottom_center=True, enable_control=False, 
                          steering_gain=1.0, base_speed=10.0, curvature_damping=0.1, 
                          preview_distance=30.0, max_speed=20.0, min_speed=5.0):
    """
    é›†æˆè½¦é“çº¿åˆ†å‰²æ¨ç†å’Œé€è§†å˜æ¢çš„å®Œæ•´æ„ŸçŸ¥ç®¡é“ - Atlasç‰ˆæœ¬
    
    å‚æ•°ï¼š
        image_path: è¾“å…¥å›¾ç‰‡è·¯å¾„
        model_path: OMæ¨¡å‹è·¯å¾„
        device_id: Atlas NPUè®¾å¤‡ID
        save_visualization: æ˜¯å¦ä¿å­˜æ™®é€šå¯è§†åŒ–ç»“æœ
        save_mask: æ˜¯å¦ä¿å­˜åˆ†å‰²æ©ç 
        bird_eye: æ˜¯å¦ç”Ÿæˆé¸Ÿç°å›¾
        save_control_map: æ˜¯å¦ä¿å­˜æ§åˆ¶åœ°å›¾
        pixels_per_unit: æ¯å•ä½åƒç´ æ•°
        margin_ratio: è¾¹è·æ¯”ä¾‹
        full_image_bird_eye: æ˜¯å¦ç”Ÿæˆå®Œæ•´åŸå›¾çš„é¸Ÿç°å›¾ï¼ˆå¦åˆ™ä»…A4çº¸åŒºåŸŸï¼‰
        path_smooth_method: è·¯å¾„å¹³æ»‘æ–¹æ³•
        path_degree: è·¯å¾„æ‹Ÿåˆé˜¶æ•°
        num_waypoints: è·¯å¾„ç‚¹æ•°é‡
        min_road_width: æœ€å°å¯è¡Œé©¶å®½åº¦
        edge_computing: è¾¹ç¼˜è®¡ç®—æ¨¡å¼ï¼ˆæè‡´æ€§èƒ½ä¼˜åŒ–ï¼‰
        force_bottom_center: å¼ºåˆ¶æ‹Ÿåˆæ›²çº¿è¿‡åº•è¾¹ä¸­ç‚¹
    
    è¿”å›ï¼š
        dict: åŒ…å«ç»“æœè·¯å¾„å’Œæ€§èƒ½æ•°æ®
    """
    # éªŒè¯è¾“å…¥æ–‡ä»¶
    if not os.path.exists(image_path):
        raise FileNotFoundError(f"è¾“å…¥å›¾ç‰‡ä¸å­˜åœ¨: {image_path}")
    
    if not os.path.exists(model_path):
        raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
    
    print(f"ğŸ–¼ï¸  åŠ è½½å›¾ç‰‡: {image_path}")
    
    # 1. åŠ è½½å›¾ç‰‡
    load_start = time.time()
    img_bgr = cv2.imread(image_path)
    if img_bgr is None:
        raise ValueError(f"æ— æ³•è¯»å–å›¾ç‰‡: {image_path}")
    
    original_height, original_width = img_bgr.shape[:2]
    load_time = (time.time() - load_start) * 1000
    
    print(f"ğŸ“ åŸå§‹å°ºå¯¸: {original_width}Ã—{original_height}")
    
    # 2. åŠ è½½Atlasæ¨¡å‹
    print(f"ğŸ§  åŠ è½½Atlas OMæ¨¡å‹: {model_path}")
    model_start = time.time()
    model = AtlasInferSession(device_id, model_path)
    model_load_time = (time.time() - model_start) * 1000
    print(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆ ({model_load_time:.1f}ms)")
    
    # 3. é¢„å¤„ç†ï¼ˆä½¿ç”¨float16ä»¥åŒ¹é…Atlasæ¨¡å‹ï¼‰
    print("ğŸ”„ å¼€å§‹é¢„å¤„ç†...")
    preprocess_start = time.time()
    input_data = preprocess_matched_resolution(img_bgr, dtype=np.float16)
    preprocess_time = (time.time() - preprocess_start) * 1000
    
    print(f"ğŸ“Š è¾“å…¥å¼ é‡å½¢çŠ¶: {input_data.shape}")
    print(f"ğŸ“Š æ•°æ®ç±»å‹: {input_data.dtype}")
    
    # 4. Atlas NPUæ¨ç†
    print("ğŸš€ å¼€å§‹Atlas NPUæ¨ç†...")
    inference_start = time.time()
    outputs = model.infer([input_data])
    inference_time = (time.time() - inference_start) * 1000
    
    print(f"ğŸ“Š è¾“å‡ºå¼ é‡å½¢çŠ¶: {outputs[0].shape}")
    
    # 5. åå¤„ç†
    print("ğŸ”„ å¼€å§‹åå¤„ç†...")
    postprocess_start = time.time()
    lane_mask = postprocess_matched_resolution(outputs[0], original_width, original_height)
    postprocess_time = (time.time() - postprocess_start) * 1000
    
    # 6. é€è§†å˜æ¢ï¼ˆå¯é€‰ï¼‰
    transform_time = 0
    path_planning_time = 0
    bird_eye_image = None
    bird_eye_mask = None
    control_map = None
    view_params = None
    
    if bird_eye:
        print("ğŸ¦… å¼€å§‹é€è§†å˜æ¢...")
        transform_start = time.time()
        
        # è¾¹ç¼˜è®¡ç®—ä¼˜åŒ–ï¼šå¤§å¹…é™ä½åƒç´ å¯†åº¦
        if edge_computing:
            if full_image_bird_eye:
                # è¾¹ç¼˜è®¡ç®—+å®Œæ•´å›¾åƒï¼šè¶…ä½åƒç´ å¯†åº¦
                adjusted_pixels_per_unit = 1  # å›ºå®š1åƒç´ /å•ä½ï¼Œå‡å°‘400å€è®¡ç®—é‡
                print(f"âš¡ è¾¹ç¼˜è®¡ç®—æè‡´ä¼˜åŒ–ï¼šåƒç´ å¯†åº¦ {pixels_per_unit} â†’ {adjusted_pixels_per_unit} åƒç´ /å•ä½")
            else:
                # è¾¹ç¼˜è®¡ç®—+A4åŒºåŸŸï¼šä½åƒç´ å¯†åº¦
                adjusted_pixels_per_unit = 2  # å›ºå®š2åƒç´ /å•ä½
                print(f"âš¡ è¾¹ç¼˜è®¡ç®—ä¼˜åŒ–ï¼šåƒç´ å¯†åº¦ {pixels_per_unit} â†’ {adjusted_pixels_per_unit} åƒç´ /å•ä½")
        else:
            if full_image_bird_eye:
                # å®Œæ•´å›¾åƒæ¨¡å¼ï¼šæä½åƒç´ å¯†åº¦ï¼ˆè¾¹ç¼˜è®¡ç®—å‹å¥½ï¼‰
                adjusted_pixels_per_unit = max(1, pixels_per_unit // 20)  # æœ€ä½1åƒç´ /å•ä½ï¼Œå‡å°‘400å€è®¡ç®—é‡
                print(f"ğŸš€ è¾¹ç¼˜è®¡ç®—ä¼˜åŒ–ï¼šåƒç´ å¯†åº¦ {pixels_per_unit} â†’ {adjusted_pixels_per_unit} åƒç´ /å•ä½ï¼ˆå‡å°‘{pixels_per_unit//adjusted_pixels_per_unit}å€è®¡ç®—é‡ï¼‰")
            else:
                # A4çº¸åŒºåŸŸæ¨¡å¼ï¼šä¸­ç­‰ä¼˜åŒ–
                adjusted_pixels_per_unit = max(2, pixels_per_unit // 4)  # æœ€ä½2åƒç´ /å•ä½
                print(f"ğŸ”§ æ€§èƒ½ä¼˜åŒ–ï¼šåƒç´ å¯†åº¦ {pixels_per_unit} â†’ {adjusted_pixels_per_unit} åƒç´ /å•ä½")
        
        transformer = PerspectiveTransformer()  # ä½¿ç”¨å†…ç½®æ ‡å®šå‚æ•°
        bird_eye_image, bird_eye_mask, view_params = transformer.transform_image_and_mask(
            img_bgr, lane_mask, adjusted_pixels_per_unit, margin_ratio, full_image=full_image_bird_eye)
        
        transform_time = (time.time() - transform_start) * 1000
        
        # 6.5. è·¯å¾„è§„åˆ’ï¼ˆå¯é€‰ï¼‰
        path_planning_time = 0
        if save_control_map:
            print("ğŸ›£ï¸ å¼€å§‹è·¯å¾„è§„åˆ’...")
            path_start = time.time()
            control_map, path_data = create_control_map(
                bird_eye_mask, view_params, add_grid=True, add_path=True,
                path_smooth_method=path_smooth_method,
                path_degree=path_degree,
                num_waypoints=num_waypoints,
                min_road_width=min_road_width,
                edge_computing=edge_computing,
                force_bottom_center=force_bottom_center
            )
            path_planning_time = (time.time() - path_start) * 1000
        else:
            path_data = None
        
        print(f"ğŸ“ é¸Ÿç°å›¾å°ºå¯¸: {view_params['output_size'][0]}Ã—{view_params['output_size'][1]}")
        bounds = view_params['view_bounds']
        print(f"ğŸ“ ä¸–ç•Œåæ ‡èŒƒå›´: X({bounds[0]:.1f}~{bounds[2]:.1f}), Y({bounds[1]:.1f}~{bounds[3]:.1f}) cm")
    
    # 7. ä¿å­˜ç»“æœ
    save_start = time.time()
    results = {}
    
    # ç¡®ä¿outputç›®å½•å­˜åœ¨
    output_dir = "output"
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
    
    # ç”ŸæˆåŸºç¡€æ–‡ä»¶åï¼ˆä¸å«è·¯å¾„å’Œæ‰©å±•åï¼‰
    base_name = os.path.splitext(os.path.basename(image_path))[0]
    
    # ä¿å­˜æ™®é€šåˆ†å‰²æ©ç 
    if save_mask:
        mask_path = os.path.join(output_dir, f"{base_name}_onnx_mask.jpg")
        cv2.imwrite(mask_path, lane_mask)
        results['mask_path'] = mask_path
        print(f"ğŸ’¾ åˆ†å‰²æ©ç å·²ä¿å­˜: {mask_path}")
    
    # ä¿å­˜æ™®é€šå¯è§†åŒ–ç»“æœ
    if save_visualization:
        vis_img = create_visualization(img_bgr, lane_mask)
        vis_path = os.path.join(output_dir, f"{base_name}_onnx_result.jpg")
        cv2.imwrite(vis_path, vis_img)
        results['visualization_path'] = vis_path
        print(f"ğŸ’¾ å¯è§†åŒ–ç»“æœå·²ä¿å­˜: {vis_path}")
    
    # ä¿å­˜é¸Ÿç°å›¾
    if bird_eye and bird_eye_image is not None:
        bird_eye_path = os.path.join(output_dir, f"{base_name}_bird_eye.jpg")
        cv2.imwrite(bird_eye_path, bird_eye_image)
        results['bird_eye_path'] = bird_eye_path
        print(f"ğŸ’¾ é¸Ÿç°å›¾å·²ä¿å­˜: {bird_eye_path}")
        
        # ä¿å­˜å¸¦åˆ†å‰²ç»“æœçš„é¸Ÿç°å›¾
        bird_eye_vis = create_visualization(bird_eye_image, bird_eye_mask)
        bird_eye_vis_path = os.path.join(output_dir, f"{base_name}_bird_eye_segmented.jpg")
        cv2.imwrite(bird_eye_vis_path, bird_eye_vis)
        results['bird_eye_vis_path'] = bird_eye_vis_path
        print(f"ğŸ’¾ é¸Ÿç°å›¾åˆ†å‰²å¯è§†åŒ–å·²ä¿å­˜: {bird_eye_vis_path}")
    
    # ä¿å­˜æ§åˆ¶åœ°å›¾
    if save_control_map and control_map is not None:
        control_map_path = os.path.join(output_dir, f"{base_name}_control_map.jpg")
        cv2.imwrite(control_map_path, control_map)
        results['control_map_path'] = control_map_path
        print(f"ğŸ’¾ æ§åˆ¶åœ°å›¾å·²ä¿å­˜: {control_map_path}")
        
        # ä¿å­˜è·¯å¾„æ•°æ®ä¸ºJSON
        if path_data is not None:
            path_json_path = os.path.join(output_dir, f"{base_name}_path_data.json")
            save_path_data_json(path_data, path_json_path)
            results['path_json_path'] = path_json_path
            print(f"ğŸ’¾ è·¯å¾„æ•°æ®å·²ä¿å­˜: {path_json_path}")
    
    # 7.5. è§†è§‰æ§åˆ¶ç®—æ³•ï¼ˆå¯é€‰ï¼‰
    control_result = None
    if enable_control and path_data is not None and view_params is not None:
        print("ğŸš— å¯åŠ¨è§†è§‰æ¨ªå‘è¯¯å·®æ§åˆ¶ç®—æ³•...")
        control_start = time.time()
        
        # åˆå§‹åŒ–æ§åˆ¶å™¨
        controller = VisualLateralErrorController(
            steering_gain=steering_gain,
            base_pwm=base_speed,  # é‡å‘½åå‚æ•°æ˜ å°„
            curvature_damping=curvature_damping,
            preview_distance=preview_distance,
            max_pwm=max_speed,    # é‡å‘½åå‚æ•°æ˜ å°„
            min_pwm=min_speed     # é‡å‘½åå‚æ•°æ˜ å°„
        )
        
        # è®¡ç®—æ§åˆ¶æŒ‡ä»¤
        control_result = controller.compute_wheel_pwm(path_data, view_params)
        
        # ç”Ÿæˆæ§åˆ¶å¯è§†åŒ–åœ°å›¾
        if control_map is not None:
            control_vis_map = controller.generate_control_visualization(
                control_map, control_result, view_params)
            control_vis_path = os.path.join(output_dir, f"{base_name}_control_visualization.jpg")
            cv2.imwrite(control_vis_path, control_vis_map)
            results['control_vis_path'] = control_vis_path
            print(f"ğŸ’¾ æ§åˆ¶å¯è§†åŒ–åœ°å›¾å·²ä¿å­˜: {control_vis_path}")
        
        # ä¿å­˜æ§åˆ¶æ•°æ®
        control_json_path = os.path.join(output_dir, f"{base_name}_control_data.json")
        controller.save_control_data(control_result, control_json_path)
        results['control_json_path'] = control_json_path
        print(f"ğŸ’¾ æ§åˆ¶æ•°æ®å·²ä¿å­˜: {control_json_path}")
        
        # æ‰“å°æ§åˆ¶åˆ†æ
        controller.print_control_analysis(control_result)
        
        control_time = (time.time() - control_start) * 1000
    else:
        control_time = 0
    
    save_time = (time.time() - save_start) * 1000
    
    # 8. æ€§èƒ½åˆ†æ
    times_dict = {
        "å›¾ç‰‡åŠ è½½": load_time,
        "æ¨¡å‹åŠ è½½": model_load_time,
        "CPUé¢„å¤„ç†": preprocess_time,
        "Atlasæ¨ç†": inference_time,
        "CPUåå¤„ç†": postprocess_time,
        "é€è§†å˜æ¢": transform_time,
        "è·¯å¾„è§„åˆ’": path_planning_time,
        "æ§åˆ¶è®¡ç®—": control_time,
        "ç»“æœä¿å­˜": save_time
    }
    
    print_performance_analysis(times_dict, input_data, model_path, f"Atlas NPU {device_id}")
    
    # 9. ç»Ÿè®¡è½¦é“çº¿åƒç´ 
    lane_pixels = np.sum(lane_mask > 0)
    total_pixels = lane_mask.shape[0] * lane_mask.shape[1]
    lane_ratio = (lane_pixels / total_pixels) * 100
    
    print(f"\nğŸ“ˆ æ£€æµ‹ç»“æœç»Ÿè®¡:")
    print(f"ğŸ›£ï¸  è½¦é“çº¿åƒç´ : {lane_pixels:,} / {total_pixels:,} ({lane_ratio:.2f}%)")
    
    if bird_eye_mask is not None:
        bird_lane_pixels = np.sum(bird_eye_mask > 0)
        bird_total_pixels = bird_eye_mask.shape[0] * bird_eye_mask.shape[1]
        bird_lane_ratio = (bird_lane_pixels / bird_total_pixels) * 100
        print(f"ğŸ¦… é¸Ÿç°å›¾è½¦é“çº¿åƒç´ : {bird_lane_pixels:,} / {bird_total_pixels:,} ({bird_lane_ratio:.2f}%)")
    
    results.update({
        'lane_pixels': lane_pixels,
        'total_pixels': total_pixels,
        'lane_ratio': lane_ratio,
        'performance': times_dict,
        'device': f"Atlas NPU {device_id}",
        'view_params': view_params,
        'control_result': control_result
    })
    
    return results

# ---------------------------------------------------------------------------------
# --- ğŸ¦… é€è§†å˜æ¢æ¨¡å— (é¸Ÿç°å›¾ç”Ÿæˆ) ---
# ---------------------------------------------------------------------------------

class PerspectiveTransformer:
    """é€è§†å˜æ¢å™¨ï¼Œç”¨äºç”Ÿæˆé¸Ÿç°å›¾"""
    
    def __init__(self, calibration_data=None, use_corrected=True):
        """
        åˆå§‹åŒ–é€è§†å˜æ¢å™¨
        
        å‚æ•°ï¼š
            calibration_data: æ ‡å®šæ•°æ®å­—å…¸ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨å†…ç½®æ ‡å®š
            use_corrected: æ˜¯å¦ä½¿ç”¨æ ¡æ­£åçš„æ ‡å®šï¼ˆç¡®ä¿çŸ©å½¢é¸Ÿç°å›¾ï¼‰
        """
        if calibration_data is None:
            if use_corrected:
                calibration_data = get_corrected_calibration()
                print("âœ… ä½¿ç”¨æ ¡æ­£åçš„æ ‡å®šå‚æ•°ï¼ˆç¡®ä¿çŸ©å½¢é¸Ÿç°å›¾ï¼‰")
            else:
                calibration_data = get_builtin_calibration()
                print("âš ï¸ ä½¿ç”¨åŸå§‹æ ‡å®šå‚æ•°ï¼ˆå¯èƒ½äº§ç”Ÿæ¢¯å½¢ï¼‰")
        
        self.calibration_data = calibration_data
        self.transform_matrix = np.array(calibration_data['transform_matrix'], dtype=np.float32)
        self.inverse_transform_matrix = np.array(calibration_data['inverse_transform_matrix'], dtype=np.float32)
        self.image_points = calibration_data['image_points']
        self.world_points = calibration_data['world_points']
        self.original_image_size = calibration_data['image_size']
        
        print(f"âœ… é€è§†å˜æ¢å™¨å·²åˆå§‹åŒ–")
        print(f"ğŸ“ æ ‡å®šå›¾åƒå°ºå¯¸: {self.original_image_size[0]} Ã— {self.original_image_size[1]}")
    
    def calculate_bird_eye_params(self, pixels_per_unit=20, margin_ratio=0.1, full_image=True):
        """
        è®¡ç®—é¸Ÿç°å›¾å‚æ•°
        
        å‚æ•°ï¼š
            pixels_per_unit: æ¯å•ä½çš„åƒç´ æ•°
            margin_ratio: è¾¹è·æ¯”ä¾‹
            full_image: æ˜¯å¦æ˜¾ç¤ºå®Œæ•´å›¾åƒçš„é¸Ÿç°å›¾
        """
        if full_image:
            # å°†æ•´ä¸ªå›¾åƒçš„å››ä¸ªè§’æŠ•å½±åˆ°ä¸–ç•Œåæ ‡
            img_width, img_height = self.original_image_size
            
            # å›¾åƒçš„å››ä¸ªè§’ç‚¹
            image_corners = np.array([
                [0, 0, 1],           # å·¦ä¸Šè§’
                [img_width-1, 0, 1], # å³ä¸Šè§’
                [img_width-1, img_height-1, 1], # å³ä¸‹è§’
                [0, img_height-1, 1] # å·¦ä¸‹è§’
            ], dtype=np.float32)
            
            # æŠ•å½±åˆ°ä¸–ç•Œåæ ‡
            world_corners = []
            for corner in image_corners:
                # åº”ç”¨é€è§†å˜æ¢
                world_pt = self.transform_matrix @ corner
                world_x = world_pt[0] / world_pt[2]
                world_y = world_pt[1] / world_pt[2]
                world_corners.append([world_x, world_y])
            
            world_corners = np.array(world_corners)
            
            # è®¡ç®—ä¸–ç•Œåæ ‡èŒƒå›´
            min_x, min_y = world_corners.min(axis=0)
            max_x, max_y = world_corners.max(axis=0)
            
            # æ·»åŠ è¾¹è·
            range_x = max_x - min_x
            range_y = max_y - min_y
            margin_x = range_x * margin_ratio
            margin_y = range_y * margin_ratio
            
            min_x -= margin_x
            min_y -= margin_y
            max_x += margin_x
            max_y += margin_y
            
        else:
            # åŸæ¥çš„æ–¹æ³•ï¼šåªåŸºäºæ ‡å®šç‚¹èŒƒå›´
            world_points_array = np.array(self.world_points)
            min_x, min_y = world_points_array.min(axis=0)
            max_x, max_y = world_points_array.max(axis=0)
            
            # æ·»åŠ è¾¹è·ï¼Œæ‰©å±•è§†é‡
            range_x = max_x - min_x
            range_y = max_y - min_y
            margin = max(range_x, range_y) * margin_ratio
            
            min_x -= margin
            min_y -= margin
            max_x += margin
            max_y += margin
        
        # è®¡ç®—è¾“å‡ºå›¾åƒå°ºå¯¸
        output_width = int((max_x - min_x) * pixels_per_unit)
        output_height = int((max_y - min_y) * pixels_per_unit)
        
        # åˆ›å»ºä¸–ç•Œåæ ‡åˆ°åƒç´ åæ ‡çš„å˜æ¢çŸ©é˜µ
        world_to_pixel = np.array([
            [pixels_per_unit, 0, -min_x * pixels_per_unit],
            [0, pixels_per_unit, -min_y * pixels_per_unit],
            [0, 0, 1]
        ], dtype=np.float32)
        
        # ç»„åˆå˜æ¢çŸ©é˜µï¼šå›¾åƒåæ ‡ â†’ ä¸–ç•Œåæ ‡ â†’ åƒç´ åæ ‡
        combined_transform = world_to_pixel @ self.transform_matrix
        
        view_bounds = (min_x, min_y, max_x, max_y)
        
        return output_width, output_height, combined_transform, view_bounds
    
    def transform_image_and_mask(self, image, mask, pixels_per_unit=20, margin_ratio=0.1, full_image=True):
        """
        å°†å›¾åƒå’Œåˆ†å‰²æ©ç éƒ½è½¬æ¢ä¸ºé¸Ÿç°å›¾
        
        å‚æ•°ï¼š
            image: è¾“å…¥å›¾åƒ (BGRæ ¼å¼)
            mask: åˆ†å‰²æ©ç  (0/255)
            pixels_per_unit: æ¯å•ä½çš„åƒç´ æ•°
            margin_ratio: è¾¹è·æ¯”ä¾‹
            full_image: æ˜¯å¦æ˜¾ç¤ºå®Œæ•´å›¾åƒçš„é¸Ÿç°å›¾
        
        è¿”å›ï¼š
            bird_eye_image: é¸Ÿç°å›¾
            bird_eye_mask: é¸Ÿç°å›¾åˆ†å‰²æ©ç 
            view_params: è§†å›¾å‚æ•°å­—å…¸
        """
        # è®¡ç®—é¸Ÿç°å›¾å‚æ•°ï¼ˆæ˜¾ç¤ºå®Œæ•´å›¾åƒï¼‰
        output_width, output_height, combined_transform, view_bounds = \
            self.calculate_bird_eye_params(pixels_per_unit, margin_ratio, full_image)
        
        # å¦‚æœè¾“å…¥å›¾åƒå°ºå¯¸ä¸æ ‡å®šæ—¶ä¸åŒï¼Œéœ€è¦è°ƒæ•´å˜æ¢çŸ©é˜µ
        input_height, input_width = image.shape[:2]
        orig_width, orig_height = self.original_image_size
        
        if input_width != orig_width or input_height != orig_height:
            print(f"âš ï¸ å›¾åƒå°ºå¯¸ä¸åŒ¹é…: {input_width}Ã—{input_height} vs {orig_width}Ã—{orig_height}")
            print("ğŸ”„ è‡ªåŠ¨è°ƒæ•´å˜æ¢çŸ©é˜µ...")
            
            # è®¡ç®—ç¼©æ”¾å› å­
            scale_x = input_width / orig_width
            scale_y = input_height / orig_height
            
            # åˆ›å»ºç¼©æ”¾çŸ©é˜µ
            scale_matrix = np.array([
                [scale_x, 0, 0],
                [0, scale_y, 0],
                [0, 0, 1]
            ], dtype=np.float32)
            
            # è°ƒæ•´å˜æ¢çŸ©é˜µ
            adjusted_transform = combined_transform @ np.linalg.inv(scale_matrix)
            combined_transform = adjusted_transform
        
        # æ‰§è¡Œé€è§†å˜æ¢ - å›¾åƒ
        bird_eye_image = cv2.warpPerspective(
            image, combined_transform, 
            (output_width, output_height),
            flags=cv2.INTER_LINEAR,
            borderMode=cv2.BORDER_CONSTANT,
            borderValue=(0, 0, 0)
        )
        
        # æ‰§è¡Œé€è§†å˜æ¢ - åˆ†å‰²æ©ç 
        bird_eye_mask = cv2.warpPerspective(
            mask, combined_transform, 
            (output_width, output_height),
            flags=cv2.INTER_NEAREST,  # ä½¿ç”¨æœ€è¿‘é‚»æ’å€¼ä¿æŒæ©ç çš„äºŒå€¼æ€§
            borderMode=cv2.BORDER_CONSTANT,
            borderValue=0
        )
        
        # å‡†å¤‡è§†å›¾å‚æ•°
        view_params = {
            'output_size': (output_width, output_height),
            'view_bounds': view_bounds,
            'pixels_per_unit': pixels_per_unit,
            'margin_ratio': margin_ratio,
            'transform_matrix': combined_transform.tolist(),
            'image_to_world_matrix': self.transform_matrix.tolist()  # å­˜å‚¨æ­£ç¡®çš„"å›¾åƒ->ä¸–ç•Œ"çŸ©é˜µ
        }
        
        return bird_eye_image, bird_eye_mask, view_params

# ---------------------------------------------------------------------------------
# --- ğŸ—ºï¸ æ§åˆ¶åœ°å›¾ç”Ÿæˆæ¨¡å— ---
# ---------------------------------------------------------------------------------

def create_control_map(bird_eye_mask, view_params, add_grid=True, add_path=True,
                      path_smooth_method='polynomial', path_degree=3, 
                      num_waypoints=20, min_road_width=10, edge_computing=False,
                      force_bottom_center=True):
    """
    åˆ›å»ºç”¨äºè·¯å¾„è§„åˆ’çš„æ§åˆ¶åœ°å›¾
    
    å‚æ•°ï¼š
        bird_eye_mask: é¸Ÿç°å›¾åˆ†å‰²æ©ç 
        view_params: è§†å›¾å‚æ•°
        add_grid: æ˜¯å¦æ·»åŠ ç½‘æ ¼
        add_path: æ˜¯å¦æ·»åŠ è·¯å¾„è§„åˆ’
        path_smooth_method: è·¯å¾„å¹³æ»‘æ–¹æ³•
        path_degree: è·¯å¾„æ‹Ÿåˆé˜¶æ•°
        num_waypoints: è·¯å¾„ç‚¹æ•°é‡
        min_road_width: æœ€å°å¯è¡Œé©¶å®½åº¦
        edge_computing: è¾¹ç¼˜è®¡ç®—æ¨¡å¼
        force_bottom_center: å¼ºåˆ¶æ‹Ÿåˆæ›²çº¿è¿‡åº•è¾¹ä¸­ç‚¹
    
    è¿”å›ï¼š
        control_map: æ§åˆ¶åœ°å›¾ (ä¸‰é€šé“BGRå›¾åƒ)
        path_data: è·¯å¾„è§„åˆ’æ•°æ®ï¼ˆå¦‚æœadd_path=Trueï¼‰
    """
    # åˆ›å»ºæ§åˆ¶åœ°å›¾
    control_map = np.zeros((bird_eye_mask.shape[0], bird_eye_mask.shape[1], 3), dtype=np.uint8)
    
    # å¯é©¾é©¶åŒºåŸŸ - ç»¿è‰²
    control_map[bird_eye_mask > 0] = [0, 255, 0]  # BGRç»¿è‰²
    
    # ä¸å¯é©¾é©¶åŒºåŸŸ - ä¿æŒé»‘è‰²
    # control_map[bird_eye_mask == 0] = [0, 0, 0]  # å·²ç»æ˜¯é»‘è‰²
    
    # è·¯å¾„è§„åˆ’
    path_data = None
    if add_path:
        try:
            planner = PathPlanner(view_params)
            path_data = planner.plan_complete_path(
                bird_eye_mask, 
                smooth_method=path_smooth_method,
                degree=path_degree,
                num_waypoints=num_waypoints,
                min_width=min_road_width,
                fast_mode=edge_computing,
                force_bottom_center=force_bottom_center
            )
            
            # åœ¨æ§åˆ¶åœ°å›¾ä¸Šå¯è§†åŒ–è·¯å¾„
            control_map = visualize_path_on_control_map(control_map, path_data, view_params)
            
            print(f"ğŸ›£ï¸ è·¯å¾„è§„åˆ’å®Œæˆ:")
            print(f"   - ä¸­å¿ƒçº¿ç‚¹æ•°: {path_data['num_centerline_points']}")
            print(f"   - è·¯å¾„ç‚¹æ•°: {path_data['num_waypoints']}")
            print(f"   - è·¯å¾„é•¿åº¦: {path_data['path_length']:.1f} cm")
            
        except Exception as e:
            print(f"âš ï¸ è·¯å¾„è§„åˆ’å¤±è´¥: {e}")
            path_data = None
    
    if add_grid:
        control_map = add_grid_to_control_map(control_map, view_params)
    
    return control_map, path_data

def add_grid_to_control_map(control_map, view_params):
    """
    åœ¨æ§åˆ¶åœ°å›¾ä¸Šæ·»åŠ ç½‘æ ¼å’Œåæ ‡æ ‡ç­¾
    
    å‚æ•°ï¼š
        control_map: æ§åˆ¶åœ°å›¾
        view_params: è§†å›¾å‚æ•°
    
    è¿”å›ï¼š
        å¸¦ç½‘æ ¼çš„æ§åˆ¶åœ°å›¾
    """
    annotated_map = control_map.copy()
    
    min_x, min_y, max_x, max_y = view_params['view_bounds']
    pixels_per_unit = view_params['pixels_per_unit']
    output_width, output_height = view_params['output_size']
    
    # ç»˜åˆ¶ç½‘æ ¼
    grid_interval = 10  # ç½‘æ ¼é—´éš”ï¼ˆå•ä½ï¼šcmï¼‰
    grid_color = (128, 128, 128)  # ç°è‰²
    origin_color = (0, 0, 255)    # çº¢è‰²åŸç‚¹
    
    # å‚ç›´çº¿
    x = min_x
    while x <= max_x:
        if abs(x % grid_interval) < 0.1:  # å¤„ç†æµ®ç‚¹æ•°ç²¾åº¦é—®é¢˜
            pixel_x = int((x - min_x) * pixels_per_unit)
            if 0 <= pixel_x < output_width:
                cv2.line(annotated_map, (pixel_x, 0), (pixel_x, output_height-1), grid_color, 1)
                
                # æ·»åŠ Xåæ ‡æ ‡ç­¾
                if abs(x) > 0.1:  # é¿å…åœ¨åŸç‚¹é‡å¤æ ‡æ³¨
                    label = f"{int(x)}"
                    cv2.putText(annotated_map, label, (pixel_x + 2, 20),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.4, grid_color, 1)
        x += grid_interval / 2
    
    # æ°´å¹³çº¿
    y = min_y
    while y <= max_y:
        if abs(y % grid_interval) < 0.1:  # å¤„ç†æµ®ç‚¹æ•°ç²¾åº¦é—®é¢˜
            pixel_y = int((y - min_y) * pixels_per_unit)
            if 0 <= pixel_y < output_height:
                cv2.line(annotated_map, (0, pixel_y), (output_width-1, pixel_y), grid_color, 1)
                
                # æ·»åŠ Yåæ ‡æ ‡ç­¾
                if abs(y) > 0.1:  # é¿å…åœ¨åŸç‚¹é‡å¤æ ‡æ³¨
                    label = f"{int(y)}"
                    cv2.putText(annotated_map, label, (5, pixel_y - 5),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.4, grid_color, 1)
        y += grid_interval / 2
    
    # ç»˜åˆ¶åŸç‚¹
    origin_x = int((0 - min_x) * pixels_per_unit)
    origin_y = int((0 - min_y) * pixels_per_unit)
    
    if 0 <= origin_x < output_width and 0 <= origin_y < output_height:
        cv2.circle(annotated_map, (origin_x, origin_y), 5, origin_color, -1)
        cv2.putText(annotated_map, "O(0,0)", (origin_x + 8, origin_y - 8),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, origin_color, 1)
    
    # æ ‡è®°A4çº¸çš„å››ä¸ªè§’
    for i, (world_x, world_y) in enumerate([(0, 0), (21, 0), (21, 29.7), (0, 29.7)]):
        pixel_x = int((world_x - min_x) * pixels_per_unit)
        pixel_y = int((world_y - min_y) * pixels_per_unit)
        
        if 0 <= pixel_x < output_width and 0 <= pixel_y < output_height:
            cv2.circle(annotated_map, (pixel_x, pixel_y), 3, (0, 255, 255), -1)
            cv2.putText(annotated_map, f"A4-{i+1}", (pixel_x + 5, pixel_y - 5),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.3, (0, 255, 255), 1)
    
    return annotated_map

# ---------------------------------------------------------------------------------
# --- ğŸ›£ï¸ è·¯å¾„è§„åˆ’æ¨¡å— ---
# ---------------------------------------------------------------------------------

class PathPlanner:
    """ä»é¸Ÿç°å›¾åˆ†å‰²æ©ç ä¸­æå–å’Œè§„åˆ’å¯è¡Œé©¶è·¯å¾„"""
    
    def __init__(self, view_params):
        """
        åˆå§‹åŒ–è·¯å¾„è§„åˆ’å™¨
        
        å‚æ•°ï¼š
            view_params: é¸Ÿç°å›¾è§†å›¾å‚æ•°
        """
        self.view_params = view_params
        self.pixels_per_unit = view_params['pixels_per_unit']
        self.view_bounds = view_params['view_bounds']
        
    def extract_centerline(self, bird_eye_mask, scan_from_bottom=True, min_width=10):
        """
        ä»é¸Ÿç°å›¾åˆ†å‰²æ©ç ä¸­æå–ä¸­å¿ƒçº¿
        
        å‚æ•°ï¼š
            bird_eye_mask: é¸Ÿç°å›¾åˆ†å‰²æ©ç 
            scan_from_bottom: æ˜¯å¦ä»å›¾åƒåº•éƒ¨å¼€å§‹æ‰«æ
            min_width: æœ€å°å¯è¡Œé©¶å®½åº¦ï¼ˆåƒç´ ï¼‰
        
        è¿”å›ï¼š
            centerline_points: ä¸­å¿ƒçº¿ç‚¹åˆ—è¡¨ [(x, y), ...]ï¼ˆåƒç´ åæ ‡ï¼‰
            centerline_world: ä¸­å¿ƒçº¿ç‚¹åˆ—è¡¨ï¼ˆä¸–ç•Œåæ ‡å˜ç±³ï¼‰
        """
        height, width = bird_eye_mask.shape
        centerline_points = []
        
        # ç¡®å®šæ‰«ææ–¹å‘
        rows = range(height-1, -1, -1) if scan_from_bottom else range(height)
        
        for y in rows:
            row = bird_eye_mask[y, :]
            
            # æ‰¾åˆ°è¯¥è¡Œæ‰€æœ‰å¯è¡Œé©¶åŒºåŸŸçš„è¿ç»­æ®µ
            segments = self._find_drivable_segments(row, min_width)
            
            if segments:
                # é€‰æ‹©æœ€å¤§çš„è¿ç»­æ®µï¼ˆé€šå¸¸æ˜¯ä¸»è·¯ï¼‰
                largest_segment = max(segments, key=lambda s: s[1] - s[0])
                
                # è®¡ç®—è¯¥æ®µçš„ä¸­å¿ƒç‚¹
                center_x = (largest_segment[0] + largest_segment[1]) // 2
                centerline_points.append((center_x, y))
        
        # è½¬æ¢ä¸ºä¸–ç•Œåæ ‡
        centerline_world = self._pixels_to_world(centerline_points)
        
        return centerline_points, centerline_world
    
    def extract_centerline_fast(self, bird_eye_mask, scan_from_bottom=True, min_width=5, skip_rows=5):
        """
        å¿«é€Ÿä¸­å¿ƒçº¿æå–ï¼ˆè¾¹ç¼˜è®¡ç®—ä¼˜åŒ–ç‰ˆæœ¬ï¼‰
        
        å‚æ•°ï¼š
            bird_eye_mask: é¸Ÿç°å›¾åˆ†å‰²æ©ç 
            scan_from_bottom: æ˜¯å¦ä»å›¾åƒåº•éƒ¨å¼€å§‹æ‰«æ
            min_width: æœ€å°å¯è¡Œé©¶å®½åº¦ï¼ˆåƒç´ ï¼‰
            skip_rows: è·³è¿‡è¡Œæ•°ï¼ˆå‡å°‘è®¡ç®—é‡ï¼‰
        
        è¿”å›ï¼š
            centerline_points: ä¸­å¿ƒçº¿ç‚¹åˆ—è¡¨ [(x, y), ...]ï¼ˆåƒç´ åæ ‡ï¼‰
            centerline_world: ä¸­å¿ƒçº¿ç‚¹åˆ—è¡¨ï¼ˆä¸–ç•Œåæ ‡å˜ç±³ï¼‰
        """
        height, width = bird_eye_mask.shape
        centerline_points = []
        
        # ç¡®å®šæ‰«ææ–¹å‘ï¼Œè·³è¡Œæ‰«æä»¥æé«˜é€Ÿåº¦
        if scan_from_bottom:
            rows = range(height-1, -1, -skip_rows)
        else:
            rows = range(0, height, skip_rows)
        
        for y in rows:
            row = bird_eye_mask[y, :]
            
            # å¿«é€Ÿæ‰¾åˆ°ä¸­å¿ƒç‚¹ï¼šä½¿ç”¨é‡å¿ƒæ³•
            drivable_indices = np.where(row > 0)[0]
            
            if len(drivable_indices) >= min_width:
                # è®¡ç®—é‡å¿ƒä½œä¸ºä¸­å¿ƒç‚¹
                center_x = int(np.mean(drivable_indices))
                centerline_points.append((center_x, y))
        
        # è½¬æ¢ä¸ºä¸–ç•Œåæ ‡
        centerline_world = self._pixels_to_world(centerline_points)
        
        return centerline_points, centerline_world
    
    def _find_drivable_segments(self, row, min_width):
        """
        åœ¨ä¸€è¡Œä¸­æ‰¾åˆ°æ‰€æœ‰å¯è¡Œé©¶åŒºåŸŸçš„è¿ç»­æ®µ
        
        å‚æ•°ï¼š
            row: å›¾åƒè¡Œæ•°æ®
            min_width: æœ€å°å®½åº¦
        
        è¿”å›ï¼š
            segments: è¿ç»­æ®µåˆ—è¡¨ [(start, end), ...]
        """
        segments = []
        start = None
        
        for i, pixel in enumerate(row):
            if pixel > 0:  # å¯è¡Œé©¶åŒºåŸŸ
                if start is None:
                    start = i
            else:  # ä¸å¯è¡Œé©¶åŒºåŸŸ
                if start is not None:
                    if i - start >= min_width:  # æ»¡è¶³æœ€å°å®½åº¦è¦æ±‚
                        segments.append((start, i))
                    start = None
        
        # å¤„ç†è¡Œæœ«å°¾çš„æƒ…å†µ
        if start is not None and len(row) - start >= min_width:
            segments.append((start, len(row)))
        
        return segments
    
    def _pixels_to_world(self, pixel_points):
        """
        å°†åƒç´ åæ ‡è½¬æ¢ä¸ºä¸–ç•Œåæ ‡
        
        å‚æ•°ï¼š
            pixel_points: åƒç´ åæ ‡ç‚¹åˆ—è¡¨ [(x, y), ...]
        
        è¿”å›ï¼š
            world_points: ä¸–ç•Œåæ ‡ç‚¹åˆ—è¡¨ [(x, y), ...]ï¼ˆå•ä½ï¼šå˜ç±³ï¼‰
        """
        min_x, min_y, max_x, max_y = self.view_bounds
        world_points = []
        
        for px, py in pixel_points:
            # åƒç´ åæ ‡è½¬ä¸–ç•Œåæ ‡
            world_x = min_x + (px / self.pixels_per_unit)
            world_y = min_y + (py / self.pixels_per_unit)
            world_points.append((world_x, world_y))
        
        return world_points
    
    def smooth_path(self, centerline_world, method='polynomial', degree=3, force_bottom_center=True):
        """
        å¯¹ä¸­å¿ƒçº¿è·¯å¾„è¿›è¡Œå¹³æ»‘å¤„ç† (å·²ä¿®æ­£ä¸ºæ‹Ÿåˆ x=f(y) å¹¶ä½¿ç”¨æƒé‡)
        
        å‚æ•°ï¼š
            centerline_world: ä¸–ç•Œåæ ‡ä¸­å¿ƒçº¿ç‚¹åˆ—è¡¨
            method: å¹³æ»‘æ–¹æ³• ('polynomial', 'spline')
            degree: å¤šé¡¹å¼é˜¶æ•°æˆ–æ ·æ¡é˜¶æ•°
            force_bottom_center: æ˜¯å¦å¼ºåˆ¶æ›²çº¿è¿‡åº•è¾¹ä¸­ç‚¹
        
        è¿”å›ï¼š
            smooth_path_func: å¹³æ»‘è·¯å¾„å‡½æ•° x = f(y)
            fit_params: æ‹Ÿåˆå‚æ•°
        """
        if not centerline_world or not SCIPY_AVAILABLE:
            return None, None
        
        points = np.array(centerline_world)
        # æ ¸å¿ƒä¿®æ­£1: æˆ‘ä»¬å°†Yä½œä¸ºè‡ªå˜é‡ï¼ŒXä½œä¸ºå› å˜é‡
        y_coords = points[:, 1]  # å‰è¿›æ–¹å‘
        x_coords = points[:, 0]  # å·¦å³åç§»

        # æŒ‰Yåæ ‡ï¼ˆå‰è¿›æ–¹å‘ï¼‰æ’åº
        sorted_indices = np.argsort(y_coords)
        y_sorted = y_coords[sorted_indices]
        x_sorted = x_coords[sorted_indices]
        
        # ç”¨äºå­˜å‚¨æœ€ç»ˆæ‹Ÿåˆç‚¹
        final_y = y_sorted
        final_x = x_sorted
        weights = np.ones_like(final_y) # é»˜è®¤æƒé‡ä¸º1
        
        # å¦‚æœéœ€è¦å¼ºåˆ¶è¿‡åº•è¾¹ä¸­ç‚¹
        if force_bottom_center:
            bottom_center = self._get_bottom_center_world_coord()
            
            if bottom_center is not None:
                # å°†åº•è¾¹ä¸­ç‚¹æ·»åŠ åˆ°æ‹Ÿåˆç‚¹ä¸­
                # æ³¨æ„ï¼šbottom_centeræ˜¯ (x, y) æ ¼å¼
                final_y = np.append(final_y, bottom_center[1])
                final_x = np.append(final_x, bottom_center[0])
                
                # æ ¸å¿ƒä¿®æ­£2: ä¸ºè¿™ä¸ªç‚¹è®¾ç½®ä¸€ä¸ªæå¤§çš„æƒé‡
                weights = np.append(weights, 1e6) # ç»™æ–°ç‚¹ä¸€ä¸ªå·¨å¤§çš„æƒé‡
                
                # é‡æ–°æ’åº
                sorted_indices = np.argsort(final_y)
                final_y = final_y[sorted_indices]
                final_x = final_x[sorted_indices]
                weights = weights[sorted_indices]
                
                print(f"ğŸ¯ å¼ºåˆ¶æ‹Ÿåˆæ›²çº¿è¿‡åº•è¾¹ä¸­ç‚¹: ({bottom_center[0]:.1f}, {bottom_center[1]:.1f}) cmï¼Œæƒé‡: {1e6}")

        # ç¡®ä¿ç‚¹æ•°è¶³å¤Ÿæ‹Ÿåˆ
        if len(final_y) <= degree:
            print(f"âš ï¸ æ‹Ÿåˆç‚¹æ•° ({len(final_y)}) ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œ {degree} é˜¶æ‹Ÿåˆã€‚")
            return None, None

        if method == 'polynomial':
            # æ ¸å¿ƒä¿®æ­£3: æ‹Ÿåˆ x = f(y)ï¼Œå¹¶ä¼ å…¥æƒé‡
            fit_params = np.polyfit(final_y, final_x, degree, w=weights)
            smooth_path_func = np.poly1d(fit_params)
            
        elif method == 'spline':
            # æ ·æ¡æ’å€¼é»˜è®¤ä¼šç©¿è¿‡æ‰€æœ‰ç‚¹ï¼Œä½†è¿™é‡Œä¸ºäº†ç»Ÿä¸€ï¼Œä¹Ÿä½¿ç”¨å¤šé¡¹å¼
            # å¦‚æœéœ€è¦æ ·æ¡ï¼Œä¹Ÿéœ€è¦æ‹Ÿåˆ x=f(y)
            print("âš ï¸ æ ·æ¡æ–¹æ³•æš‚ä¸æ”¯æŒæƒé‡ï¼Œå¼ºåˆ¶ä½¿ç”¨å¤šé¡¹å¼æ‹Ÿåˆä»¥ç¡®ä¿è¿‡ä¸­ç‚¹ã€‚")
            fit_params = np.polyfit(final_y, final_x, degree, w=weights)
            smooth_path_func = np.poly1d(fit_params)
        
        return smooth_path_func, fit_params
    
    def _get_bottom_center_world_coord(self):
        """
        è·å–å›¾åƒåº•è¾¹ä¸­ç‚¹çš„ä¸–ç•Œåæ ‡
        
        è¿”å›ï¼š
            bottom_center: (x, y) åº•è¾¹ä¸­ç‚¹çš„ä¸–ç•Œåæ ‡ï¼Œå•ä½å˜ç±³
        """
        try:
            # ä½¿ç”¨æ­£ç¡®çš„"å›¾åƒåæ ‡->ä¸–ç•Œåæ ‡"å˜æ¢çŸ©é˜µ
            if 'image_to_world_matrix' in self.view_params:
                transform_matrix = np.array(self.view_params['image_to_world_matrix'], dtype=np.float32)
            else:
                # å¦‚æœæ²¡æœ‰ï¼Œä½œä¸ºå›é€€ï¼Œä»æ ¡æ­£é…ç½®ä¸­è·å–
                print("âš ï¸ åœ¨view_paramsä¸­æœªæ‰¾åˆ°image_to_world_matrixï¼Œå°è¯•ä»å†…ç½®æ ¡å‡†è·å–ã€‚")
                transform_matrix = get_corrected_calibration()
            
            # 640Ã—360å›¾åƒåº•è¾¹ä¸­ç‚¹çš„åƒç´ åæ ‡
            img_bottom_center = np.array([320, 359, 1], dtype=np.float32)  # (320, 359) æ˜¯åº•è¾¹ä¸­ç‚¹
            
            # æŠ•å½±åˆ°ä¸–ç•Œåæ ‡
            world_pt = transform_matrix @ img_bottom_center
            world_x = world_pt[0] / world_pt[2]
            world_y = world_pt[1] / world_pt[2]
            
            return (world_x, world_y)
            
        except Exception as e:
            print(f"âš ï¸ æ— æ³•è®¡ç®—åº•è¾¹ä¸­ç‚¹ä¸–ç•Œåæ ‡: {e}")
            return None
    
    def generate_waypoints(self, smooth_path_func, num_points=20, y_range=None):
        """
        ä»å¹³æ»‘è·¯å¾„ç”Ÿæˆè·¯å¾„ç‚¹ (å·²ä¿®æ­£ä¸ºåŸºäº y è½´ç”Ÿæˆ)
        
        å‚æ•°ï¼š
            smooth_path_func: å¹³æ»‘è·¯å¾„å‡½æ•° x = f(y)
            num_points: è·¯å¾„ç‚¹æ•°é‡
            y_range: Yåæ ‡èŒƒå›´ (min_y, max_y)ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨è§†å›¾è¾¹ç•Œ
        
        è¿”å›ï¼š
            waypoints: è·¯å¾„ç‚¹åˆ—è¡¨ [(x, y), ...]ï¼ˆä¸–ç•Œåæ ‡ï¼Œå˜ç±³ï¼‰
        """
        if smooth_path_func is None:
            return []
        
        # æ ¸å¿ƒä¿®æ­£: æˆ‘ä»¬åº”è¯¥åœ¨yè½´ï¼ˆå‰è¿›æ–¹å‘ï¼‰ä¸Šå–ç‚¹
        if y_range is None:
            min_x, min_y, max_x, max_y = self.view_bounds
        else:
            min_y, max_y = y_range

        # ç”Ÿæˆå‡åŒ€åˆ†å¸ƒçš„yåæ ‡
        y_waypoints = np.linspace(min_y, max_y, num_points)
        
        # è®¡ç®—å¯¹åº”çš„xåæ ‡
        x_waypoints = smooth_path_func(y_waypoints)
        
        # ç»„åˆæˆè·¯å¾„ç‚¹ (x, y)
        waypoints = list(zip(x_waypoints, y_waypoints))
        
        return waypoints
    
    def plan_complete_path(self, bird_eye_mask, smooth_method='polynomial', degree=3, 
                          num_waypoints=20, min_width=10, fast_mode=True, force_bottom_center=True):
        """
        å®Œæ•´çš„è·¯å¾„è§„åˆ’æµç¨‹
        
        å‚æ•°ï¼š
            bird_eye_mask: é¸Ÿç°å›¾åˆ†å‰²æ©ç 
            smooth_method: å¹³æ»‘æ–¹æ³•
            degree: æ‹Ÿåˆé˜¶æ•°
            num_waypoints: è·¯å¾„ç‚¹æ•°é‡
            min_width: æœ€å°å¯è¡Œé©¶å®½åº¦
            fast_mode: æ˜¯å¦ä½¿ç”¨å¿«é€Ÿæ¨¡å¼ï¼ˆè¾¹ç¼˜è®¡ç®—ä¼˜åŒ–ï¼‰
            force_bottom_center: æ˜¯å¦å¼ºåˆ¶æ›²çº¿è¿‡åº•è¾¹ä¸­ç‚¹
        
        è¿”å›ï¼š
            path_data: åŒ…å«æ‰€æœ‰è·¯å¾„ä¿¡æ¯çš„å­—å…¸
        """
        # ç¬¬ä¸€æ­¥ï¼šæå–ä¸­å¿ƒçº¿ï¼ˆé€‰æ‹©å¿«é€Ÿæˆ–ç²¾ç¡®æ¨¡å¼ï¼‰
        if fast_mode:
            centerline_pixels, centerline_world = self.extract_centerline_fast(
                bird_eye_mask, min_width=min_width//2, skip_rows=3)  # é™ä½è¦æ±‚ï¼Œè·³è¡Œæ‰«æ
        else:
            centerline_pixels, centerline_world = self.extract_centerline(
                bird_eye_mask, min_width=min_width)
        
        if not centerline_world:
            return {
                'centerline_pixels': [],
                'centerline_world': [],
                'smooth_path_func': None,
                'fit_params': None,
                'waypoints': [],
                'path_length': 0
            }
        
        # ç¬¬äºŒæ­¥ï¼šè·¯å¾„å¹³æ»‘ï¼ˆè¾¹ç¼˜è®¡ç®—æ¨¡å¼ä¸‹é™ä½é˜¶æ•°ï¼Œå¼ºåˆ¶è¿‡åº•è¾¹ä¸­ç‚¹ï¼‰
        if fast_mode:
            smooth_degree = min(2, degree)  # æœ€é«˜2é˜¶ï¼Œå‡å°‘è®¡ç®—é‡
        else:
            smooth_degree = degree
            
        smooth_path_func, fit_params = self.smooth_path(
            centerline_world, method=smooth_method, degree=smooth_degree, 
            force_bottom_center=force_bottom_center)
        
        # ç¬¬ä¸‰æ­¥ï¼šç”Ÿæˆè·¯å¾„ç‚¹
        waypoints = self.generate_waypoints(smooth_path_func, num_waypoints)
        
        # è®¡ç®—è·¯å¾„é•¿åº¦
        path_length = self._calculate_path_length(waypoints) if waypoints else 0
        
        return {
            'centerline_pixels': centerline_pixels,
            'centerline_world': centerline_world,
            'smooth_path_func': smooth_path_func,
            'fit_params': fit_params,
            'waypoints': waypoints,
            'path_length': path_length,
            'num_centerline_points': len(centerline_world),
            'num_waypoints': len(waypoints),
            'fast_mode': fast_mode,
            'force_bottom_center': force_bottom_center
        }
    
    def _calculate_path_length(self, waypoints):
        """è®¡ç®—è·¯å¾„æ€»é•¿åº¦"""
        if len(waypoints) < 2:
            return 0
        
        total_length = 0
        for i in range(1, len(waypoints)):
            dx = waypoints[i][0] - waypoints[i-1][0]
            dy = waypoints[i][1] - waypoints[i-1][1]
            total_length += np.sqrt(dx*dx + dy*dy)
        
        return total_length

# ---------------------------------------------------------------------------------
# --- ğŸš— åŸºäºè§†è§‰æ¨ªå‘è¯¯å·®çš„æ¯”ä¾‹-é€Ÿåº¦è‡ªé€‚åº”å·®é€Ÿæ§åˆ¶ç®—æ³• ---
# ---------------------------------------------------------------------------------

class VisualLateralErrorController:
    """
    åŸºäºè§†è§‰æ¨ªå‘è¯¯å·®çš„æ¯”ä¾‹-é€Ÿåº¦è‡ªé€‚åº”å·®é€Ÿæ§åˆ¶ç®—æ³•
    (Proportional-Speed-Adaptive Differential Drive Control based on Visual Lateral Error)
    
    ç®—æ³•æ¦‚è¿°ï¼š
    æœ¬ç®—æ³•æ˜¯ä¸€ç§ä¸“ä¸ºçº¯è§†è§‰ã€å·®é€Ÿè½¬å‘æœºå™¨äººè®¾è®¡çš„å¼€ç¯è·¯å¾„è·Ÿè¸ªæ§åˆ¶å™¨ã€‚
    é€šè¿‡é¸Ÿç°å›¾å®æ—¶è®¡ç®—æœºå™¨äººä¸è§„åˆ’è·¯å¾„ä¹‹é—´çš„æ¨ªå‘åå·®ï¼Œåˆ©ç”¨æ¯”ä¾‹æ§åˆ¶å™¨
    å°†æ­¤åå·®ç›´æ¥è½¬æ¢ä¸ºå·¦å³é©±åŠ¨è½®çš„é€Ÿåº¦å·®ï¼ŒåŒæ—¶å¼•å…¥é€Ÿåº¦è‡ªé€‚åº”æœºåˆ¶ã€‚
    """
    
    def __init__(self, steering_gain=50.0, base_pwm=300, curvature_damping=0.1, 
                 preview_distance=30.0, max_pwm=800, min_pwm=100):
        """
        åˆå§‹åŒ–æ§åˆ¶å™¨å‚æ•°
        
        å‚æ•°ï¼š
            steering_gain: è½¬å‘å¢ç›Š Kpï¼ˆæ¯”ä¾‹æ§åˆ¶å™¨å¢ç›Šï¼‰
            base_pwm: åŸºç¡€PWMå€¼ï¼ˆ-1000åˆ°+1000èŒƒå›´ï¼‰
            curvature_damping: æ›²ç‡é˜»å°¼ç³»æ•°ï¼ˆé€Ÿåº¦è‡ªé€‚åº”å‚æ•°ï¼‰
            preview_distance: é¢„ç„è·ç¦»ï¼ˆcmï¼Œæ§åˆ¶ç‚¹è·ç¦»æœºå™¨äººçš„è·ç¦»ï¼‰
            max_pwm: æœ€å¤§PWMå€¼ï¼ˆ-1000åˆ°+1000èŒƒå›´ï¼‰
            min_pwm: æœ€å°PWMå€¼ï¼ˆ-1000åˆ°+1000èŒƒå›´ï¼Œç”¨äºå‰è¿›æ—¶çš„æœ€ä½é€Ÿåº¦ï¼‰
        """
        self.steering_gain = steering_gain
        self.base_pwm = base_pwm
        self.curvature_damping = curvature_damping
        self.preview_distance = preview_distance
        self.max_pwm = max_pwm
        self.min_pwm = min_pwm
        
        # æ€§èƒ½ç»Ÿè®¡
        self.control_history = []
        
        print(f"ğŸš— è§†è§‰æ¨ªå‘è¯¯å·®æ§åˆ¶å™¨å·²åˆå§‹åŒ–:")
        print(f"   ğŸ“ è½¬å‘å¢ç›Š: {steering_gain}")
        print(f"   ğŸƒ åŸºç¡€PWM: {base_pwm} (-1000~+1000)")
        print(f"   ğŸŒŠ æ›²ç‡é˜»å°¼: {curvature_damping}")
        print(f"   ğŸ‘ï¸ é¢„ç„è·ç¦»: {preview_distance} cm")
        print(f"   âš¡ PWMèŒƒå›´: {min_pwm} ~ {max_pwm} (æ”¯æŒåŒå‘æ—‹è½¬)")
    
    def calculate_lateral_error(self, path_data, view_params):
        """
        æ¨¡å—ä¸€ï¼šè§†è§‰è¯¯å·®æ„ŸçŸ¥ (Visual Error Perception)
        
        ä»è·¯å¾„æ•°æ®ä¸­è®¡ç®—æ¨ªå‘è¯¯å·®
        
        å‚æ•°ï¼š
            path_data: è·¯å¾„è§„åˆ’æ•°æ®
            view_params: è§†å›¾å‚æ•°
            
        è¿”å›ï¼š
            lateral_error: æ¨ªå‘è¯¯å·®ï¼ˆcmï¼‰
            car_position: æœºå™¨äººå½“å‰ä½ç½®ï¼ˆä¸–ç•Œåæ ‡ï¼‰
            control_point: æ§åˆ¶ç‚¹ä½ç½®ï¼ˆä¸–ç•Œåæ ‡ï¼‰
        """
        # 1. å®šä¹‰æœºå™¨äººå½“å‰ä½ç½®ï¼ˆå›¾åƒåº•éƒ¨ä¸­å¿ƒç‚¹ï¼‰
        car_position = self._get_car_position_world(view_params)
        
        # 2. åœ¨è·¯å¾„ä¸Šæ‰¾åˆ°é¢„ç„æ§åˆ¶ç‚¹
        control_point = self._find_preview_point(path_data, car_position)
        
        if control_point is None:
            return 0.0, car_position, None
        
        # 3. è®¡ç®—æ¨ªå‘è¯¯å·®ï¼ˆæ§åˆ¶ç‚¹Xåæ ‡ - æœºå™¨äººXåæ ‡ï¼‰
        lateral_error = control_point[0] - car_position[0]
        
        return lateral_error, car_position, control_point
    
    def calculate_steering_adjustment(self, lateral_error):
        """
        æ¨¡å—äºŒï¼šæ¯”ä¾‹è½¬å‘æ§åˆ¶ (Proportional Steering Control)
        
        å‚æ•°ï¼š
            lateral_error: æ¨ªå‘è¯¯å·®ï¼ˆcmï¼‰
            
        è¿”å›ï¼š
            steering_adjustment: è½¬å‘è°ƒæ•´é‡ï¼ˆPWMå•ä½ï¼‰
        """
        # æ¯”ä¾‹æ§åˆ¶å¾‹: Steering_Adjustment = STEERING_GAIN * Lateral_Error
        steering_adjustment = self.steering_gain * lateral_error
        
        return steering_adjustment
    
    def calculate_dynamic_pwm(self, lateral_error):
        """
        æ¨¡å—ä¸‰ï¼šåŠ¨æ€é€Ÿåº¦è‡ªé€‚åº” (Dynamic Speed Adaptation)
        
        å‚æ•°ï¼š
            lateral_error: æ¨ªå‘è¯¯å·®ï¼ˆcmï¼‰
            
        è¿”å›ï¼š
            dynamic_pwm: è‡ªé€‚åº”è°ƒæ•´åçš„PWMå€¼ï¼ˆ0-1000ï¼‰
        """
        # åŠ¨æ€PWMæ§åˆ¶å¾‹: Dynamic_PWM = BASE_PWM / (1 + CURVATURE_DAMPING * |Lateral_Error|)
        dynamic_pwm = self.base_pwm / (1 + self.curvature_damping * abs(lateral_error))
        
        # é™åˆ¶åœ¨å…è®¸çš„PWMèŒƒå›´å†…
        dynamic_pwm = np.clip(dynamic_pwm, self.min_pwm, self.max_pwm)
        
        return dynamic_pwm
    
    def compute_wheel_pwm(self, path_data, view_params):
        """
        å®Œæ•´çš„æ§åˆ¶è®¡ç®—æµç¨‹ - è¾“å‡ºPWMæ§åˆ¶å€¼
        
        å‚æ•°ï¼š
            path_data: è·¯å¾„è§„åˆ’æ•°æ®
            view_params: è§†å›¾å‚æ•°
            
        è¿”å›ï¼š
            control_result: æ§åˆ¶ç»“æœå­—å…¸
        """
        # æ¨¡å—ä¸€ï¼šè®¡ç®—æ¨ªå‘è¯¯å·®
        lateral_error, car_position, control_point = self.calculate_lateral_error(path_data, view_params)
        
        # æ¨¡å—äºŒï¼šè®¡ç®—è½¬å‘è°ƒæ•´
        steering_adjustment = self.calculate_steering_adjustment(lateral_error)
        
        # æ¨¡å—ä¸‰ï¼šè®¡ç®—åŠ¨æ€PWM
        dynamic_pwm = self.calculate_dynamic_pwm(lateral_error)
        
        # æœ€ç»ˆæŒ‡ä»¤åˆæˆ - ä¿®æ­£å·®é€Ÿè½¬å‘é€»è¾‘
        # å½“lateral_error < 0æ—¶éœ€è¦å·¦è½¬ï¼Œåº”è¯¥å³è½®å¿«å·¦è½®æ…¢
        # å½“lateral_error > 0æ—¶éœ€è¦å³è½¬ï¼Œåº”è¯¥å·¦è½®å¿«å³è½®æ…¢
        pwm_right = dynamic_pwm - steering_adjustment  # å³è½®PWM
        pwm_left = dynamic_pwm + steering_adjustment   # å·¦è½®PWM
        
        # é™åˆ¶PWMå€¼åœ¨-1000åˆ°+1000èŒƒå›´å†…ï¼ˆæ”¯æŒåŒå‘æ—‹è½¬ï¼‰
        pwm_right = np.clip(pwm_right, -1000, 1000)
        pwm_left = np.clip(pwm_left, -1000, 1000)
        
        # æ„å»ºæ§åˆ¶ç»“æœ
        control_result = {
            'lateral_error': lateral_error,
            'car_position': car_position,
            'control_point': control_point,
            'steering_adjustment': steering_adjustment,
            'dynamic_pwm': dynamic_pwm,
            'pwm_right': pwm_right,
            'pwm_left': pwm_left,
            'turn_direction': 'left' if lateral_error < 0 else 'right' if lateral_error > 0 else 'straight',
            'curvature_level': abs(lateral_error) / self.preview_distance,  # æ›²ç‡æ°´å¹³æŒ‡ç¤º
            'pwm_reduction_factor': self.base_pwm / dynamic_pwm if dynamic_pwm > 0 else 1.0,
            # å…¼å®¹æ€§å­—æ®µï¼ˆä¿æŒåŸæœ‰æ¥å£ï¼‰
            'dynamic_speed': dynamic_pwm,  # æ˜ å°„åˆ°PWM
            'speed_right': pwm_right,      # æ˜ å°„åˆ°PWM
            'speed_left': pwm_left,        # æ˜ å°„åˆ°PWM
            'speed_reduction_factor': self.base_pwm / dynamic_pwm if dynamic_pwm > 0 else 1.0
        }
        
        # è®°å½•æ§åˆ¶å†å²
        self.control_history.append(control_result.copy())
        
        return control_result
    
    def _get_car_position_world(self, view_params):
        """
        è·å–æœºå™¨äººåœ¨ä¸–ç•Œåæ ‡ç³»ä¸­çš„å½“å‰ä½ç½®ï¼ˆå›¾åƒåº•éƒ¨ä¸­å¿ƒç‚¹ï¼‰
        
        å‚æ•°ï¼š
            view_params: è§†å›¾å‚æ•°
            
        è¿”å›ï¼š
            car_position: (x, y) æœºå™¨äººä½ç½®çš„ä¸–ç•Œåæ ‡ï¼ˆcmï¼‰
        """
        try:
            # ä½¿ç”¨é€è§†å˜æ¢çŸ©é˜µå°†å›¾åƒåº•éƒ¨ä¸­å¿ƒç‚¹è½¬æ¢ä¸ºä¸–ç•Œåæ ‡
            if 'image_to_world_matrix' in view_params:
                transform_matrix = np.array(view_params['image_to_world_matrix'], dtype=np.float32)
            else:
                # å›é€€åˆ°å†…ç½®æ ¡å‡†
                transform_matrix = get_corrected_calibration()
            
            # 640Ã—360å›¾åƒåº•éƒ¨ä¸­å¿ƒç‚¹çš„åƒç´ åæ ‡
            img_bottom_center = np.array([320, 359, 1], dtype=np.float32)
            
            # æŠ•å½±åˆ°ä¸–ç•Œåæ ‡
            world_pt = transform_matrix @ img_bottom_center
            world_x = world_pt[0] / world_pt[2]
            world_y = world_pt[1] / world_pt[2]
            
            return (world_x, world_y)
            
        except Exception as e:
            print(f"âš ï¸ æ— æ³•è·å–æœºå™¨äººä¸–ç•Œåæ ‡: {e}")
            # ä½¿ç”¨è§†å›¾è¾¹ç•Œçš„åº•éƒ¨ä¸­å¿ƒä½œä¸ºå›é€€
            min_x, min_y, max_x, max_y = view_params['view_bounds']
            return ((min_x + max_x) / 2, max_y)
    
    def _find_preview_point(self, path_data, car_position):
        """
        åœ¨è·¯å¾„ä¸Šæ‰¾åˆ°é¢„ç„æ§åˆ¶ç‚¹
        
        å‚æ•°ï¼š
            path_data: è·¯å¾„æ•°æ®
            car_position: æœºå™¨äººå½“å‰ä½ç½®
            
        è¿”å›ï¼š
            control_point: æ§åˆ¶ç‚¹åæ ‡ (x, y)ï¼Œå¦‚æœæ‰¾ä¸åˆ°åˆ™è¿”å›None
        """
        waypoints = path_data.get('waypoints', [])
        if not waypoints:
            return None
        
        car_x, car_y = car_position
        
        # æ‰¾åˆ°è·ç¦»æœºå™¨äººé¢„ç„è·ç¦»æœ€è¿‘çš„è·¯å¾„ç‚¹
        best_point = None
        min_distance_diff = float('inf')
        
        for waypoint in waypoints:
            wx, wy = waypoint
            
            # è®¡ç®—è¯¥ç‚¹åˆ°æœºå™¨äººçš„è·ç¦»
            distance = np.sqrt((wx - car_x)**2 + (wy - car_y)**2)
            
            # æ‰¾åˆ°æœ€æ¥è¿‘é¢„ç„è·ç¦»çš„ç‚¹ï¼ˆä¼˜å…ˆé€‰æ‹©å‰æ–¹çš„ç‚¹ï¼‰
            if wy < car_y:  # åªè€ƒè™‘å‰æ–¹çš„ç‚¹ï¼ˆYå€¼æ›´å°ï¼‰
                distance_diff = abs(distance - self.preview_distance)
                if distance_diff < min_distance_diff:
                    min_distance_diff = distance_diff
                    best_point = waypoint
        
        # å¦‚æœæ²¡æ‰¾åˆ°å‰æ–¹çš„ç‚¹ï¼Œé€‰æ‹©æœ€å‰æ–¹çš„ç‚¹
        if best_point is None and waypoints:
            best_point = min(waypoints, key=lambda p: p[1])  # Yå€¼æœ€å°çš„ç‚¹
        
        return best_point
    
    def generate_control_visualization(self, control_map, control_result, view_params):
        """
        åœ¨æ§åˆ¶åœ°å›¾ä¸Šå¯è§†åŒ–æ§åˆ¶ç®—æ³•çš„åˆ†æç»“æœ
        
        å‚æ•°ï¼š
            control_map: åŸå§‹æ§åˆ¶åœ°å›¾
            control_result: æ§åˆ¶è®¡ç®—ç»“æœ
            view_params: è§†å›¾å‚æ•°
            
        è¿”å›ï¼š
            annotated_map: å¸¦æ§åˆ¶ä¿¡æ¯æ ‡æ³¨çš„åœ°å›¾
        """
        annotated_map = control_map.copy()
        
        if control_result['car_position'] is None:
            return annotated_map
        
        # è½¬æ¢ä¸–ç•Œåæ ‡åˆ°åƒç´ åæ ‡
        car_pos_pixel = self._world_to_pixel(control_result['car_position'], view_params)
        
        # ç»˜åˆ¶æœºå™¨äººä½ç½®ï¼ˆç»¿è‰²åœ†åœˆï¼‰
        cv2.circle(annotated_map, (int(car_pos_pixel[0]), int(car_pos_pixel[1])), 
                  8, (0, 255, 0), 3)
        cv2.putText(annotated_map, "CAR", 
                   (int(car_pos_pixel[0]) + 10, int(car_pos_pixel[1]) - 10),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
        
        # ç»˜åˆ¶æ§åˆ¶ç‚¹ï¼ˆç´«è‰²åœ†åœˆï¼‰
        if control_result['control_point'] is not None:
            control_pos_pixel = self._world_to_pixel(control_result['control_point'], view_params)
            cv2.circle(annotated_map, (int(control_pos_pixel[0]), int(control_pos_pixel[1])), 
                      6, (255, 0, 255), 3)
            cv2.putText(annotated_map, "TARGET", 
                       (int(control_pos_pixel[0]) + 10, int(control_pos_pixel[1]) - 10),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 0, 255), 1)
            
            # ç»˜åˆ¶æ¨ªå‘è¯¯å·®çº¿ï¼ˆçº¢è‰²è™šçº¿ï¼‰
            cv2.line(annotated_map, 
                    (int(car_pos_pixel[0]), int(car_pos_pixel[1])),
                    (int(control_pos_pixel[0]), int(car_pos_pixel[1])),  # æ°´å¹³çº¿æ˜¾ç¤ºæ¨ªå‘è¯¯å·®
                    (0, 0, 255), 2)
        
        # æ·»åŠ æ§åˆ¶ä¿¡æ¯æ–‡æœ¬
        self._add_control_info_text(annotated_map, control_result)
        
        return annotated_map
    
    def _world_to_pixel(self, world_point, view_params):
        """å°†ä¸–ç•Œåæ ‡è½¬æ¢ä¸ºåƒç´ åæ ‡"""
        min_x, min_y, max_x, max_y = view_params['view_bounds']
        pixels_per_unit = view_params['pixels_per_unit']
        
        pixel_x = (world_point[0] - min_x) * pixels_per_unit
        pixel_y = (world_point[1] - min_y) * pixels_per_unit
        
        return (pixel_x, pixel_y)
    
    def _add_control_info_text(self, image, control_result):
        """åœ¨å›¾åƒä¸Šæ·»åŠ æ§åˆ¶ä¿¡æ¯æ–‡æœ¬"""
        text_lines = [
            f"Lateral Error: {control_result['lateral_error']:.1f} cm",
            f"Direction: {control_result['turn_direction'].upper()}",
            f"Dynamic PWM: {control_result['dynamic_pwm']:.0f}",
            f"Left PWM: {control_result['pwm_left']:.0f}",
            f"Right PWM: {control_result['pwm_right']:.0f}",
            f"Curvature: {control_result['curvature_level']:.3f}",
            f"PWM Reduction: {control_result['pwm_reduction_factor']:.2f}x"
        ]
        
        # åœ¨å›¾åƒå·¦ä¸Šè§’æ·»åŠ æ§åˆ¶ä¿¡æ¯
        y_offset = 20
        for line in text_lines:
            cv2.putText(image, line, (10, y_offset), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)
            y_offset += 18
    
    def print_control_analysis(self, control_result):
        """æ‰“å°è¯¦ç»†çš„æ§åˆ¶åˆ†æç»“æœ"""
        print("\n" + "="*60)
        print("ğŸš— åŸºäºè§†è§‰æ¨ªå‘è¯¯å·®çš„å·®é€Ÿæ§åˆ¶åˆ†æ")
        print("="*60)
        
        # åŸºç¡€ä¿¡æ¯
        print(f"ğŸ“ æœºå™¨äººä½ç½®: ({control_result['car_position'][0]:.1f}, {control_result['car_position'][1]:.1f}) cm")
        if control_result['control_point']:
            print(f"ğŸ¯ æ§åˆ¶ç‚¹ä½ç½®: ({control_result['control_point'][0]:.1f}, {control_result['control_point'][1]:.1f}) cm")
        
        # æ¨¡å—ä¸€ï¼šè§†è§‰è¯¯å·®æ„ŸçŸ¥
        print(f"\nğŸ“± æ¨¡å—ä¸€ï¼šè§†è§‰è¯¯å·®æ„ŸçŸ¥")
        print(f"   æ¨ªå‘è¯¯å·®: {control_result['lateral_error']:+.1f} cm")
        print(f"   è½¬å‘æ–¹å‘: {control_result['turn_direction'].upper()}")
        print(f"   è¯¯å·®å¼ºåº¦: {'é«˜' if abs(control_result['lateral_error']) > 10 else 'ä¸­' if abs(control_result['lateral_error']) > 5 else 'ä½'}")
        
        # æ¨¡å—äºŒï¼šæ¯”ä¾‹è½¬å‘æ§åˆ¶
        print(f"\nğŸ® æ¨¡å—äºŒï¼šæ¯”ä¾‹è½¬å‘æ§åˆ¶")
        print(f"   è½¬å‘è°ƒæ•´: {control_result['steering_adjustment']:+.0f} PWM")
        print(f"   æ§åˆ¶å¢ç›Š: {self.steering_gain}")
        
        # æ¨¡å—ä¸‰ï¼šåŠ¨æ€PWMè‡ªé€‚åº”
        print(f"\nâš¡ æ¨¡å—ä¸‰ï¼šåŠ¨æ€PWMè‡ªé€‚åº”")
        print(f"   åŸºç¡€PWM: {self.base_pwm:.0f}")
        print(f"   åŠ¨æ€PWM: {control_result['dynamic_pwm']:.0f}")
        print(f"   PWMè¡°å‡: {control_result['pwm_reduction_factor']:.2f}x")
        print(f"   æ›²ç‡æ°´å¹³: {control_result['curvature_level']:.3f}")
        
        # æœ€ç»ˆæ§åˆ¶æŒ‡ä»¤
        print(f"\nğŸ› æœ€ç»ˆå·®é€ŸPWMæ§åˆ¶æŒ‡ä»¤")
        print(f"   å·¦è½®PWM: {control_result['pwm_left']:+.0f}")
        print(f"   å³è½®PWM: {control_result['pwm_right']:+.0f}")
        print(f"   PWMå·®å€¼: {abs(control_result['pwm_right'] - control_result['pwm_left']):.0f}")
        print(f"   å¯ç›´æ¥å‘é€ç»™åº•å±‚é©±åŠ¨ï¼")
        
        # æ€§èƒ½å»ºè®®
        self._print_performance_recommendations(control_result)
    
    def _print_performance_recommendations(self, control_result):
        """æ‰“å°æ€§èƒ½å»ºè®®"""
        print(f"\nğŸ’¡ æ€§èƒ½åˆ†æä¸å»ºè®®")
        
        error_abs = abs(control_result['lateral_error'])
        if error_abs > 15:
            print("   âš ï¸ æ¨ªå‘è¯¯å·®è¾ƒå¤§ï¼Œå»ºè®®æ£€æŸ¥è·¯å¾„è§„åˆ’è´¨é‡")
        elif error_abs < 2:
            print("   âœ… æ¨ªå‘è¯¯å·®å¾ˆå°ï¼Œè·¯å¾„è·Ÿè¸ªè‰¯å¥½")
        else:
            print("   ğŸ‘ æ¨ªå‘è¯¯å·®åœ¨åˆç†èŒƒå›´å†…")
        
        if control_result['curvature_level'] > 0.3:
            print("   ğŸŒŠ è¿›å…¥é«˜æ›²ç‡è·¯æ®µï¼Œè‡ªåŠ¨å‡é€Ÿç”Ÿæ•ˆ")
        elif control_result['curvature_level'] < 0.1:
            print("   ğŸ›£ï¸ ç›´çº¿è·¯æ®µï¼Œä¿æŒè¾ƒé«˜é€Ÿåº¦")
        
        speed_diff = abs(control_result['speed_right'] - control_result['speed_left'])
        if speed_diff > 10:
            print("   ğŸ”„ å¤§å¹…è½¬å‘æŒ‡ä»¤ï¼Œæ³¨æ„æœºå™¨äººç¨³å®šæ€§")
        elif speed_diff < 2:
            print("   â¡ï¸ ç›´è¡Œä¸ºä¸»ï¼Œè½¬å‘è°ƒæ•´è½»å¾®")

    def save_control_data(self, control_result, json_path):
        """
        ä¿å­˜æ§åˆ¶æ•°æ®åˆ°JSONæ–‡ä»¶
        
        å‚æ•°ï¼š
            control_result: æ§åˆ¶è®¡ç®—ç»“æœ
            json_path: JSONæ–‡ä»¶è·¯å¾„
        """
        # é€’å½’è½¬æ¢æ‰€æœ‰numpyç±»å‹
        def convert_to_serializable(obj):
            if isinstance(obj, np.ndarray):
                return obj.tolist()
            elif isinstance(obj, (np.integer, np.int8, np.int16, np.int32, np.int64)):
                return int(obj)
            elif isinstance(obj, (np.floating, np.float16, np.float32, np.float64)):
                return float(obj)
            elif isinstance(obj, np.bool_):
                return bool(obj)
            elif isinstance(obj, dict):
                return {key: convert_to_serializable(value) for key, value in obj.items()}
            elif isinstance(obj, (list, tuple)):
                return [convert_to_serializable(item) for item in obj]
            else:
                return obj
        
        # å‡†å¤‡å¯åºåˆ—åŒ–çš„æ•°æ®
        serializable_control_result = convert_to_serializable(control_result)
        serializable_history = convert_to_serializable(
            self.control_history[-10:] if len(self.control_history) > 10 else self.control_history
        )
        
        control_data = {
            'algorithm_name': 'åŸºäºè§†è§‰æ¨ªå‘è¯¯å·®çš„æ¯”ä¾‹-é€Ÿåº¦è‡ªé€‚åº”å·®é€Ÿæ§åˆ¶ç®—æ³•',
            'algorithm_description': 'Proportional-Speed-Adaptive Differential Drive Control based on Visual Lateral Error',
            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
            'parameters': {
                'steering_gain': float(self.steering_gain),
                'base_pwm': float(self.base_pwm),
                'curvature_damping': float(self.curvature_damping),
                'preview_distance': float(self.preview_distance),
                'max_pwm': float(self.max_pwm),
                'min_pwm': float(self.min_pwm)
            },
            'current_control': serializable_control_result,
            'control_history': serializable_history,
            'units': {
                'position': 'cm',
                'pwm': '-1000~+1000 (bidirectional)',
                'error': 'cm'
            }
        }
        
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(control_data, f, indent=2, ensure_ascii=False)

def visualize_path_on_control_map(control_map, path_data, view_params):
    """
    åœ¨æ§åˆ¶åœ°å›¾ä¸Šå¯è§†åŒ–è·¯å¾„è§„åˆ’ç»“æœ
    
    å‚æ•°ï¼š
        control_map: æ§åˆ¶åœ°å›¾
        path_data: è·¯å¾„æ•°æ®
        view_params: è§†å›¾å‚æ•°
    
    è¿”å›ï¼š
        annotated_map: å¸¦è·¯å¾„æ ‡æ³¨çš„æ§åˆ¶åœ°å›¾
    """
    annotated_map = control_map.copy()
    
    if not path_data['centerline_pixels']:
        return annotated_map
    
    # ç»˜åˆ¶åŸå§‹ä¸­å¿ƒçº¿ç‚¹ï¼ˆçº¢è‰²å°åœ†ç‚¹ï¼‰
    for px, py in path_data['centerline_pixels']:
        cv2.circle(annotated_map, (int(px), int(py)), 2, (0, 0, 255), -1)
    
    # ç»˜åˆ¶å¹³æ»‘è·¯å¾„ï¼ˆè“è‰²çº¿æ¡ï¼‰
    if path_data['smooth_path_func'] is not None and path_data['waypoints']:
        waypoints_pixels = world_to_pixels(path_data['waypoints'], view_params)
        
        for i in range(len(waypoints_pixels) - 1):
            pt1 = (int(waypoints_pixels[i][0]), int(waypoints_pixels[i][1]))
            pt2 = (int(waypoints_pixels[i+1][0]), int(waypoints_pixels[i+1][1]))
            cv2.line(annotated_map, pt1, pt2, (255, 0, 0), 3)  # è“è‰²ç²—çº¿
    
    # ç»˜åˆ¶è·¯å¾„ç‚¹ï¼ˆé»„è‰²æ–¹å—ï¼‰
    if path_data['waypoints']:
        waypoints_pixels = world_to_pixels(path_data['waypoints'], view_params)
        for i, (px, py) in enumerate(waypoints_pixels):
            cv2.rectangle(annotated_map, 
                         (int(px-3), int(py-3)), (int(px+3), int(py+3)), 
                         (0, 255, 255), -1)  # é»„è‰²æ–¹å—
            
            # æ ‡æ³¨è·¯å¾„ç‚¹ç¼–å·
            if i % 3 == 0:  # æ¯3ä¸ªç‚¹æ ‡æ³¨ä¸€æ¬¡ï¼Œé¿å…è¿‡äºå¯†é›†
                cv2.putText(annotated_map, f"{i}", (int(px+5), int(py-5)),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.3, (0, 255, 255), 1)
    
    return annotated_map

def world_to_pixels(world_points, view_params):
    """
    å°†ä¸–ç•Œåæ ‡è½¬æ¢ä¸ºåƒç´ åæ ‡
    
    å‚æ•°ï¼š
        world_points: ä¸–ç•Œåæ ‡ç‚¹åˆ—è¡¨
        view_params: è§†å›¾å‚æ•°
    
    è¿”å›ï¼š
        pixel_points: åƒç´ åæ ‡ç‚¹åˆ—è¡¨
    """
    min_x, min_y, max_x, max_y = view_params['view_bounds']
    pixels_per_unit = view_params['pixels_per_unit']
    
    pixel_points = []
    for world_x, world_y in world_points:
        pixel_x = (world_x - min_x) * pixels_per_unit
        pixel_y = (world_y - min_y) * pixels_per_unit
        pixel_points.append((pixel_x, pixel_y))
    
    return pixel_points


# ---------------------------------------------------------------------------------
# --- ğŸš€ å®æ—¶æ¨ç†æ¨¡å— (æ‘„åƒå¤´æ¨¡å¼) ---
# ---------------------------------------------------------------------------------

def setup_logging(log_file=None):
    """é…ç½®æ—¥å¿—ç³»ç»Ÿ"""
    if log_file:
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_file, encoding='utf-8'),
                logging.StreamHandler()
            ]
        )
    else:
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s'
        )

def realtime_inference(model_path, device_id=0, camera_index=0, 
                      camera_width=640, camera_height=360,
                      log_file=None, enable_control=True,
                      steering_gain=1.0, base_speed=10.0, 
                      curvature_damping=0.1, preview_distance=30.0,
                      max_speed=20.0, min_speed=5.0,
                      enable_web=False, no_gui=False, full_image_bird_eye=True):
    """
    å®æ—¶æ‘„åƒå¤´æ¨ç†æ¨¡å¼
    
    å‚æ•°ï¼š
        model_path: OMæ¨¡å‹è·¯å¾„
        device_id: Atlas NPUè®¾å¤‡ID
        camera_index: æ‘„åƒå¤´ç´¢å¼•
        camera_width: æ‘„åƒå¤´å®½åº¦
        camera_height: æ‘„åƒå¤´é«˜åº¦
        log_file: æ—¥å¿—æ–‡ä»¶è·¯å¾„
        enable_control: æ˜¯å¦å¯ç”¨æ§åˆ¶ç®—æ³•
        enable_web: æ˜¯å¦å¯ç”¨Webç•Œé¢æ•°æ®æ›´æ–°
        no_gui: æ˜¯å¦ç¦ç”¨GUIæ˜¾ç¤º
        å…¶ä»–: æ§åˆ¶å‚æ•°
    """
    # é…ç½®æ—¥å¿—
    setup_logging(log_file)
    logger = logging.getLogger(__name__)
    
    logger.info("ğŸš€ å¯åŠ¨å®æ—¶æ¨ç†ç³»ç»Ÿ")
    logger.info(f"ğŸ“± æ¨¡å‹: {model_path}")
    logger.info(f"ğŸ’¾ æ—¥å¿—æ–‡ä»¶: {log_file}")
    
    # åŠ è½½Atlasæ¨¡å‹
    logger.info("ğŸ§  åŠ è½½Atlas NPUæ¨¡å‹...")
    model = AtlasInferSession(device_id, model_path)
    logger.info("âœ… æ¨¡å‹åŠ è½½å®Œæˆ")
    
    # åˆå§‹åŒ–æ‘„åƒå¤´
    logger.info(f"ğŸ“· æ‰“å¼€æ‘„åƒå¤´ {camera_index}...")
    cap = cv2.VideoCapture(camera_index)
    if not cap.isOpened():
        logger.error(f"âŒ æ— æ³•æ‰“å¼€æ‘„åƒå¤´ {camera_index}")
        return
    
    # è®¾ç½®æ‘„åƒå¤´å‚æ•°
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, camera_width)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, camera_height)
    cap.set(cv2.CAP_PROP_FPS, 30)
    cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
    
    # ç¡®è®¤å®é™…å‚æ•°
    actual_w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    actual_h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    actual_fps = cap.get(cv2.CAP_PROP_FPS)
    
    logger.info(f"ğŸ“· æ‘„åƒå¤´å‚æ•°: {actual_w}x{actual_h} @ {actual_fps}fps")
    
    # åˆå§‹åŒ–æ§åˆ¶å™¨
    if enable_control:
        # ä½¿ç”¨å½“å‰æ–‡ä»¶ä¸­çš„æ§åˆ¶å™¨ç±»
        controller = VisualLateralErrorController(
            steering_gain=steering_gain,
            base_pwm=base_speed,
            curvature_damping=curvature_damping,
            preview_distance=preview_distance,
            max_pwm=max_speed,
            min_pwm=min_speed
        )
        logger.info("ğŸš— æ§åˆ¶å™¨åˆå§‹åŒ–å®Œæˆ")
    else:
        controller = None
    
    # é€è§†å˜æ¢å™¨
    transformer = PerspectiveTransformer()
    logger.info("ğŸ¦… é€è§†å˜æ¢å™¨åˆå§‹åŒ–å®Œæˆ")
    
    # åˆå§‹åŒ–Webç•Œé¢æ•°æ®
    if enable_web:
        with web_data_lock:
            web_data['is_running'] = True
            web_data['start_time'] = time.time()
            web_data['frame_count'] = 0
        logger.info("ğŸŒ Webç•Œé¢æ•°æ®åˆå§‹åŒ–å®Œæˆ")
    
    frame_count = 0
    start_time = time.time()
    total_times = {"preprocess": 0, "inference": 0, "postprocess": 0, "transform": 0, "control": 0}
    
    logger.info("ğŸ¬ å¼€å§‹å®æ—¶æ¨ç†å¾ªç¯...")
    
    try:
        while True:
            ret, frame = cap.read()
            if not ret:
                logger.warning("âš ï¸ æ— æ³•è¯»å–æ‘„åƒå¤´å¸§")
                time.sleep(0.1)
                continue
            
            loop_start = time.time()
            
            # 1. é¢„å¤„ç†
            preprocess_start = time.time()
            input_data = preprocess_matched_resolution(frame, dtype=np.float16)
            preprocess_time = (time.time() - preprocess_start) * 1000
            
            # 2. Atlasæ¨ç†
            inference_start = time.time()
            outputs = model.infer([input_data])
            inference_time = (time.time() - inference_start) * 1000
            
            # 3. åå¤„ç†
            postprocess_start = time.time()
            lane_mask = postprocess_matched_resolution(outputs[0], actual_w, actual_h)
            postprocess_time = (time.time() - postprocess_start) * 1000
            
            # 4. é€è§†å˜æ¢å’Œè·¯å¾„è§„åˆ’
            transform_start = time.time()
            
            # ä½¿ç”¨ä¸å•æ–‡ä»¶æ¨ç†ç›¸åŒçš„é€»è¾‘ï¼Œåº”ç”¨è¾¹ç¼˜è®¡ç®—ä¼˜åŒ–
            if full_image_bird_eye:
                # å®Œæ•´å›¾åƒæ¨¡å¼ï¼šåº”ç”¨ä¸å•æ–‡ä»¶æ¨ç†ç›¸åŒçš„è¾¹ç¼˜è®¡ç®—ä¼˜åŒ–
                adjusted_pixels_per_unit = 1  # ä¸å•æ–‡ä»¶æ¨ç†ç›¸åŒï¼šè¾¹ç¼˜è®¡ç®—æè‡´ä¼˜åŒ–
                print(f"âš¡ è¾¹ç¼˜è®¡ç®—æè‡´ä¼˜åŒ–ï¼šåƒç´ å¯†åº¦ = {adjusted_pixels_per_unit} åƒç´ /å•ä½")
            else:
                # A4çº¸åŒºåŸŸæ¨¡å¼ï¼šä½¿ç”¨è¾ƒé«˜åƒç´ å¯†åº¦
                adjusted_pixels_per_unit = 20
                print(f"ğŸ”§ A4çº¸åŒºåŸŸé¸Ÿç°å›¾æ¨¡å¼ï¼šåƒç´ å¯†åº¦ = {adjusted_pixels_per_unit} åƒç´ /å•ä½")
            
            transformer = PerspectiveTransformer()
            bird_eye_image, bird_eye_mask, view_params = transformer.transform_image_and_mask(
                frame, lane_mask, pixels_per_unit=adjusted_pixels_per_unit, margin_ratio=0.1, full_image=full_image_bird_eye)
            
            # è·¯å¾„è§„åˆ’ - ä½¿ç”¨ä¸å•æ–‡ä»¶æ¨ç†ç›¸åŒçš„å‚æ•°
            control_map, path_data = create_control_map(
                bird_eye_mask, view_params, 
                add_grid=True, add_path=True,
                path_smooth_method='polynomial',
                path_degree=3,
                num_waypoints=20,
                min_road_width=10,
                edge_computing=True, 
                force_bottom_center=True
            )
            transform_time = (time.time() - transform_start) * 1000
            
            # æ£€æŸ¥Webç•Œé¢å‚æ•°æ›´æ–°
            if enable_web and enable_control and controller:
                with web_data_lock:
                    if web_data.get('params_updated', False):
                        # åº”ç”¨æ–°å‚æ•°åˆ°æ§åˆ¶å™¨
                        new_params = web_data['control_params']
                        controller.steering_gain = new_params['steering_gain']
                        controller.base_pwm = new_params['base_speed']
                        controller.preview_distance = new_params['preview_distance']
                        
                        web_data['params_updated'] = False  # é‡ç½®æ ‡å¿—
                        print(f"ğŸ›ï¸ æ§åˆ¶å‚æ•°å·²æ›´æ–°: è½¬å‘å¢ç›Š={controller.steering_gain}, "
                              f"åŸºç¡€PWM={controller.base_pwm}, é¢„ç„è·ç¦»={controller.preview_distance}cm")
            
            # 5. æ§åˆ¶è®¡ç®—
            control_time = 0
            control_result = None
            if enable_control and path_data is not None:
                control_start = time.time()
                control_result = controller.compute_wheel_pwm(path_data, view_params)
                control_time = (time.time() - control_start) * 1000
            
            # æ€§èƒ½ç»Ÿè®¡
            frame_count += 1
            total_times["preprocess"] += preprocess_time
            total_times["inference"] += inference_time
            total_times["postprocess"] += postprocess_time
            total_times["transform"] += transform_time
            total_times["control"] += control_time
            
            pipeline_latency = (time.time() - loop_start) * 1000
            
            # æ¯20å¸§è¾“å‡ºä¸€æ¬¡è¯¦ç»†ç»Ÿè®¡
            if frame_count % 20 == 0:
                elapsed = time.time() - start_time
                avg_fps = frame_count / elapsed
                
                avg_preprocess = total_times["preprocess"] / frame_count
                avg_inference = total_times["inference"] / frame_count
                avg_postprocess = total_times["postprocess"] / frame_count
                avg_transform = total_times["transform"] / frame_count
                avg_control = total_times["control"] / frame_count
                avg_total = sum(total_times.values()) / frame_count
                
                logger.info(f"ğŸ“Š ç¬¬{frame_count}å¸§æ€§èƒ½åˆ†æ:")
                logger.info(f"   é¢„å¤„ç†: {preprocess_time:.1f}ms (å¹³å‡: {avg_preprocess:.1f}ms)")
                logger.info(f"   Atlasæ¨ç†: {inference_time:.1f}ms (å¹³å‡: {avg_inference:.1f}ms)")
                logger.info(f"   åå¤„ç†: {postprocess_time:.1f}ms (å¹³å‡: {avg_postprocess:.1f}ms)")
                logger.info(f"   é€è§†å˜æ¢: {transform_time:.1f}ms (å¹³å‡: {avg_transform:.1f}ms)")
                if enable_control:
                    logger.info(f"   æ§åˆ¶è®¡ç®—: {control_time:.1f}ms (å¹³å‡: {avg_control:.1f}ms)")
                logger.info(f"   æ€»å»¶è¿Ÿ: {pipeline_latency:.1f}ms (å¹³å‡: {avg_total:.1f}ms)")
                logger.info(f"   å®é™…FPS: {avg_fps:.1f}, ç†è®ºFPS: {1000/avg_total:.1f}")
                
                # æ§åˆ¶ä¿¡æ¯
                if control_result:
                    logger.info(f"ğŸš— æ§åˆ¶æŒ‡ä»¤: å·¦è½®={control_result['pwm_left']:.0f}, å³è½®={control_result['pwm_right']:.0f}")
                    logger.info(f"   æ¨ªå‘è¯¯å·®: {control_result['lateral_error']:.2f}cm, æ›²ç‡: {control_result.get('curvature_level', 0):.4f}")
            
            # æ£€æµ‹è½¦é“çº¿
            lane_pixels = np.sum(lane_mask > 0)
            total_pixels = lane_mask.shape[0] * lane_mask.shape[1]
            lane_ratio = (lane_pixels / total_pixels) * 100
            
            # æ¯å¸§ç®€è¦æ—¥å¿—
            if control_result:
                logger.info(f"å¸§{frame_count}: å»¶è¿Ÿ{pipeline_latency:.1f}ms, è½¦é“çº¿{lane_ratio:.1f}%, "
                          f"æ§åˆ¶[L:{control_result['pwm_left']:.0f}, R:{control_result['pwm_right']:.0f}]")
                # æ¯å¸§è¯¦ç»†æ§åˆ¶ä¿¡æ¯
                logger.info(f"   ğŸš— æ¨ªå‘è¯¯å·®: {control_result['lateral_error']:.2f}cm, "
                          f"æ›²ç‡: {control_result.get('curvature_level', 0):.4f}, "
                          f"è½¬å‘: {control_result.get('turn_direction', 'unknown')}")
            else:
                logger.info(f"å¸§{frame_count}: å»¶è¿Ÿ{pipeline_latency:.1f}ms, è½¦é“çº¿{lane_ratio:.1f}%")
            
            # æ›´æ–°Webç•Œé¢æ•°æ®
            if enable_web:
                with web_data_lock:
                    web_data['frame_count'] = frame_count
                    
                    # è°ƒè¯•ä¿¡æ¯
                    if control_map is not None:
                        print(f"ğŸ–¼ï¸ ç”Ÿæˆæ§åˆ¶åœ°å›¾: {control_map.shape}, æ•°æ®ç±»å‹: {control_map.dtype}")
                        web_data['latest_control_map'] = control_map.copy()
                    else:
                        print("âš ï¸ æ§åˆ¶åœ°å›¾ä¸ºNone")
                        web_data['latest_control_map'] = None
                        
                    web_data['latest_stats'] = {
                        'latency': pipeline_latency,
                        'lane_ratio': lane_ratio,
                        'left_pwm': control_result['pwm_left'] if control_result else 0,
                        'right_pwm': control_result['pwm_right'] if control_result else 0,
                        'lateral_error': control_result['lateral_error'] if control_result else 0,
                        'path_curvature': control_result.get('curvature_level', 0) if control_result else 0
                    }
            
            # æ£€æµ‹é€€å‡ºæ¡ä»¶ï¼ˆä»…åœ¨æœ‰GUIæ—¶æ£€æŸ¥æŒ‰é”®ï¼‰
            if not no_gui:
                try:
                    if cv2.waitKey(1) & 0xFF == 27:  # ESCé”®
                        logger.info("ğŸ›‘ ç”¨æˆ·æŒ‰ESCé”®é€€å‡º")
                        break
                except cv2.error:
                    # å¦‚æœOpenCV GUIä¸å¯ç”¨ï¼Œå¿½ç•¥é”™è¯¯
                    logger.warning("âš ï¸ OpenCV GUIä¸å¯ç”¨ï¼Œæ— æ³•æ£€æµ‹æŒ‰é”®")
                    no_gui = True  # è‡ªåŠ¨åˆ‡æ¢åˆ°æ— GUIæ¨¡å¼
            else:
                # æ— GUIæ¨¡å¼ä¸‹å¯ä»¥é€šè¿‡å…¶ä»–æ–¹å¼é€€å‡ºï¼Œä¾‹å¦‚æ–‡ä»¶æ ‡å¿—
                time.sleep(0.001)  # çŸ­æš‚ä¼‘çœ é¿å…è¿‡åº¦å ç”¨CPU
                
    except KeyboardInterrupt:
        logger.info("ğŸ›‘ ç”¨æˆ·ä¸­æ–­ (Ctrl+C)")
    except Exception as e:
        logger.error(f"âŒ å®æ—¶æ¨ç†é”™è¯¯: {e}")
        import traceback
        logger.error(traceback.format_exc())
    finally:
        # æ›´æ–°Webç•Œé¢çŠ¶æ€
        if enable_web:
            with web_data_lock:
                web_data['is_running'] = False
                
        cap.release()
        
        # ä»…åœ¨éæ— GUIæ¨¡å¼ä¸‹è°ƒç”¨OpenCV GUIå‡½æ•°
        if not no_gui:
            try:
                cv2.destroyAllWindows()
            except cv2.error:
                # å¿½ç•¥OpenCV GUIç›¸å…³é”™è¯¯
                pass
                
        logger.info("ğŸ”š å®æ—¶æ¨ç†ç³»ç»Ÿå·²å…³é—­")

# ---------------------------------------------------------------------------------
# --- ğŸŒ Webç•Œé¢æ¨¡å— ---
# ---------------------------------------------------------------------------------

# Webç•Œé¢ç›¸å…³å…¨å±€å˜é‡
web_data = {
    'latest_frame': None,
    'latest_control_map': None,
    'latest_stats': {},
    'is_running': False,
    'frame_count': 0,
    'start_time': None,
    'control_params': {
        'steering_gain': 10.0,
        'base_speed': 500.0,
        'preview_distance': 30.0
    },
    'params_updated': False
}
web_data_lock = Lock()

# HTMLæ¨¡æ¿
WEB_TEMPLATE = """
<!DOCTYPE html>
<html>
<head>
    <title>å®æ—¶è½¦é“çº¿åˆ†å‰²æ§åˆ¶å°</title>
    <meta charset="utf-8">
    <style>
        body { 
            font-family: Arial, sans-serif; 
            background: #1a1a1a; 
            color: #fff; 
            margin: 0; 
            padding: 20px; 
        }
        .container { 
            max-width: 1200px; 
            margin: 0 auto; 
        }
        .header { 
            text-align: center; 
            margin-bottom: 30px; 
            padding: 20px; 
            background: #2d2d2d; 
            border-radius: 10px; 
        }
        .stats-panel {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 15px;
            margin-bottom: 30px;
        }
        .stat-card {
            background: #2d2d2d;
            padding: 15px;
            border-radius: 8px;
            text-align: center;
        }
        .stat-value {
            font-size: 24px;
            font-weight: bold;
            color: #4CAF50;
        }
        .stat-label {
            font-size: 14px;
            color: #ccc;
        }
        .image-panel {
            background: #2d2d2d;
            padding: 20px;
            border-radius: 10px;
            text-align: center;
        }
        .control-map {
            max-width: 100%;
            border: 2px solid #4CAF50;
            border-radius: 8px;
        }
        .status-indicator {
            display: inline-block;
            width: 12px;
            height: 12px;
            border-radius: 50%;
            margin-right: 8px;
        }
        .status-running { background: #4CAF50; }
        .status-stopped { background: #f44336; }
        .log-panel {
            background: #2d2d2d;
            padding: 20px;
            border-radius: 10px;
            margin-top: 20px;
            max-height: 300px;
            overflow-y: auto;
        }
        .log-entry {
            margin-bottom: 5px;
            font-family: monospace;
            font-size: 12px;
        }
        .param-panel {
            background: #2d2d2d;
            padding: 20px;
            border-radius: 10px;
            margin-bottom: 20px;
        }
        .param-control {
            display: flex;
            align-items: center;
            margin-bottom: 15px;
            gap: 15px;
        }
        .param-label {
            min-width: 120px;
            font-weight: bold;
            color: #4CAF50;
        }
        .param-slider {
            flex: 1;
            height: 6px;
            border-radius: 3px;
            background: #444;
            outline: none;
            -webkit-appearance: none;
        }
        .param-slider::-webkit-slider-thumb {
            -webkit-appearance: none;
            appearance: none;
            width: 20px;
            height: 20px;
            border-radius: 50%;
            background: #4CAF50;
            cursor: pointer;
        }
        .param-value {
            min-width: 80px;
            text-align: center;
            font-weight: bold;
            color: #fff;
        }
        .param-apply {
            background: #4CAF50;
            color: white;
            border: none;
            padding: 10px 20px;
            border-radius: 5px;
            cursor: pointer;
            font-weight: bold;
        }
        .param-apply:hover {
            background: #45a049;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ğŸš— å®æ—¶è½¦é“çº¿åˆ†å‰²æ§åˆ¶å°</h1>
            <p>
                <span id="status-indicator" class="status-indicator status-stopped"></span>
                <span id="status-text">ç³»ç»Ÿåœæ­¢</span>
            </p>
        </div>
        
        <div class="stats-panel">
            <div class="stat-card">
                <div class="stat-value" id="frame-count">0</div>
                <div class="stat-label">å¸§æ•°</div>
            </div>
            <div class="stat-card">
                <div class="stat-value" id="fps">0.0</div>
                <div class="stat-label">FPS</div>
            </div>
            <div class="stat-card">
                <div class="stat-value" id="latency">0</div>
                <div class="stat-label">å»¶è¿Ÿ(ms)</div>
            </div>
            <div class="stat-card">
                <div class="stat-value" id="lane-ratio">0.0</div>
                <div class="stat-label">è½¦é“çº¿è¦†ç›–ç‡(%)</div>
            </div>
            <div class="stat-card">
                <div class="stat-value" id="left-pwm">0</div>
                <div class="stat-label">å·¦è½®PWM</div>
            </div>
            <div class="stat-card">
                <div class="stat-value" id="right-pwm">0</div>
                <div class="stat-label">å³è½®PWM</div>
            </div>
        </div>
        
        <div class="param-panel">
            <h3>ğŸ›ï¸ æ§åˆ¶å‚æ•°å®æ—¶è°ƒæ•´</h3>
            <div class="param-control">
                <span class="param-label">è½¬å‘å¢ç›Š</span>
                <input type="range" class="param-slider" id="steering-gain-slider" 
                       min="1" max="50" step="0.5" value="10">
                <span class="param-value" id="steering-gain-value">10.0</span>
            </div>
            <div class="param-control">
                <span class="param-label">åŸºç¡€PWM</span>
                <input type="range" class="param-slider" id="base-speed-slider" 
                       min="100" max="1000" step="10" value="500">
                <span class="param-value" id="base-speed-value">500</span>
            </div>
            <div class="param-control">
                <span class="param-label">é¢„ç„è·ç¦»(cm)</span>
                <input type="range" class="param-slider" id="preview-distance-slider" 
                       min="10" max="100" step="1" value="30">
                <span class="param-value" id="preview-distance-value">30</span>
            </div>
            <div style="text-align: center; margin-top: 15px;">
                <button class="param-apply" onclick="applyParameters()">åº”ç”¨å‚æ•°</button>
            </div>
        </div>
        
        <div class="image-panel">
            <h3>ğŸ—ºï¸ å®æ—¶æ§åˆ¶åœ°å›¾</h3>
            <img id="control-map" class="control-map" src="/api/control_map" alt="æ§åˆ¶åœ°å›¾åŠ è½½ä¸­...">
        </div>
        
        <div class="log-panel">
            <h3>ğŸ“‹ ç³»ç»Ÿæ—¥å¿—</h3>
            <div id="log-content"></div>
        </div>
    </div>
    
    <script>
        let logEntries = [];
        const maxLogEntries = 50;
        
        function updateStats() {
            fetch('/api/stats')
            .then(response => response.json())
            .then(data => {
                document.getElementById('frame-count').textContent = data.frame_count || 0;
                document.getElementById('fps').textContent = (data.fps || 0).toFixed(1);
                document.getElementById('latency').textContent = Math.round(data.latency || 0);
                document.getElementById('lane-ratio').textContent = (data.lane_ratio || 0).toFixed(1);
                document.getElementById('left-pwm').textContent = Math.round(data.left_pwm || 0);
                document.getElementById('right-pwm').textContent = Math.round(data.right_pwm || 0);
                
                // æ›´æ–°çŠ¶æ€æŒ‡ç¤ºå™¨
                const statusIndicator = document.getElementById('status-indicator');
                const statusText = document.getElementById('status-text');
                if (data.is_running) {
                    statusIndicator.className = 'status-indicator status-running';
                    statusText.textContent = 'ç³»ç»Ÿè¿è¡Œä¸­';
                } else {
                    statusIndicator.className = 'status-indicator status-stopped';
                    statusText.textContent = 'ç³»ç»Ÿåœæ­¢';
                }
                
                // æ·»åŠ æ–°æ—¥å¿—æ¡ç›®
                if (data.latest_log) {
                    addLogEntry(data.latest_log);
                }
            })
            .catch(error => console.error('è·å–çŠ¶æ€å¤±è´¥:', error));
        }
        
        function addLogEntry(logText) {
            const timestamp = new Date().toLocaleTimeString();
            logEntries.push(`[${timestamp}] ${logText}`);
            if (logEntries.length > maxLogEntries) {
                logEntries.shift();
            }
            
            const logContent = document.getElementById('log-content');
            logContent.innerHTML = logEntries.map(entry => 
                `<div class="log-entry">${entry}</div>`
            ).join('');
            logContent.scrollTop = logContent.scrollHeight;
        }
        
        // å®šæœŸæ›´æ–°æ§åˆ¶åœ°å›¾
        function updateControlMap() {
            const img = document.getElementById('control-map');
            img.src = '/api/control_map?' + new Date().getTime();
        }
        
        // å‚æ•°æ»‘å—æ›´æ–°æ˜¾ç¤ºå€¼
        function updateSliderValues() {
            const steeringGain = document.getElementById('steering-gain-slider');
            const steeringValue = document.getElementById('steering-gain-value');
            steeringValue.textContent = parseFloat(steeringGain.value).toFixed(1);
            
            const baseSpeed = document.getElementById('base-speed-slider');
            const baseValue = document.getElementById('base-speed-value');
            baseValue.textContent = baseSpeed.value;
            
            const previewDistance = document.getElementById('preview-distance-slider');
            const previewValue = document.getElementById('preview-distance-value');
            previewValue.textContent = previewDistance.value;
        }
        
        // åº”ç”¨å‚æ•°åˆ°ç³»ç»Ÿ
        function applyParameters() {
            const steeringGain = document.getElementById('steering-gain-slider').value;
            const baseSpeed = document.getElementById('base-speed-slider').value;
            const previewDistance = document.getElementById('preview-distance-slider').value;
            
            const params = {
                steering_gain: parseFloat(steeringGain),
                base_speed: parseFloat(baseSpeed),
                preview_distance: parseFloat(previewDistance)
            };
            
            fetch('/api/update_params', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                },
                body: JSON.stringify(params)
            })
            .then(response => response.json())
            .then(data => {
                if (data.success) {
                    addLogEntry(`å‚æ•°æ›´æ–°æˆåŠŸ: è½¬å‘å¢ç›Š=${steeringGain}, åŸºç¡€PWM=${baseSpeed}, é¢„ç„è·ç¦»=${previewDistance}cm`);
                } else {
                    addLogEntry(`å‚æ•°æ›´æ–°å¤±è´¥: ${data.error}`);
                }
            })
            .catch(error => {
                addLogEntry(`å‚æ•°æ›´æ–°é”™è¯¯: ${error}`);
                console.error('å‚æ•°æ›´æ–°å¤±è´¥:', error);
            });
        }
        
        // ç»‘å®šæ»‘å—äº‹ä»¶
        document.getElementById('steering-gain-slider').addEventListener('input', updateSliderValues);
        document.getElementById('base-speed-slider').addEventListener('input', updateSliderValues);
        document.getElementById('preview-distance-slider').addEventListener('input', updateSliderValues);
        
        // å¯åŠ¨å®šæ—¶æ›´æ–°
        setInterval(updateStats, 1000);  // æ¯ç§’æ›´æ–°çŠ¶æ€
        setInterval(updateControlMap, 2000);  // æ¯2ç§’æ›´æ–°æ§åˆ¶åœ°å›¾
        
        // åˆå§‹åŠ è½½
        updateStats();
        updateSliderValues();
    </script>
</body>
</html>
"""

def create_web_app():
    """åˆ›å»ºFlask Webåº”ç”¨"""
    if not FLASK_AVAILABLE:
        return None
    
    app = Flask(__name__)
    
    @app.route('/')
    def index():
        return render_template_string(WEB_TEMPLATE)
    
    @app.route('/api/stats')
    def get_stats():
        with web_data_lock:
            stats = web_data['latest_stats'].copy()
            stats['is_running'] = web_data['is_running']
            stats['frame_count'] = web_data['frame_count']
            
            # è®¡ç®—FPS
            if web_data['start_time'] and web_data['frame_count'] > 0:
                elapsed = time.time() - web_data['start_time']
                stats['fps'] = web_data['frame_count'] / elapsed if elapsed > 0 else 0
            else:
                stats['fps'] = 0
        
        return jsonify(stats)
    
    @app.route('/api/update_params', methods=['POST'])
    def update_params():
        try:
            params = request.get_json()
            
            # éªŒè¯å‚æ•°
            if not params:
                return jsonify({'success': False, 'error': 'æ— æ•ˆçš„å‚æ•°æ•°æ®'})
            
            # æ›´æ–°å…¨å±€æ§åˆ¶å‚æ•°
            with web_data_lock:
                if 'control_params' not in web_data:
                    web_data['control_params'] = {}
                
                if 'steering_gain' in params:
                    web_data['control_params']['steering_gain'] = float(params['steering_gain'])
                if 'base_speed' in params:
                    web_data['control_params']['base_speed'] = float(params['base_speed'])
                if 'preview_distance' in params:
                    web_data['control_params']['preview_distance'] = float(params['preview_distance'])
                
                # è®¾ç½®æ›´æ–°æ ‡å¿—
                web_data['params_updated'] = True
            
            print(f"ğŸ›ï¸ Webå‚æ•°æ›´æ–°: {params}")
            return jsonify({'success': True, 'message': 'å‚æ•°æ›´æ–°æˆåŠŸ'})
            
        except Exception as e:
            print(f"âŒ å‚æ•°æ›´æ–°é”™è¯¯: {e}")
            return jsonify({'success': False, 'error': str(e)})
    
    @app.route('/api/control_map')
    def get_control_map():
        with web_data_lock:
            if web_data['latest_control_map'] is not None:
                try:
                    # ç¡®ä¿å›¾åƒæ ¼å¼æ­£ç¡®
                    control_map = web_data['latest_control_map']
                    
                    # è°ƒè¯•ä¿¡æ¯
                    print(f"ğŸ–¼ï¸ Webè¯·æ±‚æ§åˆ¶åœ°å›¾: {control_map.shape}, ç±»å‹: {control_map.dtype}")
                    print(f"ğŸ–¼ï¸ æ•°æ®èŒƒå›´: {control_map.min()} ~ {control_map.max()}")
                    
                    # å¦‚æœæ˜¯å•é€šé“å›¾åƒï¼Œè½¬æ¢ä¸º3é€šé“
                    if len(control_map.shape) == 2:
                        control_map = cv2.cvtColor(control_map, cv2.COLOR_GRAY2BGR)
                        print("ğŸ”„ å•é€šé“è½¬æ¢ä¸º3é€šé“")
                    elif control_map.shape[2] == 1:
                        control_map = cv2.cvtColor(control_map, cv2.COLOR_GRAY2BGR)
                        print("ğŸ”„ å•é€šé“è½¬æ¢ä¸º3é€šé“")
                    
                    # ç¡®ä¿æ•°æ®ç±»å‹ä¸ºuint8
                    if control_map.dtype != np.uint8:
                        if control_map.max() <= 1.0:
                            control_map = (control_map * 255).astype(np.uint8)
                            print("ğŸ”„ å½’ä¸€åŒ–æ•°æ®è½¬æ¢ä¸ºuint8")
                        else:
                            control_map = control_map.astype(np.uint8)
                            print("ğŸ”„ æ•°æ®ç±»å‹è½¬æ¢ä¸ºuint8")
                    
                    # å°†OpenCVå›¾åƒè½¬æ¢ä¸ºPNGæ ¼å¼
                    success, buffer = cv2.imencode('.png', control_map)
                    if not success:
                        raise Exception("å›¾åƒç¼–ç å¤±è´¥")
                        
                    print(f"âœ… æ§åˆ¶åœ°å›¾ç¼–ç æˆåŠŸï¼Œbufferé•¿åº¦: {len(buffer)}")
                    
                    # è¿”å›äºŒè¿›åˆ¶å›¾åƒæ•°æ®
                    from flask import Response
                    return Response(
                        buffer.tobytes(),
                        mimetype='image/png',
                        headers={'Cache-Control': 'no-cache, no-store, must-revalidate'}
                    )
                    
                except Exception as e:
                    print(f"âŒ æ§åˆ¶åœ°å›¾ç¼–ç é”™è¯¯: {e}")
                    # è¿”å›é”™è¯¯æç¤ºå›¾ç‰‡
                    empty_img = np.zeros((300, 400, 3), dtype=np.uint8)
                    cv2.putText(empty_img, f"Error: {str(e)[:20]}", (10, 150), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
                    _, buffer = cv2.imencode('.png', empty_img)
                    from flask import Response
                    return Response(
                        buffer.tobytes(),
                        mimetype='image/png'
                    )
            else:
                print("âš ï¸ æ²¡æœ‰å¯ç”¨çš„æ§åˆ¶åœ°å›¾æ•°æ®")
                # è¿”å›ç©ºå›¾ç‰‡å ä½ç¬¦
                empty_img = np.zeros((300, 400, 3), dtype=np.uint8)
                cv2.putText(empty_img, "No Control Map", (50, 150), 
                           cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
                _, buffer = cv2.imencode('.png', empty_img)
                from flask import Response
                return Response(
                    buffer.tobytes(),
                    mimetype='image/png'
                )
    
    return app

def start_web_server(port=5000):
    """å¯åŠ¨WebæœåŠ¡å™¨"""
    if not FLASK_AVAILABLE:
        print("âŒ Flaskæœªå®‰è£…ï¼Œæ— æ³•å¯åŠ¨WebæœåŠ¡å™¨")
        return None
    
    app = create_web_app()
    if app is None:
        return None
    
    def run_server():
        app.run(host='0.0.0.0', port=port, debug=False, use_reloader=False)
    
    server_thread = Thread(target=run_server, daemon=True)
    server_thread.start()
    
    print(f"ğŸŒ Webç•Œé¢å·²å¯åŠ¨: http://localhost:{port}")
    print(f"ğŸŒ å¤–éƒ¨è®¿é—®: http://0.0.0.0:{port}")
    
    return server_thread

# ---------------------------------------------------------------------------------
# --- ğŸ“± å‘½ä»¤è¡Œæ¥å£ ---
# ---------------------------------------------------------------------------------

def main():
    parser = argparse.ArgumentParser(description="é›†æˆæ„ŸçŸ¥ä¸ç¯å¢ƒå»ºæ¨¡çš„è½¦é“çº¿åˆ†å‰²æ¨ç†å·¥å…· - Atlasç‰ˆæœ¬")
    
    # ä¸»è¦æ¨¡å¼é€‰æ‹©
    parser.add_argument("--realtime", action="store_true", help="å®æ—¶æ‘„åƒå¤´æ¨ç†æ¨¡å¼")
    parser.add_argument("--input", "-i", help="è¾“å…¥å›¾ç‰‡è·¯å¾„ (å•å¼ å›¾ç‰‡æ¨¡å¼)")
    parser.add_argument("--output", "-o", help="è¾“å‡ºå¯è§†åŒ–å›¾ç‰‡è·¯å¾„ï¼ˆå¯é€‰ï¼‰")
    parser.add_argument("--save_mask", help="ä¿å­˜åˆ†å‰²æ©ç è·¯å¾„ï¼ˆå¯é€‰ï¼‰")
    
    # æ¨¡å‹å’Œè®¾å¤‡å‚æ•°
    parser.add_argument("--model", "-m", 
                       default="./weights/fast_scnn_custom_e2e_360x640_fp16_fixed_simp.om",
                       help="OMæ¨¡å‹è·¯å¾„")
    parser.add_argument("--device_id", type=int, default=0, help="Atlas NPUè®¾å¤‡ID")
    
    # æ‘„åƒå¤´å‚æ•°
    parser.add_argument("--camera_index", type=int, default=0, help="æ‘„åƒå¤´ç´¢å¼•")
    parser.add_argument("--camera_width", type=int, default=640, help="æ‘„åƒå¤´å®½åº¦")
    parser.add_argument("--camera_height", type=int, default=360, help="æ‘„åƒå¤´é«˜åº¦")
    
    # æ—¥å¿—å‚æ•°
    parser.add_argument("--log_file", help="æ—¥å¿—æ–‡ä»¶è·¯å¾„ (å®æ—¶æ¨¡å¼)")
    
    # å›¾åƒå¤„ç†å‚æ•°
    parser.add_argument("--pixels_per_unit", type=int, default=20, help="æ¯å•ä½åƒç´ æ•° (é»˜è®¤: 20)")
    parser.add_argument("--margin_ratio", type=float, default=0.1, help="è¾¹è·æ¯”ä¾‹ (é»˜è®¤: 0.1)")
    parser.add_argument("--no_vis", action="store_true", help="ä¸ä¿å­˜å¯è§†åŒ–ç»“æœï¼Œä»…æ¨ç†")
    parser.add_argument("--bird_eye", action="store_true", help="ç”Ÿæˆé¸Ÿç°å›¾ï¼ˆä½¿ç”¨å†…ç½®A4çº¸æ ‡å®šï¼‰")
    parser.add_argument("--no_full_image_bird_eye", action="store_true", help="ä»…ç”ŸæˆA4çº¸åŒºåŸŸé¸Ÿç°å›¾ï¼ˆé»˜è®¤ç”Ÿæˆå®Œæ•´åŸå›¾ï¼‰")
    parser.add_argument("--save_control_map", action="store_true", help="ä¿å­˜æ§åˆ¶åœ°å›¾å¹¶è¿›è¡Œè·¯å¾„è§„åˆ’")
    parser.add_argument("--path_smooth_method", default="polynomial", choices=["polynomial", "spline"], help="è·¯å¾„å¹³æ»‘æ–¹æ³•")
    parser.add_argument("--path_degree", type=int, default=3, help="è·¯å¾„æ‹Ÿåˆé˜¶æ•°")
    parser.add_argument("--num_waypoints", type=int, default=20, help="è·¯å¾„ç‚¹æ•°é‡")
    parser.add_argument("--min_road_width", type=int, default=10, help="æœ€å°å¯è¡Œé©¶å®½åº¦ï¼ˆåƒç´ ï¼‰")
    parser.add_argument("--force_bottom_center", action="store_true", default=True, help="å¼ºåˆ¶æ‹Ÿåˆæ›²çº¿è¿‡åº•è¾¹ä¸­ç‚¹")
    parser.add_argument("--edge_computing", action="store_true", help="è¾¹ç¼˜è®¡ç®—æ¨¡å¼ï¼ˆæè‡´æ€§èƒ½ä¼˜åŒ–ï¼‰")
    parser.add_argument("--preview", action="store_true", help="æ˜¾ç¤ºé¢„è§ˆçª—å£")
    
    # æ§åˆ¶ç®—æ³•å‚æ•°
    parser.add_argument("--enable_control", action="store_true", help="å¯ç”¨è§†è§‰æ¨ªå‘è¯¯å·®æ§åˆ¶ç®—æ³•")
    parser.add_argument("--steering_gain", type=float, default=10.0, help="è½¬å‘å¢ç›ŠKp (é»˜è®¤: 10.0)")
    parser.add_argument("--base_speed", type=float, default=500.0, help="åŸºç¡€PWMå€¼ -1000~+1000 (é»˜è®¤: 500)")
    parser.add_argument("--curvature_damping", type=float, default=0.1, help="æ›²ç‡é˜»å°¼ç³»æ•° (é»˜è®¤: 0.1)")
    parser.add_argument("--preview_distance", type=float, default=30.0, help="é¢„ç„è·ç¦» cm (é»˜è®¤: 30.0)")
    parser.add_argument("--max_speed", type=float, default=800.0, help="æœ€å¤§PWMå€¼ -1000~+1000 (é»˜è®¤: 800)")
    parser.add_argument("--min_speed", type=float, default=100.0, help="æœ€å°PWMå€¼ï¼Œå‰è¿›æ—¶æœ€ä½é€Ÿåº¦ (é»˜è®¤: 100)")
    
    # Webç•Œé¢å’ŒGUIé€‰é¡¹
    parser.add_argument("--web", action="store_true", help="å¯ç”¨Webç•Œé¢")
    parser.add_argument("--web_port", type=int, default=5000, help="Webç•Œé¢ç«¯å£ (é»˜è®¤: 5000)")
    parser.add_argument("--no_gui", action="store_true", help="æ— GUIæ¨¡å¼ï¼ˆä¸æ˜¾ç¤ºOpenCVçª—å£ï¼Œä»…è¾“å‡ºç»“æœï¼‰")
    
    args = parser.parse_args()
    
    try:
        print("ğŸ§  é›†æˆæ„ŸçŸ¥ä¸ç¯å¢ƒå»ºæ¨¡çš„è½¦é“çº¿åˆ†å‰²æ¨ç†å·¥å…· - Atlasç‰ˆæœ¬")
        print("=" * 60)
        print("ğŸ“ åŠŸèƒ½: è½¦é“çº¿åˆ†å‰² + é€è§†å˜æ¢ + æ§åˆ¶åœ°å›¾ç”Ÿæˆ")
        print("ğŸ“ å†…ç½®æ ‡å®š: åŸºäºA4çº¸çš„é€è§†å˜æ¢å‚æ•°")
        print("ğŸš€ æ¨ç†è®¾å¤‡: Atlas NPU")
        print("=" * 60)
        
        # å®æ—¶æ¨¡å¼
        if args.realtime:
            print("ğŸ¬ å¯åŠ¨å®æ—¶æ‘„åƒå¤´æ¨ç†æ¨¡å¼")
            
            # å¯åŠ¨WebæœåŠ¡å™¨ï¼ˆå¦‚æœéœ€è¦ï¼‰
            web_server = None
            if args.web:
                print("ğŸŒ å¯åŠ¨Webç•Œé¢...")
                web_server = start_web_server(args.web_port)
                time.sleep(2)  # ç­‰å¾…æœåŠ¡å™¨å¯åŠ¨
                if args.no_gui:
                    print("ğŸ’¡ æç¤ºï¼šæ— GUIæ¨¡å¼ä¸‹ï¼Œè¯·é€šè¿‡Webç•Œé¢æŸ¥çœ‹å®æ—¶çŠ¶æ€")
            
            realtime_inference(
                model_path=args.model,
                device_id=args.device_id,
                camera_index=args.camera_index,
                camera_width=args.camera_width,
                camera_height=args.camera_height,
                log_file=args.log_file,
                enable_control=args.enable_control,
                steering_gain=args.steering_gain,
                base_speed=args.base_speed,
                curvature_damping=args.curvature_damping,
                preview_distance=args.preview_distance,
                max_speed=args.max_speed,
                min_speed=args.min_speed,
                enable_web=args.web,
                no_gui=args.no_gui,
                full_image_bird_eye=not args.no_full_image_bird_eye  # åè½¬é€»è¾‘
            )
            return
        
        # å•å¼ å›¾ç‰‡æ¨¡å¼
        if not args.input:
            print("âŒ é”™è¯¯ï¼šè¯·æŒ‡å®š --input è¾“å…¥å›¾ç‰‡è·¯å¾„æˆ–ä½¿ç”¨ --realtime è¿›å…¥å®æ—¶æ¨¡å¼")
            parser.print_help()
            sys.exit(1)
        
        # è‡ªåŠ¨ç¡®å®šè¾“å‡ºè·¯å¾„
        save_visualization = not args.no_vis
        save_mask = bool(args.save_mask)
        
        # éªŒè¯è¾“å…¥æ–‡ä»¶å­˜åœ¨
        if not os.path.exists(args.input):
            print(f"âŒ é”™è¯¯ï¼šè¾“å…¥å›¾ç‰‡ä¸å­˜åœ¨: {args.input}")
            sys.exit(1)
        
        # æ‰§è¡Œæ¨ç†
        results = inference_single_image(
            image_path=args.input,
            model_path=args.model,
            device_id=args.device_id,
            save_visualization=save_visualization,
            save_mask=save_mask,
            bird_eye=args.bird_eye,
            save_control_map=args.save_control_map,
            pixels_per_unit=args.pixels_per_unit,
            margin_ratio=args.margin_ratio,
            full_image_bird_eye=args.full_image_bird_eye,
            path_smooth_method=args.path_smooth_method,
            path_degree=args.path_degree,
            num_waypoints=args.num_waypoints,
            min_road_width=args.min_road_width,
            edge_computing=args.edge_computing,
            force_bottom_center=args.force_bottom_center,
            enable_control=args.enable_control,
            steering_gain=args.steering_gain,
            base_speed=args.base_speed,
            curvature_damping=args.curvature_damping,
            preview_distance=args.preview_distance,
            max_speed=args.max_speed,
            min_speed=args.min_speed
        )
        
        # å¤„ç†è¾“å‡ºè·¯å¾„é‡å‘½å
        if args.output and 'visualization_path' in results:
            import shutil
            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            output_dir = os.path.dirname(args.output)
            if output_dir and not os.path.exists(output_dir):
                os.makedirs(output_dir)
            
            # ç§»åŠ¨å¯è§†åŒ–ç»“æœåˆ°æŒ‡å®šè·¯å¾„
            shutil.move(results['visualization_path'], args.output)
            results['visualization_path'] = args.output
            print(f"ğŸ’¾ å¯è§†åŒ–ç»“æœå·²ç§»åŠ¨åˆ°æŒ‡å®šè·¯å¾„: {args.output}")
        
        # å¤„ç†æ©ç è·¯å¾„é‡å‘½å
        if args.save_mask and 'mask_path' in results:
            import shutil
            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            mask_dir = os.path.dirname(args.save_mask)
            if mask_dir and not os.path.exists(mask_dir):
                os.makedirs(mask_dir)
            
            # ç§»åŠ¨åˆ†å‰²æ©ç åˆ°æŒ‡å®šè·¯å¾„
            shutil.move(results['mask_path'], args.save_mask)
            results['mask_path'] = args.save_mask
            print(f"ğŸ’¾ åˆ†å‰²æ©ç å·²ç§»åŠ¨åˆ°æŒ‡å®šè·¯å¾„: {args.save_mask}")
        
        # é¢„è§ˆç»“æœï¼ˆå¯é€‰ï¼‰
        if args.preview:
            print("ğŸ‘ï¸ æ˜¾ç¤ºé¢„è§ˆ...")
            original = cv2.imread(args.input)
            
            if 'visualization_path' in results:
                vis_result = cv2.imread(results['visualization_path'])
                cv2.imshow("Original Image", original)
                cv2.imshow("Segmentation Result", vis_result)
            
            if 'bird_eye_vis_path' in results:
                bird_eye_vis = cv2.imread(results['bird_eye_vis_path'])
                cv2.imshow("Bird's Eye View Segmentation", bird_eye_vis)
            
            if 'control_map_path' in results:
                control_map = cv2.imread(results['control_map_path'])
                cv2.imshow("Control Map", control_map)
            
            print("æŒ‰ä»»æ„é”®å…³é—­é¢„è§ˆ...")
            cv2.waitKey(0)
            cv2.destroyAllWindows()
        
        print("\nâœ… Atlasæ¨ç†ä¸ç¯å¢ƒå»ºæ¨¡å®Œæˆï¼")
        print("ğŸ”§ æ­¤ç»“æœå¯ç”¨äºåç»­çš„è·¯å¾„è§„åˆ’å’Œè½¦è¾†æ§åˆ¶")
        
        if 'visualization_path' in results:
            print(f"ğŸ¨ åˆ†å‰²å¯è§†åŒ–: {results['visualization_path']}")
        if 'mask_path' in results:
            print(f"ğŸ­ åˆ†å‰²æ©ç : {results['mask_path']}")
        if 'bird_eye_vis_path' in results:
            print(f"ğŸ¦… é¸Ÿç°å›¾åˆ†å‰²: {results['bird_eye_vis_path']}")
        if 'control_map_path' in results:
            print(f"ğŸ—ºï¸ æ§åˆ¶åœ°å›¾: {results['control_map_path']}")
        if 'path_json_path' in results:
            print(f"ğŸ›£ï¸ è·¯å¾„æ•°æ®: {results['path_json_path']}")
        if 'control_json_path' in results:
            print(f"ğŸš— æ§åˆ¶æ•°æ®: {results['control_json_path']}")
        if 'control_vis_path' in results:
            print(f"ğŸ® æ§åˆ¶å¯è§†åŒ–: {results['control_vis_path']}")
            
    except Exception as e:
        print(f"âŒ æ¨ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

def save_path_data_json(path_data, json_path):
    """
    å°†è·¯å¾„æ•°æ®ä¿å­˜ä¸ºJSONæ–‡ä»¶
    
    å‚æ•°ï¼š
        path_data: è·¯å¾„æ•°æ®å­—å…¸
        json_path: JSONæ–‡ä»¶è·¯å¾„
    """
    # å‡†å¤‡å¯åºåˆ—åŒ–çš„æ•°æ®
    json_data = {
        'centerline_world': path_data['centerline_world'],
        'waypoints': path_data['waypoints'],
        'path_length': path_data['path_length'],
        'num_centerline_points': path_data['num_centerline_points'],
        'num_waypoints': path_data['num_waypoints'],
        'fit_params': path_data['fit_params'].tolist() if path_data['fit_params'] is not None else None,
        'description': 'è½¦é“ä¸­å¿ƒçº¿å’Œè·¯å¾„ç‚¹æ•°æ®ï¼ˆä¸–ç•Œåæ ‡ï¼Œå•ä½ï¼šå˜ç±³ï¼‰',
        'coordinate_system': 'world coordinates (cm)',
        'waypoints_description': 'è·¯å¾„ç‚¹ï¼Œå¯ç›´æ¥ç”¨äºè½¦è¾†æ§åˆ¶'
    }
    
    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(json_data, f, indent=2, ensure_ascii=False)

if __name__ == "__main__":
    main()
