#!/usr/bin/env python3
"""
æ ‡å®šæ¨¡å— - é€è§†å˜æ¢æ ‡å®šå‚æ•°ç®¡ç†

åŸºäºç”¨æˆ·æä¾›çš„A4çº¸æ ‡å®šç‚¹è¿›è¡Œé€è§†å˜æ¢å‚æ•°è®¡ç®—ã€‚
åŒ…å«å†…ç½®æ ‡å®šå‚æ•°å’Œæ ¡æ­£åçš„æ ‡å®šå‚æ•°ã€‚
"""

import numpy as np
import cv2

# ---------------------------------------------------------------------------------
# --- ğŸ”§ å†…ç½®æ ‡å®šå‚æ•° (åŸºäºç”¨æˆ·æä¾›çš„æ ‡å®šç‚¹) ---
# ---------------------------------------------------------------------------------

def get_builtin_calibration():
    """
    è·å–å†…ç½®çš„æ ‡å®šå‚æ•° (åŸºäºç”¨æˆ·æ ‡å®šçš„A4çº¸)
    
    æ ‡å®šä¿¡æ¯ï¼š
    - å›¾åƒå°ºå¯¸: 640Ã—360
    - æ ‡è®°ç‰©: A4çº¸ (21.0cm Ã— 29.7cm)
    - å›¾åƒç‚¹: [(260, 87), (378, 87), (410, 217), (231, 221)]
    - ä¸–ç•Œç‚¹: [(0, 0), (21, 0), (21, 29.7), (0, 29.7)]  # A4çº¸å››ä¸ªè§’
    """
    # å›¾åƒä¸­çš„4ä¸ªç‚¹ (åƒç´ åæ ‡)
    image_points = [(260, 87), (378, 87), (410, 217), (231, 221)]
    
    # çœŸå®ä¸–ç•Œä¸­çš„å¯¹åº”ç‚¹ (å˜ç±³) - A4çº¸çš„å››ä¸ªè§’
    world_points = [(0, 0), (21, 0), (21, 29.7), (0, 29.7)]
    
    # è®¡ç®—é€è§†å˜æ¢çŸ©é˜µ
    src_points = np.float32(image_points)
    dst_points = np.float32(world_points)
    
    transform_matrix = cv2.getPerspectiveTransform(src_points, dst_points)
    inverse_transform_matrix = cv2.getPerspectiveTransform(dst_points, src_points)
    
    calibration_data = {
        'image_size': [640, 360],
        'image_points': image_points,
        'world_points': world_points,
        'transform_matrix': transform_matrix.tolist(),
        'inverse_transform_matrix': inverse_transform_matrix.tolist(),
        'description': 'åŸºäºA4çº¸æ ‡å®šçš„é€è§†å˜æ¢å‚æ•°',
        'units': 'centimeters'
    }
    
    return calibration_data

def get_corrected_calibration():
    """
    è·å–æ ¡æ­£åçš„æ ‡å®šå‚æ•°ï¼Œç¡®ä¿640Ã—360åŸå§‹å›¾åƒåœ¨é¸Ÿç°å›¾ä¸­ä¸Šä¸‹è¾¹ç•Œå¹³è¡Œ
    
    æ ¸å¿ƒæ€è·¯ï¼š
    1. ä½¿ç”¨A4çº¸çš„4ä¸ªæ ‡å®šç‚¹ä½œä¸ºå‚è€ƒ
    2. è®¡ç®—æ•´ä¸ª640Ã—360å›¾åƒçš„4ä¸ªè§’ç‚¹åœ¨ä¸–ç•Œåæ ‡ä¸­çš„ä½ç½®
    3. å¼ºåˆ¶å›¾åƒçš„ä¸Šè¾¹ç•Œå’Œä¸‹è¾¹ç•Œåœ¨ä¸–ç•Œåæ ‡ä¸­Yå€¼ç›¸ç­‰ï¼ˆå¹³è¡Œï¼‰
    4. é‡æ–°è®¡ç®—æ ¡æ­£åçš„é€è§†å˜æ¢çŸ©é˜µ
    """
    # è·å–åŸå§‹æ ‡å®š
    original_cal = get_builtin_calibration()
    original_transform = np.array(original_cal['transform_matrix'], dtype=np.float32)
    
    # 640Ã—360å›¾åƒçš„å››ä¸ªè§’ç‚¹ï¼ˆåƒç´ åæ ‡ï¼‰
    img_corners = np.array([
        [0, 0, 1],           # å·¦ä¸Šè§’
        [639, 0, 1],         # å³ä¸Šè§’  
        [639, 359, 1],       # å³ä¸‹è§’
        [0, 359, 1]          # å·¦ä¸‹è§’
    ], dtype=np.float32)
    
    # ä½¿ç”¨åŸå§‹å˜æ¢å°†å›¾åƒè§’ç‚¹æŠ•å½±åˆ°ä¸–ç•Œåæ ‡
    world_corners = []
    for corner in img_corners:
        world_pt = original_transform @ corner
        world_x = world_pt[0] / world_pt[2]
        world_y = world_pt[1] / world_pt[2]
        world_corners.append([world_x, world_y])
    
    world_corners = np.array(world_corners)
    
    # æ ¡æ­£ä¸–ç•Œåæ ‡ï¼šå¼ºåˆ¶ä¸Šä¸‹è¾¹ç•Œå¹³è¡Œ
    # ä¸Šè¾¹ç•Œï¼šå·¦ä¸Šè§’å’Œå³ä¸Šè§’çš„Yåæ ‡å–å¹³å‡å€¼
    # ä¸‹è¾¹ç•Œï¼šå·¦ä¸‹è§’å’Œå³ä¸‹è§’çš„Yåæ ‡å–å¹³å‡å€¼
    top_y = (world_corners[0][1] + world_corners[1][1]) / 2  # ä¸Šè¾¹ç•ŒY
    bottom_y = (world_corners[2][1] + world_corners[3][1]) / 2  # ä¸‹è¾¹ç•ŒY
    
    # ä¿æŒXåæ ‡ä¸å˜ï¼Œåªæ ¡æ­£Yåæ ‡
    corrected_world_corners = [
        [world_corners[0][0], top_y],     # å·¦ä¸Šè§’
        [world_corners[1][0], top_y],     # å³ä¸Šè§’ - Yä¸å·¦ä¸Šè§’ç›¸åŒ
        [world_corners[2][0], bottom_y],  # å³ä¸‹è§’
        [world_corners[3][0], bottom_y]   # å·¦ä¸‹è§’ - Yä¸å³ä¸‹è§’ç›¸åŒ
    ]
    
    # é‡æ–°è®¡ç®—é€è§†å˜æ¢çŸ©é˜µ
    # ä»640Ã—360å›¾åƒè§’ç‚¹åˆ°æ ¡æ­£åçš„ä¸–ç•Œåæ ‡
    src_points = np.float32([[0, 0], [639, 0], [639, 359], [0, 359]])
    dst_points = np.float32(corrected_world_corners);
    
    transform_matrix = cv2.getPerspectiveTransform(src_points, dst_points)
    inverse_transform_matrix = cv2.getPerspectiveTransform(dst_points, src_points)
    
    # ä¿æŒåŸå§‹A4çº¸æ ‡å®šç‚¹ç”¨äºæ˜¾ç¤º
    corrected_calibration = {
        'image_size': [640, 360],
        'image_points': original_cal['image_points'],  # ä¿æŒA4çº¸æ ‡å®šç‚¹
        'world_points': original_cal['world_points'],  # ä¿æŒA4çº¸ä¸–ç•Œåæ ‡
        'transform_matrix': transform_matrix.tolist(),
        'inverse_transform_matrix': inverse_transform_matrix.tolist(),
        'corrected_world_corners': corrected_world_corners,
        'original_world_corners': world_corners.tolist(),
        'description': 'æ ¡æ­£åçš„é€è§†å˜æ¢å‚æ•°ï¼ˆç¡®ä¿640Ã—360å›¾åƒä¸Šä¸‹è¾¹ç•Œå¹³è¡Œï¼‰',
        'units': 'centimeters'
    }
    
    print(f"ğŸ”§ é€è§†æ ¡æ­£å®Œæˆ:")
    print(f"   - åŸå§‹ä¸Šè¾¹ç•ŒY: {world_corners[0][1]:.2f} ~ {world_corners[1][1]:.2f} cm")
    print(f"   - æ ¡æ­£ä¸Šè¾¹ç•ŒY: {top_y:.2f} cm (å¹³è¡Œ)")
    print(f"   - åŸå§‹ä¸‹è¾¹ç•ŒY: {world_corners[2][1]:.2f} ~ {world_corners[3][1]:.2f} cm") 
    print(f"   - æ ¡æ­£ä¸‹è¾¹ç•ŒY: {bottom_y:.2f} cm (å¹³è¡Œ)")
    
    return corrected_calibration 