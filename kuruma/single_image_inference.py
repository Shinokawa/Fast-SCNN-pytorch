import os
import cv2
import time
import numpy as np
import argparse
from pathlib import Path

from ais_bench.infer.interface import InferSession

# --- é…ç½®å‚æ•° ---
DEVICE_ID = 0
# ä½¿ç”¨æ‚¨çš„æ¨¡å‹è·¯å¾„
MODEL_PATH = "./weights/fast_scnn_custom_e2e_360x640_fp16_fixed_simp.om"
# æ¨¡å‹è¾“å…¥å°ºå¯¸ï¼šé«˜Ã—å®½ = 360Ã—640
MODEL_WIDTH = 640
MODEL_HEIGHT = 360

# ---------------------------------------------------------------------------------
# --- ğŸš€ğŸš€ğŸš€ å®Œç¾åŒ¹é…çš„é¢„å¤„ç† (640Ã—360) ğŸš€ğŸš€ğŸš€ ---
# ---------------------------------------------------------------------------------

def preprocess_image(img_bgr, target_width=MODEL_WIDTH, target_height=MODEL_HEIGHT, dtype=np.float16):
    """
    é¢„å¤„ç†è¾“å…¥å›¾ç‰‡åˆ°æ¨¡å‹æ‰€éœ€çš„å°ºå¯¸å’Œæ ¼å¼
    
    Args:
        img_bgr: BGRæ ¼å¼çš„è¾“å…¥å›¾ç‰‡
        target_width: ç›®æ ‡å®½åº¦
        target_height: ç›®æ ‡é«˜åº¦
        dtype: æ•°æ®ç±»å‹
    
    Returns:
        processed_img: é¢„å¤„ç†åçš„å›¾ç‰‡ (NCHWæ ¼å¼)
        original_shape: åŸå§‹å›¾ç‰‡å½¢çŠ¶ (height, width)
    """
    original_height, original_width = img_bgr.shape[:2]
    
    # 1. å¦‚æœå°ºå¯¸ä¸åŒ¹é…ï¼Œè¿›è¡Œresize
    if original_width != target_width or original_height != target_height:
        img_resized = cv2.resize(img_bgr, (target_width, target_height), interpolation=cv2.INTER_LINEAR)
        print(f"ğŸ“ å›¾ç‰‡å°ºå¯¸è°ƒæ•´: {original_width}Ã—{original_height} -> {target_width}Ã—{target_height}")
    else:
        img_resized = img_bgr
        print(f"ğŸ¯ å›¾ç‰‡å°ºå¯¸å®Œç¾åŒ¹é…: {original_width}Ã—{original_height}")
    
    # 2. è½¬æ¢é¢œè‰²é€šé“ (BGR -> RGB)
    img_rgb = cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB)
    
    # 3. è½¬æ¢æ•°æ®ç±»å‹ (uint8 -> float16ï¼Œä¿æŒ[0-255]èŒƒå›´)
    img_typed = img_rgb.astype(dtype)
    
    # 4. è½¬æ¢ä¸ºCHWæ ¼å¼å¹¶æ·»åŠ batchç»´åº¦
    img_transposed = np.transpose(img_typed, (2, 0, 1))
    processed_img = np.ascontiguousarray(img_transposed[np.newaxis, :, :, :])
    
    return processed_img, (original_height, original_width)

# ---------------------------------------------------------------------------------
# --- ğŸš€ğŸš€ğŸš€ åå¤„ç†å‡½æ•° ğŸš€ğŸš€ğŸš€ ---
# ---------------------------------------------------------------------------------

def postprocess_output(output_tensor, original_shape):
    """
    åå¤„ç†æ¨¡å‹è¾“å‡ºï¼Œç”Ÿæˆè½¦é“çº¿æ©ç 
    
    Args:
        output_tensor: æ¨¡å‹è¾“å‡ºå¼ é‡
        original_shape: åŸå§‹å›¾ç‰‡å½¢çŠ¶ (height, width)
    
    Returns:
        lane_mask: è½¦é“çº¿æ©ç  (åŸå§‹å›¾ç‰‡å°ºå¯¸)
    """
    original_height, original_width = original_shape
    
    # 1. Argmaxè·å–åˆ†å‰²æ©ç 
    pred_mask = np.argmax(output_tensor, axis=1).squeeze()
    
    # 2. è½¬æ¢ä¸ºå¯è§†åŒ–æ ¼å¼
    vis_mask = (pred_mask * 255).astype(np.uint8)
    
    # 3. å¦‚æœéœ€è¦ï¼Œresizeå›åŸå§‹å°ºå¯¸
    if vis_mask.shape != (original_height, original_width):
        lane_mask = cv2.resize(vis_mask, (original_width, original_height), interpolation=cv2.INTER_NEAREST)
        print(f"ğŸ“ æ©ç å°ºå¯¸è°ƒæ•´: {vis_mask.shape} -> {original_height}Ã—{original_width}")
    else:
        lane_mask = vis_mask
        print(f"ğŸ¯ æ©ç å°ºå¯¸å®Œç¾åŒ¹é…: {original_height}Ã—{original_width}")
    
    return lane_mask

def create_visualization(original_img, lane_mask, alpha=0.5):
    """
    åˆ›å»ºè½¦é“çº¿æ£€æµ‹å¯è§†åŒ–ç»“æœ
    
    Args:
        original_img: åŸå§‹BGRå›¾ç‰‡
        lane_mask: è½¦é“çº¿æ©ç 
        alpha: å åŠ é€æ˜åº¦
    
    Returns:
        vis_img: å¯è§†åŒ–ç»“æœå›¾ç‰‡
    """
    # åˆ›å»ºç»¿è‰²å åŠ å±‚
    green_overlay = np.zeros_like(original_img, dtype=np.uint8)
    green_overlay[lane_mask > 0] = [0, 255, 0]  # BGRæ ¼å¼çš„ç»¿è‰²
    
    # å åŠ åŸå›¾å’Œæ©ç 
    vis_img = cv2.addWeighted(original_img, 1.0, green_overlay, alpha, 0)
    
    return vis_img

def add_info_text(img, inference_time, original_shape, model_input_shape):
    """
    åœ¨å›¾ç‰‡ä¸Šæ·»åŠ æ¨ç†ä¿¡æ¯æ–‡æœ¬
    """
    font = cv2.FONT_HERSHEY_SIMPLEX
    font_scale = 1
    color = (0, 255, 0)  # ç»¿è‰²
    thickness = 2
    
    # æ·»åŠ æ¨ç†æ—¶é—´
    time_text = f"Inference: {inference_time:.1f}ms"
    cv2.putText(img, time_text, (15, 30), font, font_scale, color, thickness)
    
    # æ·»åŠ å›¾ç‰‡å°ºå¯¸ä¿¡æ¯
    size_text = f"Size: {original_shape[1]}x{original_shape[0]} -> {model_input_shape[1]}x{model_input_shape[0]}"
    cv2.putText(img, size_text, (15, 65), font, font_scale, color, thickness)
    
    # æ·»åŠ æ¨¡å‹ä¿¡æ¯
    model_text = f"Model: Fast-SCNN (FP16)"
    cv2.putText(img, model_text, (15, 100), font, font_scale, color, thickness)
    
    return img

def inference_single_image(image_path, output_dir=None, show_result=True, save_result=True):
    """
    å¯¹å•å¼ å›¾ç‰‡è¿›è¡Œè½¦é“çº¿æ£€æµ‹æ¨ç†
    
    Args:
        image_path: è¾“å…¥å›¾ç‰‡è·¯å¾„
        output_dir: è¾“å‡ºç›®å½•
        show_result: æ˜¯å¦æ˜¾ç¤ºç»“æœ
        save_result: æ˜¯å¦ä¿å­˜ç»“æœ
    """
    # æ£€æŸ¥è¾“å…¥å›¾ç‰‡æ˜¯å¦å­˜åœ¨
    if not os.path.exists(image_path):
        print(f"âŒ é”™è¯¯: å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨ - {image_path}")
        return
    
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(MODEL_PATH):
        print(f"âŒ é”™è¯¯: æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ - {MODEL_PATH}")
        return
    
    print("=" * 80)
    print("ğŸš€ Fast-SCNN è½¦é“çº¿æ£€æµ‹ - å•å›¾æ¨ç†")
    print("=" * 80)
    print(f"ğŸ“ è¾“å…¥å›¾ç‰‡: {image_path}")
    print(f"ğŸ§  æ¨¡å‹è·¯å¾„: {MODEL_PATH}")
    print(f"ğŸ¯ æ¨¡å‹è¾“å…¥: {MODEL_WIDTH}Ã—{MODEL_HEIGHT} (FP16)")
    
    # åŠ è½½æ¨¡å‹
    print("\nâ³ æ­£åœ¨åŠ è½½æ¨¡å‹...")
    start_time = time.time()
    model = InferSession(DEVICE_ID, MODEL_PATH)
    load_time = (time.time() - start_time) * 1000
    print(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆ ({load_time:.1f}ms)")
    
    # è¯»å–å›¾ç‰‡
    print("\nğŸ“– æ­£åœ¨è¯»å–å›¾ç‰‡...")
    original_img = cv2.imread(image_path)
    if original_img is None:
        print(f"âŒ é”™è¯¯: æ— æ³•è¯»å–å›¾ç‰‡ - {image_path}")
        return
    
    original_shape = original_img.shape[:2]
    print(f"âœ… å›¾ç‰‡è¯»å–æˆåŠŸï¼Œå°ºå¯¸: {original_shape[1]}Ã—{original_shape[0]}")
    
    # é¢„å¤„ç†
    print("\nâš™ï¸ æ­£åœ¨é¢„å¤„ç†...")
    preprocess_start = time.time()
    input_data, original_shape = preprocess_image(original_img)
    preprocess_time = (time.time() - preprocess_start) * 1000
    print(f"âœ… é¢„å¤„ç†å®Œæˆ ({preprocess_time:.1f}ms)")
    print(f"   è¾“å…¥å¼ é‡å½¢çŠ¶: {input_data.shape}")
    print(f"   æ•°æ®ç±»å‹: {input_data.dtype}")
    
    # NPUæ¨ç†
    print("\nğŸš€ æ­£åœ¨è¿›è¡ŒNPUæ¨ç†...")
    inference_start = time.time()
    outputs = model.infer([input_data])
    inference_time = (time.time() - inference_start) * 1000
    print(f"âœ… NPUæ¨ç†å®Œæˆ ({inference_time:.1f}ms)")
    print(f"   è¾“å‡ºå¼ é‡å½¢çŠ¶: {outputs[0].shape}")
    
    # åå¤„ç†
    print("\nğŸ¨ æ­£åœ¨åå¤„ç†...")
    postprocess_start = time.time()
    lane_mask = postprocess_output(outputs[0], original_shape)
    postprocess_time = (time.time() - postprocess_start) * 1000
    print(f"âœ… åå¤„ç†å®Œæˆ ({postprocess_time:.1f}ms)")
    
    # åˆ›å»ºå¯è§†åŒ–ç»“æœ
    print("\nğŸ–¼ï¸ æ­£åœ¨ç”Ÿæˆå¯è§†åŒ–ç»“æœ...")
    vis_img = create_visualization(original_img, lane_mask)
    vis_img = add_info_text(vis_img, inference_time, original_shape, (MODEL_HEIGHT, MODEL_WIDTH))
    
    # ç»Ÿè®¡ä¿¡æ¯
    total_time = preprocess_time + inference_time + postprocess_time
    print("\nğŸ“Š æ€§èƒ½ç»Ÿè®¡:")
    print(f"   é¢„å¤„ç†æ—¶é—´: {preprocess_time:.1f}ms ({preprocess_time/total_time*100:.1f}%)")
    print(f"   NPUæ¨ç†æ—¶é—´: {inference_time:.1f}ms ({inference_time/total_time*100:.1f}%)")
    print(f"   åå¤„ç†æ—¶é—´: {postprocess_time:.1f}ms ({postprocess_time/total_time*100:.1f}%)")
    print(f"   æ€»å¤„ç†æ—¶é—´: {total_time:.1f}ms")
    print(f"   ç­‰æ•ˆFPS: {1000/total_time:.1f}")
    
    # ä¿å­˜ç»“æœ
    if save_result:
        if output_dir is None:
            output_dir = os.path.dirname(image_path)
        
        os.makedirs(output_dir, exist_ok=True)
        
        # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
        input_name = Path(image_path).stem
        
        # ä¿å­˜åŸå§‹æ©ç 
        mask_path = os.path.join(output_dir, f"{input_name}_mask.png")
        cv2.imwrite(mask_path, lane_mask)
        
        # ä¿å­˜å¯è§†åŒ–ç»“æœ
        vis_path = os.path.join(output_dir, f"{input_name}_result.jpg")
        cv2.imwrite(vis_path, vis_img)
        
        print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜:")
        print(f"   æ©ç æ–‡ä»¶: {mask_path}")
        print(f"   å¯è§†åŒ–æ–‡ä»¶: {vis_path}")
    
    # æ˜¾ç¤ºç»“æœ
    if show_result:
        print("\nğŸ‘ï¸ æ­£åœ¨æ˜¾ç¤ºç»“æœ...")
        print("   æŒ‰ä»»æ„é”®å…³é—­çª—å£")
        
        # åˆ›å»ºçª—å£å¹¶æ˜¾ç¤º
        window_name = f"Fast-SCNN Lane Detection - {Path(image_path).name}"
        cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)
        cv2.imshow(window_name, vis_img)
        cv2.waitKey(0)
        cv2.destroyAllWindows()
    
    print("\nâœ… æ¨ç†å®Œæˆ!")
    print("=" * 80)

def main():
    global MODEL_PATH, DEVICE_ID
    parser = argparse.ArgumentParser(description="Fast-SCNN è½¦é“çº¿æ£€æµ‹ - å•å›¾æ¨ç†")
    parser.add_argument("--input", "-i", required=True, help="è¾“å…¥å›¾ç‰‡è·¯å¾„")
    parser.add_argument("--output", "-o", default=None, help="è¾“å‡ºç›®å½• (é»˜è®¤ä¸ºè¾“å…¥å›¾ç‰‡åŒç›®å½•)")
    parser.add_argument("--model", "-m", default=MODEL_PATH, help=f"æ¨¡å‹æ–‡ä»¶è·¯å¾„ (é»˜è®¤: {MODEL_PATH})")
    parser.add_argument("--device", "-d", type=int, default=DEVICE_ID, help=f"è®¾å¤‡ID (é»˜è®¤: {DEVICE_ID})")
    parser.add_argument("--no-show", action="store_true", help="ä¸æ˜¾ç¤ºç»“æœçª—å£")
    parser.add_argument("--no-save", action="store_true", help="ä¸ä¿å­˜ç»“æœæ–‡ä»¶")
    
    args = parser.parse_args()
    
    # æ›´æ–°å…¨å±€é…ç½®
    
    MODEL_PATH = args.model
    DEVICE_ID = args.device
    
    # æ‰§è¡Œæ¨ç†
    inference_single_image(
        image_path=args.input,
        output_dir=args.output,
        show_result=not args.no_show,
        save_result=not args.no_save
    )

if __name__ == "__main__":
    # å¦‚æœæ²¡æœ‰å‘½ä»¤è¡Œå‚æ•°ï¼Œä½¿ç”¨é»˜è®¤æµ‹è¯•
    import sys
    if len(sys.argv) == 1:
        print("=" * 80)
        print("ğŸ”§ æµ‹è¯•æ¨¡å¼ - è¯·æä¾›è¾“å…¥å›¾ç‰‡è·¯å¾„")
        print("=" * 80)
        print("ä½¿ç”¨æ–¹æ³•:")
        print("  python single_image_inference.py --input <image_path>")
        print("\nå®Œæ•´å‚æ•°:")
        print("  --input  | -i  : è¾“å…¥å›¾ç‰‡è·¯å¾„ (å¿…éœ€)")
        print("  --output | -o  : è¾“å‡ºç›®å½• (å¯é€‰)")
        print("  --model  | -m  : æ¨¡å‹æ–‡ä»¶è·¯å¾„")
        print("  --device | -d  : NPUè®¾å¤‡ID")
        print("  --no-show      : ä¸æ˜¾ç¤ºç»“æœçª—å£")
        print("  --no-save      : ä¸ä¿å­˜ç»“æœæ–‡ä»¶")
        print("\nç¤ºä¾‹:")
        print("  python single_image_inference.py -i test_image.jpg")
        print("  python single_image_inference.py -i test_image.jpg -o results/")
        print("  python single_image_inference.py -i test_image.jpg --no-show")
        print("=" * 80)
    else:
        main()
