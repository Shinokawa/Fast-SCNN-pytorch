#!/usr/bin/env python3
"""
å•å¼ å›¾ç‰‡æ¨ç†æµ‹è¯•è„šæœ¬ (æ¨¡æ‹ŸAtlas NPUæ¨ç†æµç¨‹)

æ­¤è„šæœ¬ç”¨äºåœ¨å¼€å‘ç¯å¢ƒä¸­æµ‹è¯•æ¨ç†æµç¨‹ï¼Œæ— éœ€çœŸå®çš„Atlasç¡¬ä»¶ã€‚
æ¨¡æ‹Ÿäº†atlas_single_image_inference.pyçš„å®Œæ•´æµç¨‹ã€‚
"""

import os
import sys
import cv2
import time
import numpy as np
import argparse
from pathlib import Path

# ---------------------------------------------------------------------------------
# --- ğŸš€ğŸš€ğŸš€ å®Œç¾åŒ¹é…çš„é¢„å¤„ç† (ä¸Atlasè„šæœ¬å®Œå…¨ä¸€è‡´) ğŸš€ğŸš€ğŸš€ ---
# ---------------------------------------------------------------------------------

def preprocess_matched_resolution(img_bgr, target_width=640, target_height=360, dtype=np.float16):
    """
    å›¾ç‰‡é¢„å¤„ç†ï¼Œä¸atlas_single_image_inference.pyå®Œå…¨ä¸€è‡´
    """
    # 1. è°ƒæ•´å°ºå¯¸åˆ°æ¨¡å‹è¾“å…¥è¦æ±‚
    height, width = img_bgr.shape[:2]
    if width != target_width or height != target_height:
        print(f"ğŸ“ Resize: {width}Ã—{height} â†’ {target_width}Ã—{target_height}")
        img_bgr = cv2.resize(img_bgr, (target_width, target_height), interpolation=cv2.INTER_LINEAR)
    else:
        print(f"ğŸ¯ å®Œç¾åŒ¹é…: {width}Ã—{height} = {target_width}Ã—{target_height}ï¼Œæ— éœ€resize!")
    
    # 2. è½¬æ¢é¢œè‰²é€šé“ (BGR â†’ RGB)
    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)
    
    # 3. è½¬æ¢æ•°æ®ç±»å‹ (uint8 â†’ float16ï¼Œä¿æŒ[0-255]èŒƒå›´)
    img_typed = img_rgb.astype(dtype)
    
    # 4. è½¬æ¢ä¸ºCHWæ ¼å¼å¹¶æ·»åŠ batchç»´åº¦ (H,W,C) â†’ (1,C,H,W)
    img_transposed = np.transpose(img_typed, (2, 0, 1))
    return np.ascontiguousarray(img_transposed[np.newaxis, :, :, :])

# ---------------------------------------------------------------------------------
# --- ğŸš€ğŸš€ğŸš€ æç®€åå¤„ç† (ä¸Atlasè„šæœ¬å®Œå…¨ä¸€è‡´) ğŸš€ğŸš€ğŸš€ ---
# ---------------------------------------------------------------------------------

def postprocess_matched_resolution(output_tensor, original_width, original_height):
    """
    åå¤„ç†ï¼Œä¸atlas_single_image_inference.pyå®Œå…¨ä¸€è‡´
    """
    # 1. Argmaxè·å–åˆ†å‰²æ©ç  (1, num_classes, H, W) â†’ (H, W)
    pred_mask = np.argmax(output_tensor, axis=1).squeeze()
    
    # 2. è½¬æ¢ä¸ºå¯è§†åŒ–æ ¼å¼ (0/1 â†’ 0/255)
    vis_mask = (pred_mask * 255).astype(np.uint8)
    
    # 3. å¦‚æœéœ€è¦ï¼Œresizeå›åŸå§‹å°ºå¯¸
    model_height, model_width = vis_mask.shape
    if original_width != model_width or original_height != model_height:
        print(f"ğŸ“ Resize back: {model_width}Ã—{model_height} â†’ {original_width}Ã—{original_height}")
        vis_mask = cv2.resize(vis_mask, (original_width, original_height), interpolation=cv2.INTER_NEAREST)
    else:
        print(f"ğŸ¯ è¾“å‡ºå°ºå¯¸åŒ¹é…: {model_width}Ã—{model_height} = {original_width}Ã—{original_height}")
    
    return vis_mask

# ---------------------------------------------------------------------------------
# --- ğŸ¨ å¯è§†åŒ–ç”Ÿæˆ (ä¸Atlasè„šæœ¬å®Œå…¨ä¸€è‡´) ---
# ---------------------------------------------------------------------------------

def create_visualization(original_img, mask, alpha=0.5):
    """åˆ›å»ºè½¦é“çº¿åˆ†å‰²å¯è§†åŒ–å›¾åƒ"""
    # åˆ›å»ºç»¿è‰²è¦†ç›–å±‚
    green_overlay = np.zeros_like(original_img, dtype=np.uint8)
    green_overlay[mask > 0] = [0, 255, 0]  # BGRæ ¼å¼çš„ç»¿è‰²
    
    # èåˆåŸå›¾å’Œè¦†ç›–å±‚
    vis_img = cv2.addWeighted(original_img, 1.0, green_overlay, alpha, 0)
    
    return vis_img

# ---------------------------------------------------------------------------------
# --- ğŸ¤– æ¨¡æ‹ŸAtlas NPUæ¨ç† ---
# ---------------------------------------------------------------------------------

class MockInferSession:
    """æ¨¡æ‹ŸAtlas InferSessionï¼Œç”¨äºæµ‹è¯•"""
    
    def __init__(self, device_id, model_path):
        self.device_id = device_id
        self.model_path = model_path
        print(f"ğŸ¤– æ¨¡æ‹ŸåŠ è½½æ¨¡å‹: {model_path} (è®¾å¤‡: {device_id})")
        time.sleep(0.1)  # æ¨¡æ‹ŸåŠ è½½æ—¶é—´
    
    def infer(self, inputs):
        """æ¨¡æ‹Ÿæ¨ç†ï¼Œç”Ÿæˆéšæœºçš„è½¦é“çº¿åˆ†å‰²ç»“æœ"""
        input_tensor = inputs[0]
        batch, channels, height, width = input_tensor.shape
        
        # æ¨¡æ‹ŸNPUæ¨ç†æ—¶é—´
        time.sleep(0.001)  # 1msæ¨¡æ‹Ÿæ¨ç†æ—¶é—´
        
        # ç”Ÿæˆæ¨¡æ‹Ÿçš„åˆ†å‰²ç»“æœ (2ä¸ªç±»åˆ«: èƒŒæ™¯å’Œè½¦é“çº¿)
        # åˆ›å»ºä¸€äº›ç®€å•çš„è½¦é“çº¿æ¨¡å¼
        output = np.zeros((batch, 2, height, width), dtype=np.float32)
        
        # èƒŒæ™¯ç±»åˆ« (ç´¢å¼•0)
        output[:, 0, :, :] = 0.8
        
        # è½¦é“çº¿ç±»åˆ« (ç´¢å¼•1) - åˆ›å»ºä¸¤æ¡å‚ç›´çš„è½¦é“çº¿
        lane_width = 20
        left_lane_center = width // 3
        right_lane_center = 2 * width // 3
        
        # å·¦è½¦é“çº¿
        output[:, 1, :, left_lane_center-lane_width//2:left_lane_center+lane_width//2] = 0.9
        # å³è½¦é“çº¿
        output[:, 1, :, right_lane_center-lane_width//2:right_lane_center+lane_width//2] = 0.9
        
        # èƒŒæ™¯åŒºåŸŸå¯¹åº”é™ä½
        output[:, 0, :, left_lane_center-lane_width//2:left_lane_center+lane_width//2] = 0.1
        output[:, 0, :, right_lane_center-lane_width//2:right_lane_center+lane_width//2] = 0.1
        
        return [output]

# ---------------------------------------------------------------------------------
# --- ğŸ“Š æ€§èƒ½åˆ†æ (ä¸Atlasè„šæœ¬å®Œå…¨ä¸€è‡´) ---
# ---------------------------------------------------------------------------------

def print_performance_analysis(times_dict, input_shape, model_path):
    """æ‰“å°è¯¦ç»†çš„æ€§èƒ½åˆ†ææŠ¥å‘Š"""
    total_time = sum(times_dict.values())
    
    print("\n" + "="*60)
    print("ğŸ¤– æ¨¡æ‹ŸAtlas NPU å•å¼ å›¾ç‰‡æ¨ç†æ€§èƒ½åˆ†æ")
    print("="*60)
    print(f"ğŸ§  æ¨¡å‹: {Path(model_path).name}")
    print(f"ğŸ“ è¾“å…¥å°ºå¯¸: {input_shape[3]}Ã—{input_shape[2]} (WÃ—H)")
    print(f"ğŸ¯ æ•°æ®ç±»å‹: {str(input_shape).split('.')[-1].upper()}")
    print(f"âš ï¸  æ³¨æ„: è¿™æ˜¯æ¨¡æ‹Ÿæ¨ç†ï¼ŒéçœŸå®Atlasæ€§èƒ½")
    print("-"*60)
    
    for stage, time_ms in times_dict.items():
        percentage = (time_ms / total_time) * 100
        print(f"â±ï¸  {stage:12}: {time_ms:6.1f}ms ({percentage:5.1f}%)")
    
    print("-"*60)
    print(f"ğŸ æ€»è€—æ—¶: {total_time:.1f}ms")
    print(f"âš¡ ç†è®ºFPS: {1000/total_time:.1f}")
    print("="*60)

# ---------------------------------------------------------------------------------
# --- ğŸ“± ä¸»æ¨ç†å‡½æ•° (ä¸Atlasè„šæœ¬æµç¨‹å®Œå…¨ä¸€è‡´) ---
# ---------------------------------------------------------------------------------

def test_inference_single_image(image_path, model_path="mock_model.om", device_id=0, save_visualization=True, save_mask=False):
    """
    æµ‹è¯•å•å¼ å›¾ç‰‡æ¨ç†æµç¨‹ï¼ˆæ¨¡æ‹ŸAtlasï¼‰
    """
    # éªŒè¯è¾“å…¥æ–‡ä»¶
    if not os.path.exists(image_path):
        raise FileNotFoundError(f"è¾“å…¥å›¾ç‰‡ä¸å­˜åœ¨: {image_path}")
    
    print(f"ğŸ–¼ï¸  åŠ è½½å›¾ç‰‡: {image_path}")
    
    # 1. åŠ è½½å›¾ç‰‡
    load_start = time.time()
    img_bgr = cv2.imread(image_path)
    if img_bgr is None:
        raise ValueError(f"æ— æ³•è¯»å–å›¾ç‰‡: {image_path}")
    
    original_height, original_width = img_bgr.shape[:2]
    load_time = (time.time() - load_start) * 1000
    
    print(f"ğŸ“ åŸå§‹å°ºå¯¸: {original_width}Ã—{original_height}")
    
    # 2. åŠ è½½æ¨¡å‹ (æ¨¡æ‹Ÿ)
    print(f"ğŸ§  æ¨¡æ‹ŸåŠ è½½æ¨¡å‹: {model_path}")
    model_start = time.time()
    model = MockInferSession(device_id, model_path)
    model_load_time = (time.time() - model_start) * 1000
    print(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆ ({model_load_time:.1f}ms)")
    
    # 3. é¢„å¤„ç†
    print("ğŸ”„ å¼€å§‹é¢„å¤„ç†...")
    preprocess_start = time.time()
    input_data = preprocess_matched_resolution(img_bgr, dtype=np.float16)
    preprocess_time = (time.time() - preprocess_start) * 1000
    
    print(f"ğŸ“Š è¾“å…¥å¼ é‡å½¢çŠ¶: {input_data.shape}")
    print(f"ğŸ“Š æ•°æ®ç±»å‹: {input_data.dtype}")
    
    # 4. NPUæ¨ç† (æ¨¡æ‹Ÿ)
    print("ğŸ¤– å¼€å§‹æ¨¡æ‹ŸNPUæ¨ç†...")
    inference_start = time.time()
    outputs = model.infer([input_data])
    inference_time = (time.time() - inference_start) * 1000
    
    print(f"ğŸ“Š è¾“å‡ºå¼ é‡å½¢çŠ¶: {outputs[0].shape}")
    
    # 5. åå¤„ç†
    print("ğŸ”„ å¼€å§‹åå¤„ç†...")
    postprocess_start = time.time()
    lane_mask = postprocess_matched_resolution(outputs[0], original_width, original_height)
    postprocess_time = (time.time() - postprocess_start) * 1000
    
    # 6. ä¿å­˜ç»“æœ
    save_start = time.time()
    results = {}
    
    if save_mask:
        mask_path = image_path.replace('.', '_test_mask.')
        cv2.imwrite(mask_path, lane_mask)
        results['mask_path'] = mask_path
        print(f"ğŸ’¾ åˆ†å‰²æ©ç å·²ä¿å­˜: {mask_path}")
    
    if save_visualization:
        vis_img = create_visualization(img_bgr, lane_mask)
        vis_path = image_path.replace('.', '_test_result.')
        cv2.imwrite(vis_path, vis_img)
        results['visualization_path'] = vis_path
        print(f"ğŸ’¾ å¯è§†åŒ–ç»“æœå·²ä¿å­˜: {vis_path}")
    
    save_time = (time.time() - save_start) * 1000
    
    # 7. æ€§èƒ½åˆ†æ
    times_dict = {
        "å›¾ç‰‡åŠ è½½": load_time,
        "æ¨¡å‹åŠ è½½": model_load_time,
        "CPUé¢„å¤„ç†": preprocess_time,
        "æ¨¡æ‹Ÿæ¨ç†": inference_time,
        "CPUåå¤„ç†": postprocess_time,
        "ç»“æœä¿å­˜": save_time
    }
    
    print_performance_analysis(times_dict, input_data.shape, model_path)
    
    # 8. ç»Ÿè®¡è½¦é“çº¿åƒç´ 
    lane_pixels = np.sum(lane_mask > 0)
    total_pixels = lane_mask.shape[0] * lane_mask.shape[1]
    lane_ratio = (lane_pixels / total_pixels) * 100
    
    print(f"\nğŸ“ˆ æ£€æµ‹ç»“æœç»Ÿè®¡:")
    print(f"ğŸ›£ï¸  è½¦é“çº¿åƒç´ : {lane_pixels:,} / {total_pixels:,} ({lane_ratio:.2f}%)")
    
    results.update({
        'lane_pixels': lane_pixels,
        'total_pixels': total_pixels,
        'lane_ratio': lane_ratio,
        'performance': times_dict
    })
    
    return results

# ---------------------------------------------------------------------------------
# --- ğŸ“± å‘½ä»¤è¡Œæ¥å£ ---
# ---------------------------------------------------------------------------------

def main():
    parser = argparse.ArgumentParser(description="æµ‹è¯•Atlas NPUå•å¼ å›¾ç‰‡æ¨ç†æµç¨‹ (æ¨¡æ‹Ÿ)")
    parser.add_argument("--input", "-i", required=True, help="è¾“å…¥å›¾ç‰‡è·¯å¾„")
    parser.add_argument("--output", "-o", help="è¾“å‡ºå¯è§†åŒ–å›¾ç‰‡è·¯å¾„ï¼ˆå¯é€‰ï¼‰")
    parser.add_argument("--save_mask", help="ä¿å­˜åˆ†å‰²æ©ç è·¯å¾„ï¼ˆå¯é€‰ï¼‰")
    parser.add_argument("--model", "-m", 
                       default="mock_fast_scnn_model.om",
                       help="æ¨¡æ‹Ÿæ¨¡å‹è·¯å¾„")
    parser.add_argument("--device", "-d", type=int, default=0, help="æ¨¡æ‹ŸNPUè®¾å¤‡ID")
    parser.add_argument("--no_vis", action="store_true", help="ä¸ä¿å­˜å¯è§†åŒ–ç»“æœï¼Œä»…æ¨ç†")
    
    args = parser.parse_args()
    
    try:
        print("ğŸ¤– æ¨¡æ‹ŸAtlas NPU å•å¼ å›¾ç‰‡è½¦é“çº¿åˆ†å‰²æ¨ç†æµ‹è¯•")
        print("=" * 50)
        print("âš ï¸  æ³¨æ„: è¿™æ˜¯æµ‹è¯•è„šæœ¬ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ¨ç†ç»“æœ")
        print("ğŸ“ ç”¨äºéªŒè¯é¢„å¤„ç†/åå¤„ç†æµç¨‹ä¸çœŸå®Atlasè„šæœ¬çš„ä¸€è‡´æ€§")
        print("=" * 50)
        
        # è‡ªåŠ¨ç¡®å®šè¾“å‡ºè·¯å¾„
        save_visualization = not args.no_vis
        save_mask = bool(args.save_mask)
        
        if args.output and save_visualization:
            # å¦‚æœæŒ‡å®šäº†è¾“å‡ºè·¯å¾„ï¼Œé‡å‘½ååŸå›¾ä»¥ä½¿ç”¨æŒ‡å®šè·¯å¾„
            import shutil
            target_input = args.output.replace('_test_result.', '.')
            if target_input != args.input:
                shutil.copy2(args.input, target_input)
                args.input = target_input
        
        # æ‰§è¡Œæµ‹è¯•æ¨ç†
        results = test_inference_single_image(
            image_path=args.input,
            model_path=args.model,
            device_id=args.device,
            save_visualization=save_visualization,
            save_mask=save_mask
        )
        
        # å¦‚æœæŒ‡å®šäº†æ©ç ä¿å­˜è·¯å¾„ï¼Œé‡å‘½å
        if args.save_mask and 'mask_path' in results:
            import shutil
            shutil.move(results['mask_path'], args.save_mask)
            results['mask_path'] = args.save_mask
            print(f"ğŸ’¾ åˆ†å‰²æ©ç å·²ä¿å­˜åˆ°æŒ‡å®šè·¯å¾„: {args.save_mask}")
        
        # å¦‚æœæŒ‡å®šäº†è¾“å‡ºè·¯å¾„ï¼Œé‡å‘½åå¯è§†åŒ–ç»“æœ
        if args.output and 'visualization_path' in results:
            import shutil
            shutil.move(results['visualization_path'], args.output)
            results['visualization_path'] = args.output
            print(f"ğŸ’¾ å¯è§†åŒ–ç»“æœå·²ä¿å­˜åˆ°æŒ‡å®šè·¯å¾„: {args.output}")
        
        print("\nâœ… æµ‹è¯•æ¨ç†å®Œæˆï¼")
        print("ğŸ”§ ç°åœ¨å¯ä»¥å°†ç›¸åŒçš„æµç¨‹éƒ¨ç½²åˆ°çœŸå®çš„Atlasç¯å¢ƒä¸­")
        
        if 'visualization_path' in results:
            print(f"ğŸ¨ å¯è§†åŒ–ç»“æœ: {results['visualization_path']}")
        if 'mask_path' in results:
            print(f"ğŸ­ åˆ†å‰²æ©ç : {results['mask_path']}")
            
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
