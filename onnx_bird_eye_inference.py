#!/usr/bin/env python3
"""
é›†æˆæ„ŸçŸ¥ä¸ç¯å¢ƒå»ºæ¨¡çš„è½¦é“çº¿åˆ†å‰²æ¨ç†è„šæœ¬

åŠŸèƒ½ç‰¹æ€§ï¼š
- ä½¿ç”¨ONNX Runtimeè¿›è¡Œè½¦é“çº¿åˆ†å‰²æ¨ç†
- æ”¯æŒé€è§†å˜æ¢ï¼Œç”Ÿæˆé¸Ÿç°å›¾
- å¯è§†åŒ–å¯é©¾é©¶åŒºåŸŸçš„é¸Ÿç°å›¾
- ä¸ºè·¯å¾„è§„åˆ’æä¾›2Dåœ°å›¾æ•°æ®
- æ”¯æŒå®æ—¶å¤„ç†å’Œæ‰¹é‡å¤„ç†

ä½¿ç”¨æ–¹æ³•ï¼š
# åŸºç¡€æ¨ç†ï¼ˆä»…åˆ†å‰²ï¼‰
python onnx_bird_eye_inference.py --input image.jpg --output result.jpg

# æ·»åŠ é€è§†å˜æ¢ï¼ˆéœ€è¦æ ‡å®šæ–‡ä»¶ï¼‰
python onnx_bird_eye_inference.py --input image.jpg --output result.jpg --calibration calibration.json --bird_eye

# ç”Ÿæˆæ§åˆ¶ç”¨çš„é¸Ÿç°å›¾
python onnx_bird_eye_inference.py --input image.jpg --calibration calibration.json --bird_eye --save_control_map

ä½œè€…ï¼šåŸºäºonnx_single_image_inference.pyæ‰©å±•ï¼Œé›†æˆé€è§†å˜æ¢åŠŸèƒ½
"""

import os
import sys
import cv2
import time
import numpy as np
import argparse
import json
from pathlib import Path

# å¯¼å…¥ONNX Runtime
try:
    import onnxruntime as ort
except ImportError:
    print("âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ°onnxruntimeåº“ï¼Œè¯·å®‰è£…")
    print("CPUç‰ˆæœ¬: pip install onnxruntime")
    print("GPUç‰ˆæœ¬: pip install onnxruntime-gpu")
    sys.exit(1)

# ---------------------------------------------------------------------------------
# --- ğŸš€ğŸš€ğŸš€ é¢„å¤„ç†æ¨¡å— (ä¸Atlaså®Œå…¨ä¸€è‡´) ğŸš€ğŸš€ğŸš€ ---
# ---------------------------------------------------------------------------------

def preprocess_matched_resolution(img_bgr, target_width=640, target_height=360, dtype=np.float32):
    """
    å›¾ç‰‡é¢„å¤„ç†ï¼Œä¸atlas_single_image_inference.pyå®Œå…¨ä¸€è‡´
    
    è¾“å…¥ï¼šBGRå›¾åƒ (ä»»æ„å°ºå¯¸)
    è¾“å‡ºï¼šFloat32/Float16 NCHWå¼ é‡ (1, 3, 360, 640)
    
    å¤„ç†æµç¨‹ï¼š
    1. å¦‚æœè¾“å…¥å°ºå¯¸ä¸æ˜¯640Ã—360ï¼Œå…ˆresizeåˆ°640Ã—360
    2. BGR â†’ RGB
    3. uint8 â†’ float32/float16 (ä¿æŒ[0-255]èŒƒå›´)
    4. HWC â†’ CHWï¼Œæ·»åŠ batchç»´åº¦
    """
    # 1. è°ƒæ•´å°ºå¯¸åˆ°æ¨¡å‹è¾“å…¥è¦æ±‚
    height, width = img_bgr.shape[:2]
    if width != target_width or height != target_height:
        print(f"ğŸ“ Resize: {width}Ã—{height} â†’ {target_width}Ã—{target_height}")
        img_bgr = cv2.resize(img_bgr, (target_width, target_height), interpolation=cv2.INTER_LINEAR)
    else:
        print(f"ğŸ¯ å®Œç¾åŒ¹é…: {width}Ã—{height} = {target_width}Ã—{target_height}ï¼Œæ— éœ€resize!")
    
    # 2. è½¬æ¢é¢œè‰²é€šé“ (BGR â†’ RGB)
    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)
    
    # 3. è½¬æ¢æ•°æ®ç±»å‹ (uint8 â†’ float16ï¼Œä¿æŒ[0-255]èŒƒå›´)
    img_typed = img_rgb.astype(dtype)
    
    # 4. è½¬æ¢ä¸ºCHWæ ¼å¼å¹¶æ·»åŠ batchç»´åº¦ (H,W,C) â†’ (1,C,H,W)
    img_transposed = np.transpose(img_typed, (2, 0, 1))
    return np.ascontiguousarray(img_transposed[np.newaxis, :, :, :])

# ---------------------------------------------------------------------------------
# --- ğŸš€ğŸš€ğŸš€ åå¤„ç†æ¨¡å— (ä¸Atlaså®Œå…¨ä¸€è‡´) ğŸš€ğŸš€ğŸš€ ---
# ---------------------------------------------------------------------------------

def postprocess_matched_resolution(output_tensor, original_width, original_height):
    """
    åå¤„ç†ï¼Œä¸atlas_single_image_inference.pyå®Œå…¨ä¸€è‡´
    
    è¾“å…¥ï¼šæ¨¡å‹è¾“å‡ºå¼ é‡ (1, num_classes, 360, 640)
    è¾“å‡ºï¼šåˆ†å‰²æ©ç  (original_height, original_width)
    
    å¤„ç†æµç¨‹ï¼š
    1. Argmaxè·å–åˆ†å‰²æ©ç 
    2. è½¬æ¢ä¸ºå¯è§†åŒ–æ ¼å¼
    3. å¦‚éœ€è¦ï¼Œresizeå›åŸå§‹å°ºå¯¸
    """
    # 1. Argmaxè·å–åˆ†å‰²æ©ç  (1, num_classes, H, W) â†’ (H, W)
    pred_mask = np.argmax(output_tensor, axis=1).squeeze()
    
    # 2. è½¬æ¢ä¸ºå¯è§†åŒ–æ ¼å¼ (0/1 â†’ 0/255)
    vis_mask = (pred_mask * 255).astype(np.uint8)
    
    # 3. å¦‚æœéœ€è¦ï¼Œresizeå›åŸå§‹å°ºå¯¸
    model_height, model_width = vis_mask.shape
    if original_width != model_width or original_height != model_height:
        print(f"ğŸ“ Resize back: {model_width}Ã—{model_height} â†’ {original_width}Ã—{original_height}")
        vis_mask = cv2.resize(vis_mask, (original_width, original_height), interpolation=cv2.INTER_NEAREST)
    else:
        print(f"ğŸ¯ è¾“å‡ºå°ºå¯¸åŒ¹é…: {model_width}Ã—{model_height} = {original_width}Ã—{original_height}")
    
    return vis_mask

# ---------------------------------------------------------------------------------
# --- ğŸ¨ å¯è§†åŒ–æ¨¡å— ---
# ---------------------------------------------------------------------------------

def create_visualization(original_img, mask, alpha=0.5):
    """
    åˆ›å»ºè½¦é“çº¿åˆ†å‰²å¯è§†åŒ–å›¾åƒ
    
    å‚æ•°ï¼š
        original_img: åŸå§‹BGRå›¾åƒ
        mask: åˆ†å‰²æ©ç  (0/255)
        alpha: é€æ˜åº¦
    
    è¿”å›ï¼š
        å¯è§†åŒ–å›¾åƒ (BGRæ ¼å¼)
    """
    # åˆ›å»ºç»¿è‰²è¦†ç›–å±‚
    green_overlay = np.zeros_like(original_img, dtype=np.uint8)
    green_overlay[mask > 0] = [0, 255, 0]  # BGRæ ¼å¼çš„ç»¿è‰²
    
    # èåˆåŸå›¾å’Œè¦†ç›–å±‚
    vis_img = cv2.addWeighted(original_img, 1.0, green_overlay, alpha, 0)
    
    return vis_img

# ---------------------------------------------------------------------------------
# --- ğŸ§  ONNX Runtimeæ¨ç†ä¼šè¯ ---
# ---------------------------------------------------------------------------------

class ONNXInferSession:
    """ONNX Runtimeæ¨ç†ä¼šè¯ï¼Œæ¨¡æ‹ŸAtlas InferSessionæ¥å£"""
    
    def __init__(self, model_path, provider='CPUExecutionProvider'):
        """
        åˆå§‹åŒ–ONNXæ¨ç†ä¼šè¯
        
        å‚æ•°ï¼š
            model_path: ONNXæ¨¡å‹è·¯å¾„
            provider: æ‰§è¡Œæä¾›è€… ('CPUExecutionProvider', 'CUDAExecutionProvider')
        """
        self.model_path = model_path
        self.provider = provider
        
        # è®¾ç½®æ‰§è¡Œæä¾›è€…
        available_providers = ort.get_available_providers()
        if provider not in available_providers:
            print(f"âš ï¸ è­¦å‘Š: {provider} ä¸å¯ç”¨ï¼Œå¯ç”¨æä¾›è€…: {available_providers}")
            provider = 'CPUExecutionProvider'
        
        print(f"ğŸ§  ä½¿ç”¨æ‰§è¡Œæä¾›è€…: {provider}")
        
        # åˆ›å»ºæ¨ç†ä¼šè¯
        self.session = ort.InferenceSession(model_path, providers=[provider])
        
        # è·å–è¾“å…¥è¾“å‡ºä¿¡æ¯
        self.input_name = self.session.get_inputs()[0].name
        self.output_name = self.session.get_outputs()[0].name
        
        print(f"ğŸ“Š è¾“å…¥èŠ‚ç‚¹: {self.input_name}")
        print(f"ğŸ“Š è¾“å‡ºèŠ‚ç‚¹: {self.output_name}")
    
    def infer(self, inputs):
        """
        æ‰§è¡Œæ¨ç†ï¼Œä¸Atlas InferSession.inferæ¥å£ä¸€è‡´
        
        å‚æ•°ï¼š
            inputs: è¾“å…¥å¼ é‡åˆ—è¡¨
        
        è¿”å›ï¼š
            outputs: è¾“å‡ºå¼ é‡åˆ—è¡¨
        """
        input_tensor = inputs[0]
        
        # æ‰§è¡Œæ¨ç†
        outputs = self.session.run([self.output_name], {self.input_name: input_tensor})
        
        return outputs

# ---------------------------------------------------------------------------------
# --- ğŸ¦… é€è§†å˜æ¢æ¨¡å— (é¸Ÿç°å›¾ç”Ÿæˆ) ---
# ---------------------------------------------------------------------------------

class PerspectiveTransformer:
    """é€è§†å˜æ¢å™¨ï¼Œç”¨äºç”Ÿæˆé¸Ÿç°å›¾"""
    
    def __init__(self, calibration_path):
        """
        åˆå§‹åŒ–é€è§†å˜æ¢å™¨
        
        å‚æ•°ï¼š
            calibration_path: æ ‡å®šæ–‡ä»¶è·¯å¾„
        """
        self.calibration_path = calibration_path
        self.load_calibration()
    
    def load_calibration(self):
        """åŠ è½½æ ‡å®šæ•°æ®"""
        if not os.path.exists(self.calibration_path):
            raise FileNotFoundError(f"æ ‡å®šæ–‡ä»¶ä¸å­˜åœ¨: {self.calibration_path}")
        
        with open(self.calibration_path, 'r', encoding='utf-8') as f:
            self.calibration_data = json.load(f)
        
        # æå–å…³é”®å‚æ•°
        self.transform_matrix = np.array(self.calibration_data['transform_matrix'], dtype=np.float32)
        self.inverse_transform_matrix = np.array(self.calibration_data['inverse_transform_matrix'], dtype=np.float32)
        self.image_points = self.calibration_data['image_points']
        self.world_points = self.calibration_data['world_points']
        self.original_image_size = self.calibration_data['image_size']
        
        print(f"âœ… æ ‡å®šæ•°æ®å·²åŠ è½½: {self.calibration_path}")
    
    def calculate_bird_eye_params(self, pixels_per_unit=20, margin_ratio=0.2):
        """è®¡ç®—é¸Ÿç°å›¾å‚æ•°"""
        # è®¡ç®—ä¸–ç•Œåæ ‡èŒƒå›´
        world_points_array = np.array(self.world_points)
        min_x, min_y = world_points_array.min(axis=0)
        max_x, max_y = world_points_array.max(axis=0)
        
        # æ·»åŠ è¾¹è·
        range_x = max_x - min_x
        range_y = max_y - min_y
        margin = max(range_x, range_y) * margin_ratio
        
        min_x -= margin
        min_y -= margin
        max_x += margin
        max_y += margin
        
        # è®¡ç®—è¾“å‡ºå›¾åƒå°ºå¯¸
        output_width = int((max_x - min_x) * pixels_per_unit)
        output_height = int((max_y - min_y) * pixels_per_unit)
        
        # åˆ›å»ºä¸–ç•Œåæ ‡åˆ°åƒç´ åæ ‡çš„å˜æ¢çŸ©é˜µ
        world_to_pixel = np.array([
            [pixels_per_unit, 0, -min_x * pixels_per_unit],
            [0, pixels_per_unit, -min_y * pixels_per_unit],
            [0, 0, 1]
        ], dtype=np.float32)
        
        # ç»„åˆå˜æ¢çŸ©é˜µï¼šå›¾åƒåæ ‡ â†’ ä¸–ç•Œåæ ‡ â†’ åƒç´ åæ ‡
        combined_transform = world_to_pixel @ self.transform_matrix
        
        view_bounds = (min_x, min_y, max_x, max_y)
        
        return output_width, output_height, combined_transform, view_bounds
    
    def transform_image_and_mask(self, image, mask, pixels_per_unit=20, margin_ratio=0.2):
        """
        å°†å›¾åƒå’Œåˆ†å‰²æ©ç éƒ½è½¬æ¢ä¸ºé¸Ÿç°å›¾
        
        å‚æ•°ï¼š
            image: è¾“å…¥å›¾åƒ (BGRæ ¼å¼)
            mask: åˆ†å‰²æ©ç  (0/255)
            pixels_per_unit: æ¯å•ä½çš„åƒç´ æ•°
            margin_ratio: è¾¹è·æ¯”ä¾‹
        
        è¿”å›ï¼š
            bird_eye_image: é¸Ÿç°å›¾
            bird_eye_mask: é¸Ÿç°å›¾åˆ†å‰²æ©ç 
            view_params: è§†å›¾å‚æ•°å­—å…¸
        """
        # è®¡ç®—é¸Ÿç°å›¾å‚æ•°
        output_width, output_height, combined_transform, view_bounds = \
            self.calculate_bird_eye_params(pixels_per_unit, margin_ratio)
        
        # å¦‚æœè¾“å…¥å›¾åƒå°ºå¯¸ä¸æ ‡å®šæ—¶ä¸åŒï¼Œéœ€è¦è°ƒæ•´å˜æ¢çŸ©é˜µ
        input_height, input_width = image.shape[:2]
        orig_width, orig_height = self.original_image_size
        
        if input_width != orig_width or input_height != orig_height:
            print(f"âš ï¸ å›¾åƒå°ºå¯¸ä¸åŒ¹é…: {input_width}Ã—{input_height} vs {orig_width}Ã—{orig_height}")
            print("ğŸ”„ è‡ªåŠ¨è°ƒæ•´å˜æ¢çŸ©é˜µ...")
            
            # è®¡ç®—ç¼©æ”¾å› å­
            scale_x = input_width / orig_width
            scale_y = input_height / orig_height
            
            # åˆ›å»ºç¼©æ”¾çŸ©é˜µ
            scale_matrix = np.array([
                [scale_x, 0, 0],
                [0, scale_y, 0],
                [0, 0, 1]
            ], dtype=np.float32)
            
            # è°ƒæ•´å˜æ¢çŸ©é˜µ
            adjusted_transform = combined_transform @ np.linalg.inv(scale_matrix)
            combined_transform = adjusted_transform
        
        # æ‰§è¡Œé€è§†å˜æ¢ - å›¾åƒ
        bird_eye_image = cv2.warpPerspective(
            image, combined_transform, 
            (output_width, output_height),
            flags=cv2.INTER_LINEAR,
            borderMode=cv2.BORDER_CONSTANT,
            borderValue=(0, 0, 0)
        )
        
        # æ‰§è¡Œé€è§†å˜æ¢ - åˆ†å‰²æ©ç 
        bird_eye_mask = cv2.warpPerspective(
            mask, combined_transform, 
            (output_width, output_height),
            flags=cv2.INTER_NEAREST,  # ä½¿ç”¨æœ€è¿‘é‚»æ’å€¼ä¿æŒæ©ç çš„äºŒå€¼æ€§
            borderMode=cv2.BORDER_CONSTANT,
            borderValue=0
        )
        
        # å‡†å¤‡è§†å›¾å‚æ•°
        view_params = {
            'output_size': (output_width, output_height),
            'view_bounds': view_bounds,
            'pixels_per_unit': pixels_per_unit,
            'margin_ratio': margin_ratio,
            'transform_matrix': combined_transform.tolist()
        }
        
        return bird_eye_image, bird_eye_mask, view_params

# ---------------------------------------------------------------------------------
# --- ğŸ—ºï¸ æ§åˆ¶åœ°å›¾ç”Ÿæˆæ¨¡å— ---
# ---------------------------------------------------------------------------------

def create_control_map(bird_eye_mask, view_params, add_grid=True):
    """
    åˆ›å»ºç”¨äºè·¯å¾„è§„åˆ’çš„æ§åˆ¶åœ°å›¾
    
    å‚æ•°ï¼š
        bird_eye_mask: é¸Ÿç°å›¾åˆ†å‰²æ©ç 
        view_params: è§†å›¾å‚æ•°
        add_grid: æ˜¯å¦æ·»åŠ ç½‘æ ¼
    
    è¿”å›ï¼š
        control_map: æ§åˆ¶åœ°å›¾ (ä¸‰é€šé“BGRå›¾åƒ)
    """
    # åˆ›å»ºæ§åˆ¶åœ°å›¾
    control_map = np.zeros((bird_eye_mask.shape[0], bird_eye_mask.shape[1], 3), dtype=np.uint8)
    
    # å¯é©¾é©¶åŒºåŸŸ - ç»¿è‰²
    control_map[bird_eye_mask > 0] = [0, 255, 0]  # BGRç»¿è‰²
    
    # ä¸å¯é©¾é©¶åŒºåŸŸ - ä¿æŒé»‘è‰²
    # control_map[bird_eye_mask == 0] = [0, 0, 0]  # å·²ç»æ˜¯é»‘è‰²
    
    if add_grid:
        control_map = add_grid_to_control_map(control_map, view_params)
    
    return control_map

def add_grid_to_control_map(control_map, view_params):
    """
    åœ¨æ§åˆ¶åœ°å›¾ä¸Šæ·»åŠ ç½‘æ ¼å’Œåæ ‡æ ‡ç­¾
    
    å‚æ•°ï¼š
        control_map: æ§åˆ¶åœ°å›¾
        view_params: è§†å›¾å‚æ•°
    
    è¿”å›ï¼š
        å¸¦ç½‘æ ¼çš„æ§åˆ¶åœ°å›¾
    """
    annotated_map = control_map.copy()
    
    min_x, min_y, max_x, max_y = view_params['view_bounds']
    pixels_per_unit = view_params['pixels_per_unit']
    output_width, output_height = view_params['output_size']
    
    # ç»˜åˆ¶ç½‘æ ¼
    grid_interval = 10  # ç½‘æ ¼é—´éš”ï¼ˆå•ä½ï¼šcmæˆ–æŒ‡å®šå•ä½ï¼‰
    grid_color = (128, 128, 128)  # ç°è‰²
    origin_color = (0, 0, 255)    # çº¢è‰²åŸç‚¹
    
    # å‚ç›´çº¿
    x = min_x
    while x <= max_x:
        if abs(x % grid_interval) < 0.1:  # å¤„ç†æµ®ç‚¹æ•°ç²¾åº¦é—®é¢˜
            pixel_x = int((x - min_x) * pixels_per_unit)
            if 0 <= pixel_x < output_width:
                cv2.line(annotated_map, (pixel_x, 0), (pixel_x, output_height-1), grid_color, 1)
                
                # æ·»åŠ Xåæ ‡æ ‡ç­¾
                if abs(x) > 0.1:  # é¿å…åœ¨åŸç‚¹é‡å¤æ ‡æ³¨
                    label = f"{int(x)}"
                    cv2.putText(annotated_map, label, (pixel_x + 2, 20),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.4, grid_color, 1)
        x += grid_interval / 2
    
    # æ°´å¹³çº¿
    y = min_y
    while y <= max_y:
        if abs(y % grid_interval) < 0.1:  # å¤„ç†æµ®ç‚¹æ•°ç²¾åº¦é—®é¢˜
            pixel_y = int((y - min_y) * pixels_per_unit)
            if 0 <= pixel_y < output_height:
                cv2.line(annotated_map, (0, pixel_y), (output_width-1, pixel_y), grid_color, 1)
                
                # æ·»åŠ Yåæ ‡æ ‡ç­¾
                if abs(y) > 0.1:  # é¿å…åœ¨åŸç‚¹é‡å¤æ ‡æ³¨
                    label = f"{int(y)}"
                    cv2.putText(annotated_map, label, (5, pixel_y - 5),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.4, grid_color, 1)
        y += grid_interval / 2
    
    # ç»˜åˆ¶åŸç‚¹
    origin_x = int((0 - min_x) * pixels_per_unit)
    origin_y = int((0 - min_y) * pixels_per_unit)
    
    if 0 <= origin_x < output_width and 0 <= origin_y < output_height:
        cv2.circle(annotated_map, (origin_x, origin_y), 5, origin_color, -1)
        cv2.putText(annotated_map, "O(0,0)", (origin_x + 8, origin_y - 8),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, origin_color, 1)
    
    return annotated_map

# ---------------------------------------------------------------------------------
# --- ğŸ“Š æ€§èƒ½åˆ†æ ---
# ---------------------------------------------------------------------------------

def print_performance_analysis(times_dict, input_tensor, model_path, provider):
    """æ‰“å°è¯¦ç»†çš„æ€§èƒ½åˆ†ææŠ¥å‘Š"""
    total_time = sum(times_dict.values())
    
    print("\n" + "="*60)
    print("ğŸ§  ONNX Runtime + é€è§†å˜æ¢ æ€§èƒ½åˆ†æ")
    print("="*60)
    print(f"ğŸ§  æ¨¡å‹: {Path(model_path).name}")
    print(f"âš¡ æ‰§è¡Œæä¾›è€…: {provider}")
    print(f"ğŸ“ è¾“å…¥å°ºå¯¸: {input_tensor.shape[3]}Ã—{input_tensor.shape[2]} (WÃ—H)")
    print(f"ğŸ¯ æ•°æ®ç±»å‹: {str(input_tensor.dtype).upper()}")
    print("-"*60)
    
    for stage, time_ms in times_dict.items():
        percentage = (time_ms / total_time) * 100
        print(f"â±ï¸  {stage:15}: {time_ms:6.1f}ms ({percentage:5.1f}%)")
    
    print("-"*60)
    print(f"ğŸ æ€»è€—æ—¶: {total_time:.1f}ms")
    print(f"âš¡ ç†è®ºFPS: {1000/total_time:.1f}")
    print("="*60)

# ---------------------------------------------------------------------------------
# --- ğŸ“± ä¸»æ¨ç†å‡½æ•° (é›†æˆæ„ŸçŸ¥ä¸ç¯å¢ƒå»ºæ¨¡) ---
# ---------------------------------------------------------------------------------

def inference_with_bird_eye_view(image_path, model_path, calibration_path=None,
                                provider='CPUExecutionProvider', 
                                pixels_per_unit=20, margin_ratio=0.2,
                                save_visualization=True, save_mask=False,
                                save_bird_eye=False, save_control_map=False):
    """
    é›†æˆè½¦é“çº¿åˆ†å‰²æ¨ç†å’Œé€è§†å˜æ¢çš„å®Œæ•´æ„ŸçŸ¥ç®¡é“
    
    å‚æ•°ï¼š
        image_path: è¾“å…¥å›¾ç‰‡è·¯å¾„
        model_path: ONNXæ¨¡å‹è·¯å¾„
        calibration_path: ç›¸æœºæ ‡å®šæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
        provider: ONNXæ‰§è¡Œæä¾›è€…
        pixels_per_unit: æ¯å•ä½åƒç´ æ•°
        margin_ratio: è¾¹è·æ¯”ä¾‹
        save_visualization: æ˜¯å¦ä¿å­˜æ™®é€šå¯è§†åŒ–ç»“æœ
        save_mask: æ˜¯å¦ä¿å­˜åˆ†å‰²æ©ç 
        save_bird_eye: æ˜¯å¦ä¿å­˜é¸Ÿç°å›¾
        save_control_map: æ˜¯å¦ä¿å­˜æ§åˆ¶åœ°å›¾
    
    è¿”å›ï¼š
        dict: åŒ…å«ç»“æœè·¯å¾„å’Œæ€§èƒ½æ•°æ®
    """
    # éªŒè¯è¾“å…¥æ–‡ä»¶
    if not os.path.exists(image_path):
        raise FileNotFoundError(f"è¾“å…¥å›¾ç‰‡ä¸å­˜åœ¨: {image_path}")
    
    if not os.path.exists(model_path):
        raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
    
    print(f"ğŸ–¼ï¸  åŠ è½½å›¾ç‰‡: {image_path}")
    
    # 1. åŠ è½½å›¾ç‰‡
    load_start = time.time()
    img_bgr = cv2.imread(image_path)
    if img_bgr is None:
        raise ValueError(f"æ— æ³•è¯»å–å›¾ç‰‡: {image_path}")
    
    original_height, original_width = img_bgr.shape[:2]
    load_time = (time.time() - load_start) * 1000
    
    print(f"ğŸ“ åŸå§‹å°ºå¯¸: {original_width}Ã—{original_height}")
    
    # 2. åŠ è½½æ¨¡å‹
    print(f"ğŸ§  åŠ è½½ONNXæ¨¡å‹: {model_path}")
    model_start = time.time()
    model = ONNXInferSession(model_path, provider)
    model_load_time = (time.time() - model_start) * 1000
    print(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆ ({model_load_time:.1f}ms)")
    
    # 3. é¢„å¤„ç†
    print("ğŸ”„ å¼€å§‹é¢„å¤„ç†...")
    preprocess_start = time.time()
    input_data = preprocess_matched_resolution(img_bgr, dtype=np.float32)
    preprocess_time = (time.time() - preprocess_start) * 1000
    
    print(f"ğŸ“Š è¾“å…¥å¼ é‡å½¢çŠ¶: {input_data.shape}")
    print(f"ğŸ“Š æ•°æ®ç±»å‹: {input_data.dtype}")
    
    # 4. ONNXæ¨ç†
    print("ğŸš€ å¼€å§‹ONNXæ¨ç†...")
    inference_start = time.time()
    outputs = model.infer([input_data])
    inference_time = (time.time() - inference_start) * 1000
    
    print(f"ğŸ“Š è¾“å‡ºå¼ é‡å½¢çŠ¶: {outputs[0].shape}")
    
    # 5. åå¤„ç†
    print("ğŸ”„ å¼€å§‹åå¤„ç†...")
    postprocess_start = time.time()
    lane_mask = postprocess_matched_resolution(outputs[0], original_width, original_height)
    postprocess_time = (time.time() - postprocess_start) * 1000
    
    # 6. é€è§†å˜æ¢ï¼ˆå¯é€‰ï¼‰
    transform_time = 0
    bird_eye_image = None
    bird_eye_mask = None
    control_map = None
    view_params = None
    
    if calibration_path and os.path.exists(calibration_path):
        print("ğŸ¦… å¼€å§‹é€è§†å˜æ¢...")
        transform_start = time.time()
        
        transformer = PerspectiveTransformer(calibration_path)
        bird_eye_image, bird_eye_mask, view_params = transformer.transform_image_and_mask(
            img_bgr, lane_mask, pixels_per_unit, margin_ratio)
        
        # ç”Ÿæˆæ§åˆ¶åœ°å›¾
        control_map = create_control_map(bird_eye_mask, view_params, add_grid=True)
        
        transform_time = (time.time() - transform_start) * 1000
        
        print(f"ğŸ“ é¸Ÿç°å›¾å°ºå¯¸: {view_params['output_size'][0]}Ã—{view_params['output_size'][1]}")
        bounds = view_params['view_bounds']
        print(f"ğŸ“ ä¸–ç•Œåæ ‡èŒƒå›´: X({bounds[0]:.1f}~{bounds[2]:.1f}), Y({bounds[1]:.1f}~{bounds[3]:.1f})")
    
    # 7. ä¿å­˜ç»“æœ
    save_start = time.time()
    results = {}
    
    # ä¿å­˜æ™®é€šåˆ†å‰²æ©ç 
    if save_mask:
        mask_path = image_path.replace('.', '_onnx_mask.')
        cv2.imwrite(mask_path, lane_mask)
        results['mask_path'] = mask_path
        print(f"ğŸ’¾ åˆ†å‰²æ©ç å·²ä¿å­˜: {mask_path}")
    
    # ä¿å­˜æ™®é€šå¯è§†åŒ–ç»“æœ
    if save_visualization:
        vis_img = create_visualization(img_bgr, lane_mask)
        vis_path = image_path.replace('.', '_onnx_result.')
        cv2.imwrite(vis_path, vis_img)
        results['visualization_path'] = vis_path
        print(f"ğŸ’¾ å¯è§†åŒ–ç»“æœå·²ä¿å­˜: {vis_path}")
    
    # ä¿å­˜é¸Ÿç°å›¾
    if save_bird_eye and bird_eye_image is not None:
        bird_eye_path = image_path.replace('.', '_bird_eye.')
        cv2.imwrite(bird_eye_path, bird_eye_image)
        results['bird_eye_path'] = bird_eye_path
        print(f"ğŸ’¾ é¸Ÿç°å›¾å·²ä¿å­˜: {bird_eye_path}")
        
        # ä¿å­˜å¸¦åˆ†å‰²ç»“æœçš„é¸Ÿç°å›¾
        bird_eye_vis = create_visualization(bird_eye_image, bird_eye_mask)
        bird_eye_vis_path = image_path.replace('.', '_bird_eye_segmented.')
        cv2.imwrite(bird_eye_vis_path, bird_eye_vis)
        results['bird_eye_vis_path'] = bird_eye_vis_path
        print(f"ğŸ’¾ é¸Ÿç°å›¾åˆ†å‰²å¯è§†åŒ–å·²ä¿å­˜: {bird_eye_vis_path}")
    
    # ä¿å­˜æ§åˆ¶åœ°å›¾
    if save_control_map and control_map is not None:
        control_map_path = image_path.replace('.', '_control_map.')
        cv2.imwrite(control_map_path, control_map)
        results['control_map_path'] = control_map_path
        print(f"ğŸ’¾ æ§åˆ¶åœ°å›¾å·²ä¿å­˜: {control_map_path}")
    
    save_time = (time.time() - save_start) * 1000
    
    # 8. æ€§èƒ½åˆ†æ
    times_dict = {
        "å›¾ç‰‡åŠ è½½": load_time,
        "æ¨¡å‹åŠ è½½": model_load_time,
        "CPUé¢„å¤„ç†": preprocess_time,
        "ONNXæ¨ç†": inference_time,
        "CPUåå¤„ç†": postprocess_time,
        "é€è§†å˜æ¢": transform_time,
        "ç»“æœä¿å­˜": save_time
    }
    
    print_performance_analysis(times_dict, input_data, model_path, provider)
    
    # 9. ç»Ÿè®¡è½¦é“çº¿åƒç´ 
    lane_pixels = np.sum(lane_mask > 0)
    total_pixels = lane_mask.shape[0] * lane_mask.shape[1]
    lane_ratio = (lane_pixels / total_pixels) * 100
    
    print(f"\nğŸ“ˆ æ£€æµ‹ç»“æœç»Ÿè®¡:")
    print(f"ğŸ›£ï¸  è½¦é“çº¿åƒç´ : {lane_pixels:,} / {total_pixels:,} ({lane_ratio:.2f}%)")
    
    if bird_eye_mask is not None:
        bird_lane_pixels = np.sum(bird_eye_mask > 0)
        bird_total_pixels = bird_eye_mask.shape[0] * bird_eye_mask.shape[1]
        bird_lane_ratio = (bird_lane_pixels / bird_total_pixels) * 100
        print(f"ğŸ¦… é¸Ÿç°å›¾è½¦é“çº¿åƒç´ : {bird_lane_pixels:,} / {bird_total_pixels:,} ({bird_lane_ratio:.2f}%)")
    
    results.update({
        'lane_pixels': lane_pixels,
        'total_pixels': total_pixels,
        'lane_ratio': lane_ratio,
        'performance': times_dict,
        'provider': provider,
        'view_params': view_params
    })
    
    return results

# ---------------------------------------------------------------------------------
# --- ğŸ“± å‘½ä»¤è¡Œæ¥å£ ---
# ---------------------------------------------------------------------------------

def main():
    parser = argparse.ArgumentParser(description="é›†æˆæ„ŸçŸ¥ä¸ç¯å¢ƒå»ºæ¨¡çš„è½¦é“çº¿åˆ†å‰²æ¨ç†å·¥å…·")
    parser.add_argument("--input", "-i", required=True, help="è¾“å…¥å›¾ç‰‡è·¯å¾„")
    parser.add_argument("--output", "-o", help="è¾“å‡ºå¯è§†åŒ–å›¾ç‰‡è·¯å¾„ï¼ˆå¯é€‰ï¼‰")
    parser.add_argument("--save_mask", help="ä¿å­˜åˆ†å‰²æ©ç è·¯å¾„ï¼ˆå¯é€‰ï¼‰")
    parser.add_argument("--model", "-m", 
                       default="./weights/fast_scnn_custom_e2e_640x360_fixed_simplified.onnx",
                       help="ONNXæ¨¡å‹è·¯å¾„")
    parser.add_argument("--calibration", "-c", help="ç›¸æœºæ ‡å®šæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--provider", "-p", 
                       default="CPUExecutionProvider",
                       choices=["CPUExecutionProvider", "CUDAExecutionProvider"],
                       help="ONNXæ‰§è¡Œæä¾›è€…")
    parser.add_argument("--pixels_per_unit", type=int, default=20, help="æ¯å•ä½åƒç´ æ•° (é»˜è®¤: 20)")
    parser.add_argument("--margin_ratio", type=float, default=0.2, help="è¾¹è·æ¯”ä¾‹ (é»˜è®¤: 0.2)")
    parser.add_argument("--no_vis", action="store_true", help="ä¸ä¿å­˜å¯è§†åŒ–ç»“æœï¼Œä»…æ¨ç†")
    parser.add_argument("--bird_eye", action="store_true", help="ç”Ÿæˆé¸Ÿç°å›¾ï¼ˆéœ€è¦æ ‡å®šæ–‡ä»¶ï¼‰")
    parser.add_argument("--save_control_map", action="store_true", help="ä¿å­˜æ§åˆ¶åœ°å›¾")
    parser.add_argument("--preview", action="store_true", help="æ˜¾ç¤ºé¢„è§ˆçª—å£")
    
    args = parser.parse_args()
    
    try:
        print("ğŸ§  é›†æˆæ„ŸçŸ¥ä¸ç¯å¢ƒå»ºæ¨¡çš„è½¦é“çº¿åˆ†å‰²æ¨ç†å·¥å…·")
        print("=" * 60)
        print("ğŸ“ åŠŸèƒ½: è½¦é“çº¿åˆ†å‰² + é€è§†å˜æ¢ + æ§åˆ¶åœ°å›¾ç”Ÿæˆ")
        print("=" * 60)
        
        # æ£€æŸ¥å¯ç”¨çš„æ‰§è¡Œæä¾›è€…
        available_providers = ort.get_available_providers()
        print(f"ğŸ”§ å¯ç”¨æ‰§è¡Œæä¾›è€…: {available_providers}")
        
        # éªŒè¯è¾“å…¥æ–‡ä»¶å­˜åœ¨
        if not os.path.exists(args.input):
            print(f"âŒ é”™è¯¯ï¼šè¾“å…¥å›¾ç‰‡ä¸å­˜åœ¨: {args.input}")
            sys.exit(1)
        
        # éªŒè¯æ ‡å®šæ–‡ä»¶ï¼ˆå¦‚æœéœ€è¦é€è§†å˜æ¢ï¼‰
        if (args.bird_eye or args.save_control_map) and not args.calibration:
            print("âŒ é”™è¯¯ï¼šç”Ÿæˆé¸Ÿç°å›¾æˆ–æ§åˆ¶åœ°å›¾éœ€è¦æŒ‡å®šæ ‡å®šæ–‡ä»¶ (--calibration)")
            sys.exit(1)
        
        # è‡ªåŠ¨ç¡®å®šè¾“å‡ºè·¯å¾„
        save_visualization = not args.no_vis
        save_mask = bool(args.save_mask)
        save_bird_eye = args.bird_eye
        save_control_map = args.save_control_map
        
        # æ‰§è¡Œæ¨ç†
        results = inference_with_bird_eye_view(
            image_path=args.input,
            model_path=args.model,
            calibration_path=args.calibration,
            provider=args.provider,
            pixels_per_unit=args.pixels_per_unit,
            margin_ratio=args.margin_ratio,
            save_visualization=save_visualization,
            save_mask=save_mask,
            save_bird_eye=save_bird_eye,
            save_control_map=save_control_map
        )
        
        # å¤„ç†è¾“å‡ºè·¯å¾„é‡å‘½å
        if args.output and 'visualization_path' in results:
            import shutil
            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            output_dir = os.path.dirname(args.output)
            if output_dir and not os.path.exists(output_dir):
                os.makedirs(output_dir)
            
            # ç§»åŠ¨å¯è§†åŒ–ç»“æœåˆ°æŒ‡å®šè·¯å¾„
            shutil.move(results['visualization_path'], args.output)
            results['visualization_path'] = args.output
            print(f"ğŸ’¾ å¯è§†åŒ–ç»“æœå·²ç§»åŠ¨åˆ°æŒ‡å®šè·¯å¾„: {args.output}")
        
        # å¤„ç†æ©ç è·¯å¾„é‡å‘½å
        if args.save_mask and 'mask_path' in results:
            import shutil
            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            mask_dir = os.path.dirname(args.save_mask)
            if mask_dir and not os.path.exists(mask_dir):
                os.makedirs(mask_dir)
            
            # ç§»åŠ¨åˆ†å‰²æ©ç åˆ°æŒ‡å®šè·¯å¾„
            shutil.move(results['mask_path'], args.save_mask)
            results['mask_path'] = args.save_mask
            print(f"ğŸ’¾ åˆ†å‰²æ©ç å·²ç§»åŠ¨åˆ°æŒ‡å®šè·¯å¾„: {args.save_mask}")
        
        # é¢„è§ˆç»“æœï¼ˆå¯é€‰ï¼‰
        if args.preview:
            print("ğŸ‘ï¸ æ˜¾ç¤ºé¢„è§ˆ...")
            original = cv2.imread(args.input)
            
            if 'visualization_path' in results:
                vis_result = cv2.imread(results['visualization_path'])
                cv2.imshow("Original Image", original)
                cv2.imshow("Segmentation Result", vis_result)
            
            if 'bird_eye_vis_path' in results:
                bird_eye_vis = cv2.imread(results['bird_eye_vis_path'])
                cv2.imshow("Bird's Eye View Segmentation", bird_eye_vis)
            
            if 'control_map_path' in results:
                control_map = cv2.imread(results['control_map_path'])
                cv2.imshow("Control Map", control_map)
            
            print("æŒ‰ä»»æ„é”®å…³é—­é¢„è§ˆ...")
            cv2.waitKey(0)
            cv2.destroyAllWindows()
        
        print("\nâœ… æ„ŸçŸ¥ä¸ç¯å¢ƒå»ºæ¨¡å®Œæˆï¼")
        print("ğŸ”§ æ­¤ç»“æœå¯ç”¨äºåç»­çš„è·¯å¾„è§„åˆ’å’Œè½¦è¾†æ§åˆ¶")
        
        if 'visualization_path' in results:
            print(f"ğŸ¨ åˆ†å‰²å¯è§†åŒ–: {results['visualization_path']}")
        if 'mask_path' in results:
            print(f"ğŸ­ åˆ†å‰²æ©ç : {results['mask_path']}")
        if 'bird_eye_vis_path' in results:
            print(f"ğŸ¦… é¸Ÿç°å›¾åˆ†å‰²: {results['bird_eye_vis_path']}")
        if 'control_map_path' in results:
            print(f"ğŸ—ºï¸ æ§åˆ¶åœ°å›¾: {results['control_map_path']}")
            
    except Exception as e:
        print(f"âŒ æ¨ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    main()
