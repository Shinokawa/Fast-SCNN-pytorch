"""
æµ‹è¯•customæ•°æ®é›†ç«¯åˆ°ç«¯ONNXæ¨¡å‹
éªŒè¯ONNXæ¨¡å‹çš„æ­£ç¡®æ€§ï¼Œä¸PyTorchæ¨¡å‹å¯¹æ¯”ï¼Œæ”¯æŒå¯è§†åŒ–ç»“æœ
"""
import os
import cv2
import numpy as np
import torch
import torch.nn.functional as F
from PIL import Image
import matplotlib.pyplot as plt
import argparse
import time
from models.fast_scnn import FastSCNN

def load_pytorch_model(model_path, device):
    """åŠ è½½PyTorchæ¨¡å‹ç”¨äºå¯¹æ¯”"""
    model = FastSCNN(num_classes=2, aux=True)
    state_dict = torch.load(model_path, map_location='cpu')
    if any(key.startswith('module.') for key in state_dict.keys()):
        state_dict = {k.replace('module.', ''): v for k, v in state_dict.items()}
    model.load_state_dict(state_dict)
    model.to(device)
    model.eval()
    return model

def preprocess_image_pytorch(image_path, target_size=(1024, 1024)):
    """PyTorchæ¨¡å‹é¢„å¤„ç† (ä¸validate_model_predictions.pyä¸€è‡´)"""
    image = Image.open(image_path).convert('RGB')
    image = image.resize(target_size, Image.BILINEAR)
    
    img_array = np.array(image).astype(np.float32) / 255.0
    input_tensor = torch.from_numpy(img_array.transpose((2, 0, 1))).unsqueeze(0)
    
    return input_tensor, image

def preprocess_image_onnx(image_path, target_size=(360, 640)):
    """ONNXæ¨¡å‹é¢„å¤„ç† (ç«¯åˆ°ç«¯ï¼Œä»»æ„å°ºå¯¸è¾“å…¥)"""
    image = cv2.imread(image_path)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    # ç«¯åˆ°ç«¯ONNXæ¨¡å‹å¯ä»¥æ¥å—ä»»æ„å°ºå¯¸ï¼Œå†…éƒ¨ä¼šè‡ªåŠ¨resize
    # ä½†ä¸ºäº†æœ€ä½³æ€§èƒ½ï¼Œå»ºè®®è¾“å…¥ç›®æ ‡å°ºå¯¸
    image_resized = cv2.resize(image, (target_size[1], target_size[0]))  # W, H
    
    # è½¬æ¢ä¸ºNCHWæ ¼å¼ï¼Œä¿æŒ0-255èŒƒå›´
    input_data = image_resized.transpose(2, 0, 1)[None].astype(np.float32)
    
    return input_data, image, image_resized

def compare_models(pytorch_model, onnx_session, image_path, device, args):
    """å¯¹æ¯”PyTorchå’ŒONNXæ¨¡å‹è¾“å‡º"""
    print(f"\nğŸ” å¯¹æ¯”æµ‹è¯•: {os.path.basename(image_path)}")
    
    # PyTorchæ¨ç†
    print("  ğŸ PyTorchæ¨ç†...")
    pytorch_input, original_image = preprocess_image_pytorch(image_path, (1024, 1024))
    pytorch_input = pytorch_input.to(device)
    
    with torch.no_grad():
        start_time = time.time()
        pytorch_outputs = pytorch_model(pytorch_input)
        pytorch_time = time.time() - start_time
        
        if isinstance(pytorch_outputs, tuple):
            pytorch_output = pytorch_outputs[0]
        else:
            pytorch_output = pytorch_outputs
        
        pytorch_probs = F.softmax(pytorch_output, dim=1)
        pytorch_mask = torch.argmax(pytorch_probs, dim=1).cpu().numpy()[0]
    
    # ONNXæ¨ç†
    print("  ğŸ”§ ONNXæ¨ç†...")
    onnx_input, _, onnx_image = preprocess_image_onnx(image_path, (args.input_height, args.input_width))
    
    start_time = time.time()
    onnx_outputs = onnx_session.run(None, {'input': onnx_input})
    onnx_time = time.time() - start_time
    
    onnx_output = onnx_outputs[0][0]  # Remove batch dimension
    onnx_mask = np.argmax(onnx_output, axis=0)
    
    # ç»“æœç»Ÿè®¡
    pytorch_drivable = np.sum(pytorch_mask) / pytorch_mask.size
    onnx_drivable = np.sum(onnx_mask) / onnx_mask.size
    
    print(f"  âš¡ PyTorchæ—¶é—´: {pytorch_time*1000:.2f}ms")
    print(f"  âš¡ ONNXæ—¶é—´: {onnx_time*1000:.2f}ms")
    print(f"  ğŸš€ ONNXåŠ é€Ÿæ¯”: {pytorch_time/onnx_time:.2f}x")
    print(f"  ğŸ¯ PyTorchå¯é©¾é©¶åŒºåŸŸ: {pytorch_drivable*100:.1f}%")
    print(f"  ğŸ¯ ONNXå¯é©¾é©¶åŒºåŸŸ: {onnx_drivable*100:.1f}%")
    
    # å¯è§†åŒ–å¯¹æ¯”
    if args.save_comparison:
        save_comparison(original_image, onnx_image, pytorch_mask, onnx_mask, 
                       image_path, args.output_dir)
    
    return {
        'pytorch_time': pytorch_time,
        'onnx_time': onnx_time,
        'speedup': pytorch_time / onnx_time,
        'pytorch_drivable': pytorch_drivable,
        'onnx_drivable': onnx_drivable,
        'pytorch_mask': pytorch_mask,
        'onnx_mask': onnx_mask
    }

def save_comparison(original_image, onnx_image, pytorch_mask, onnx_mask, image_path, output_dir):
    """ä¿å­˜å¯¹æ¯”å¯è§†åŒ–ç»“æœ"""
    os.makedirs(output_dir, exist_ok=True)
    
    fig, axes = plt.subplots(2, 3, figsize=(15, 10))
    
    # åŸå§‹å›¾åƒ
    axes[0, 0].imshow(original_image)
    axes[0, 0].set_title('Original Image (1024x1024)')
    axes[0, 0].axis('off')
    
    # ONNXè¾“å…¥å›¾åƒ
    axes[0, 1].imshow(onnx_image)
    axes[0, 1].set_title('ONNX Input (640x360)')
    axes[0, 1].axis('off')
    
    # ç©ºç™½
    axes[0, 2].axis('off')
    
    # PyTorchç»“æœ
    axes[1, 0].imshow(pytorch_mask, cmap='gray')
    axes[1, 0].set_title(f'PyTorch Result\nDrivable: {np.sum(pytorch_mask)/pytorch_mask.size*100:.1f}%')
    axes[1, 0].axis('off')
    
    # ONNXç»“æœ
    axes[1, 1].imshow(onnx_mask, cmap='gray')
    axes[1, 1].set_title(f'ONNX Result\nDrivable: {np.sum(onnx_mask)/onnx_mask.size*100:.1f}%')
    axes[1, 1].axis('off')
    
    # å·®å¼‚å›¾
    if pytorch_mask.shape == onnx_mask.shape:
        diff = np.abs(pytorch_mask.astype(float) - onnx_mask.astype(float))
        diff_ratio = np.sum(diff) / diff.size
        axes[1, 2].imshow(diff, cmap='Reds')
        axes[1, 2].set_title(f'Difference\nDiff: {diff_ratio*100:.1f}%')
    else:
        # å°ºå¯¸ä¸åŒæ—¶ï¼Œresizeåå¯¹æ¯”
        pytorch_resized = cv2.resize(pytorch_mask.astype(np.uint8), 
                                   (onnx_mask.shape[1], onnx_mask.shape[0]), 
                                   interpolation=cv2.INTER_NEAREST)
        diff = np.abs(pytorch_resized.astype(float) - onnx_mask.astype(float))
        diff_ratio = np.sum(diff) / diff.size
        axes[1, 2].imshow(diff, cmap='Reds')
        axes[1, 2].set_title(f'Difference (Resized)\nDiff: {diff_ratio*100:.1f}%')
    
    axes[1, 2].axis('off')
    
    plt.tight_layout()
    
    filename = os.path.splitext(os.path.basename(image_path))[0]
    save_path = os.path.join(output_dir, f"{filename}_comparison.png")
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    plt.close()
    
    print(f"  ğŸ’¾ å¯¹æ¯”å›¾ä¿å­˜: {save_path}")

def test_onnx_model(onnx_path, test_images, args):
    """æµ‹è¯•ONNXæ¨¡å‹"""
    try:
        import onnxruntime as ort
        
        print(f"ğŸ§ª æµ‹è¯•ONNXæ¨¡å‹: {onnx_path}")
        
        # åˆ›å»ºæ¨ç†ä¼šè¯
        providers = ['CUDAExecutionProvider', 'CPUExecutionProvider']
        session = ort.InferenceSession(onnx_path, providers=providers)
        print(f"  ğŸ–¥ï¸  æ‰§è¡Œæä¾›å•†: {session.get_providers()}")
        
        # åŠ è½½PyTorchæ¨¡å‹ç”¨äºå¯¹æ¯”
        pytorch_model = None
        if args.compare_pytorch and args.pytorch_model:
            device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
            pytorch_model = load_pytorch_model(args.pytorch_model, device)
            print(f"  ğŸ PyTorchæ¨¡å‹åŠ è½½æˆåŠŸ")
        
        results = []
        
        for image_path in test_images:
            if not os.path.exists(image_path):
                print(f"  âš ï¸  å›¾åƒä¸å­˜åœ¨: {image_path}")
                continue
            
            if pytorch_model is not None:
                # å¯¹æ¯”æµ‹è¯•
                result = compare_models(pytorch_model, session, image_path, device, args)
                results.append(result)
            else:
                # ä»…ONNXæµ‹è¯•
                print(f"\nğŸ§ª ONNXæµ‹è¯•: {os.path.basename(image_path)}")
                
                onnx_input, _, onnx_image = preprocess_image_onnx(image_path, (args.input_height, args.input_width))
                
                start_time = time.time()
                onnx_outputs = session.run(None, {'input': onnx_input})
                onnx_time = time.time() - start_time
                
                onnx_output = onnx_outputs[0][0]
                onnx_mask = np.argmax(onnx_output, axis=0)
                onnx_drivable = np.sum(onnx_mask) / onnx_mask.size
                
                print(f"  âš¡ ONNXæ—¶é—´: {onnx_time*1000:.2f}ms")
                print(f"  ğŸš€ ç†è®ºFPS: {1/onnx_time:.1f}")
                print(f"  ğŸ¯ å¯é©¾é©¶åŒºåŸŸ: {onnx_drivable*100:.1f}%")
                print(f"  ğŸ“Š è¾“å‡ºå°ºå¯¸: {onnx_mask.shape}")
                
                results.append({
                    'onnx_time': onnx_time,
                    'onnx_drivable': onnx_drivable
                })
        
        # æ±‡æ€»ç»Ÿè®¡
        if results:
            avg_onnx_time = np.mean([r.get('onnx_time', 0) for r in results])
            avg_onnx_fps = 1 / avg_onnx_time if avg_onnx_time > 0 else 0
            
            print(f"\nğŸ“Š æµ‹è¯•æ±‡æ€» (å…±{len(results)}å¼ å›¾åƒ):")
            print(f"  âš¡ å¹³å‡ONNXæ¨ç†æ—¶é—´: {avg_onnx_time*1000:.2f}ms")
            print(f"  ğŸš€ å¹³å‡ç†è®ºFPS: {avg_onnx_fps:.1f}")
            
            if pytorch_model is not None:
                avg_pytorch_time = np.mean([r.get('pytorch_time', 0) for r in results])
                avg_speedup = np.mean([r.get('speedup', 0) for r in results])
                
                print(f"  âš¡ å¹³å‡PyTorchæ¨ç†æ—¶é—´: {avg_pytorch_time*1000:.2f}ms")
                print(f"  ğŸš€ å¹³å‡åŠ é€Ÿæ¯”: {avg_speedup:.2f}x")
                
                # å¯é©¾é©¶åŒºåŸŸä¸€è‡´æ€§
                pytorch_drivables = [r.get('pytorch_drivable', 0) for r in results]
                onnx_drivables = [r.get('onnx_drivable', 0) for r in results]
                consistency = np.mean([1 - abs(p - o) for p, o in zip(pytorch_drivables, onnx_drivables)])
                
                print(f"  ğŸ¯ ç»“æœä¸€è‡´æ€§: {consistency*100:.1f}%")
        
        return True
        
    except ImportError:
        print("âŒ onnxruntimeæœªå®‰è£…")
        print("   å®‰è£…å‘½ä»¤: pip install onnxruntime-gpu  # GPUç‰ˆæœ¬")
        print("   å®‰è£…å‘½ä»¤: pip install onnxruntime      # CPUç‰ˆæœ¬")
        return False
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return False

def parse_args():
    parser = argparse.ArgumentParser(description='Test Custom Dataset End-to-End ONNX Model')
    parser.add_argument('--onnx-model', type=str, required=True,
                        help='path to ONNX model')
    parser.add_argument('--pytorch-model', type=str, 
                        default='./weights/custom_scratch/fast_scnn_custom.pth',
                        help='path to PyTorch model for comparison')
    parser.add_argument('--test-images', type=str, nargs='+',
                        help='test image paths')
    parser.add_argument('--test-dir', type=str,
                        help='directory containing test images')
    parser.add_argument('--input-size', type=str, default='360,640',
                        help='ONNX model input size as height,width')
    parser.add_argument('--compare-pytorch', action='store_true', default=True,
                        help='compare with PyTorch model')
    parser.add_argument('--save-comparison', action='store_true', default=True,
                        help='save comparison visualizations')
    parser.add_argument('--output-dir', type=str, default='onnx_test_results',
                        help='output directory for results')
    args = parser.parse_args()
    
    # Parse input size
    h, w = map(int, args.input_size.split(','))
    args.input_height = h
    args.input_width = w
    
    return args

def main():
    args = parse_args()
    
    print("ğŸ§ª Customæ•°æ®é›†ç«¯åˆ°ç«¯ONNXæ¨¡å‹æµ‹è¯•")
    print("=" * 50)
    
    # æ”¶é›†æµ‹è¯•å›¾åƒ
    test_images = []
    
    if args.test_images:
        test_images.extend(args.test_images)
    
    if args.test_dir and os.path.isdir(args.test_dir):
        for ext in ['*.jpg', '*.jpeg', '*.png']:
            import glob
            test_images.extend(glob.glob(os.path.join(args.test_dir, ext)))
    
    # å¦‚æœæ²¡æœ‰æŒ‡å®šæµ‹è¯•å›¾åƒï¼Œå°è¯•ä½¿ç”¨data/custom/imagesä¸­çš„å›¾åƒ
    if not test_images:
        custom_images_dir = 'data/custom/images'
        if os.path.isdir(custom_images_dir):
            test_images = [os.path.join(custom_images_dir, f) 
                          for f in os.listdir(custom_images_dir) 
                          if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
            print(f"ğŸ” è‡ªåŠ¨å‘ç°æµ‹è¯•å›¾åƒ: {len(test_images)}å¼ ")
    
    if not test_images:
        print("âŒ æœªæ‰¾åˆ°æµ‹è¯•å›¾åƒï¼")
        print("è¯·ä½¿ç”¨ --test-images æˆ– --test-dir æŒ‡å®šæµ‹è¯•å›¾åƒ")
        return
    
    print(f"ğŸ“ æµ‹è¯•å›¾åƒ: {len(test_images)}å¼ ")
    for img in test_images[:5]:  # åªæ˜¾ç¤ºå‰5å¼ 
        print(f"   {os.path.basename(img)}")
    if len(test_images) > 5:
        print(f"   ... è¿˜æœ‰{len(test_images)-5}å¼ ")
    
    # æµ‹è¯•ONNXæ¨¡å‹
    success = test_onnx_model(args.onnx_model, test_images, args)
    
    if success:
        print(f"\nâœ… æµ‹è¯•å®Œæˆ!")
        if args.save_comparison:
            print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {args.output_dir}")
    else:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥!")

if __name__ == '__main__':
    main() 