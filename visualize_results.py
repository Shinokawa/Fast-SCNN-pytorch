#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç”Ÿæˆè‡ªå®šä¹‰æ•°æ®é›†å¾®è°ƒæ¨¡å‹çš„å¯è§†åŒ–æ•ˆæœå¯¹æ¯”
å¯¹æ¯”åŸå›¾ã€çœŸå®æ ‡ç­¾ã€é¢„æµ‹ç»“æœå’Œè¯¯å·®å›¾
"""

import os
import sys
import numpy as np
import torch
import torch.nn.functional as F
from PIL import Image
import matplotlib.pyplot as plt
import matplotlib.patches as mpatches

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

try:
    import cv2
    HAS_CV2 = True
    print("âœ… æ£€æµ‹åˆ°opencv-pythonï¼Œå°†ç”Ÿæˆå åŠ æ•ˆæœå›¾")
except ImportError:
    HAS_CV2 = False
    print("âš ï¸ æœªå®‰è£…opencv-pythonï¼Œå°†ä½¿ç”¨ç®€åŒ–ç‰ˆå¯è§†åŒ–")

from models.fast_scnn import get_fast_scnn
from data_loader.custom import CustomDataset

def load_model(model_path, device):
    """åŠ è½½å¾®è°ƒæ¨¡å‹"""
    print(f"åŠ è½½æ¨¡å‹: {model_path}")
    
    # åˆ›å»ºæ¨¡å‹
    model = get_fast_scnn(dataset='custom', aux=False).to(device)
    
    # åŠ è½½æƒé‡
    checkpoint = torch.load(model_path, map_location=device, weights_only=False)
    if 'model' in checkpoint:
        model.load_state_dict(checkpoint['model'])
    else:
        model.load_state_dict(checkpoint)
    
    model.eval()
    print("âœ… æ¨¡å‹åŠ è½½å®Œæˆ")
    return model

def calculate_metrics(mask_true, mask_pred):
    """è®¡ç®—åˆ†å‰²æŒ‡æ ‡"""
    if torch.is_tensor(mask_true):
        mask_true = mask_true.cpu().numpy()
    if torch.is_tensor(mask_pred):
        mask_pred = mask_pred.cpu().numpy()
    
    # åƒç´ å‡†ç¡®ç‡
    correct = (mask_true == mask_pred).sum()
    total = mask_true.size
    pixel_acc = correct / total
    
    # è®¡ç®—IoU for each class
    ious = []
    for cls in range(2):  # 0: ä¸å¯é©¾é©¶, 1: å¯é©¾é©¶
        pred_cls = (mask_pred == cls)
        true_cls = (mask_true == cls)
        
        intersection = (pred_cls & true_cls).sum()
        union = (pred_cls | true_cls).sum()
        
        if union > 0:
            iou = intersection / union
        else:
            iou = 1.0  # å¦‚æœè¯¥ç±»åˆ«ä¸å­˜åœ¨ï¼ŒIoUä¸º1
        ious.append(iou)
    
    mean_iou = np.mean(ious)
    
    return {
        'pixel_accuracy': pixel_acc,
        'mean_iou': mean_iou,
        'class_ious': ious
    }

def visualize_comparison(image, mask_true, mask_pred, save_path, filename, metrics=None):
    """ç”Ÿæˆè¯¦ç»†çš„å¯è§†åŒ–å¯¹æ¯”å›¾"""
    if HAS_CV2:
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        
        # åŸå§‹å›¾åƒ
        axes[0, 0].imshow(image)
        axes[0, 0].set_title('åŸå§‹å›¾åƒ', fontsize=14, fontweight='bold')
        axes[0, 0].axis('off')
        
        # çœŸå®æ ‡ç­¾
        im1 = axes[0, 1].imshow(mask_true, cmap='RdYlBu_r', vmin=0, vmax=1)
        axes[0, 1].set_title('çœŸå®æ ‡ç­¾', fontsize=14, fontweight='bold')
        axes[0, 1].axis('off')
        
        # é¢„æµ‹ç»“æœ
        im2 = axes[0, 2].imshow(mask_pred, cmap='RdYlBu_r', vmin=0, vmax=1)
        axes[0, 2].set_title('é¢„æµ‹ç»“æœ', fontsize=14, fontweight='bold')
        axes[0, 2].axis('off')
        
        # å åŠ æ•ˆæœ - åŸå›¾ + çœŸå®æ ‡ç­¾
        overlay_true = np.array(image * 255).astype(np.uint8)
        mask_true_colored = np.zeros_like(overlay_true)
        mask_true_colored[mask_true == 1] = [0, 255, 0]  # ç»¿è‰²è¡¨ç¤ºå¯é©¾é©¶
        overlay_true = cv2.addWeighted(overlay_true, 0.7, mask_true_colored, 0.3, 0)
        axes[1, 0].imshow(overlay_true)
        axes[1, 0].set_title('åŸå›¾ + çœŸå®æ ‡ç­¾', fontsize=14, fontweight='bold')
        axes[1, 0].axis('off')
        
        # å åŠ æ•ˆæœ - åŸå›¾ + é¢„æµ‹ç»“æœ
        overlay_pred = np.array(image * 255).astype(np.uint8)
        mask_pred_colored = np.zeros_like(overlay_pred)
        mask_pred_colored[mask_pred == 1] = [255, 0, 0]  # çº¢è‰²è¡¨ç¤ºé¢„æµ‹å¯é©¾é©¶
        overlay_pred = cv2.addWeighted(overlay_pred, 0.7, mask_pred_colored, 0.3, 0)
        axes[1, 1].imshow(overlay_pred)
        axes[1, 1].set_title('åŸå›¾ + é¢„æµ‹ç»“æœ', fontsize=14, fontweight='bold')
        axes[1, 1].axis('off')
        
        # å·®å¼‚å›¾
        diff = np.abs(mask_true.astype(float) - mask_pred.astype(float))
        im3 = axes[1, 2].imshow(diff, cmap='Reds', vmin=0, vmax=1)
        axes[1, 2].set_title('é¢„æµ‹è¯¯å·®', fontsize=14, fontweight='bold')
        axes[1, 2].axis('off')
        
        # æ·»åŠ é¢œè‰²æ¡
        plt.colorbar(im1, ax=axes[0, 1], shrink=0.6)
        plt.colorbar(im2, ax=axes[0, 2], shrink=0.6)
        plt.colorbar(im3, ax=axes[1, 2], shrink=0.6)
        
    else:
        # ç®€åŒ–ç‰ˆï¼ˆä¸ä½¿ç”¨opencvï¼‰
        fig, axes = plt.subplots(2, 2, figsize=(12, 10))
        
        # åŸå§‹å›¾åƒ
        axes[0, 0].imshow(image)
        axes[0, 0].set_title('åŸå§‹å›¾åƒ', fontsize=14, fontweight='bold')
        axes[0, 0].axis('off')
        
        # çœŸå®æ ‡ç­¾
        im1 = axes[0, 1].imshow(mask_true, cmap='RdYlBu_r', vmin=0, vmax=1)
        axes[0, 1].set_title('çœŸå®æ ‡ç­¾', fontsize=14, fontweight='bold')
        axes[0, 1].axis('off')
        
        # é¢„æµ‹ç»“æœ
        im2 = axes[1, 0].imshow(mask_pred, cmap='RdYlBu_r', vmin=0, vmax=1)
        axes[1, 0].set_title('é¢„æµ‹ç»“æœ', fontsize=14, fontweight='bold')
        axes[1, 0].axis('off')
        
        # å·®å¼‚å›¾
        diff = np.abs(mask_true.astype(float) - mask_pred.astype(float))
        im3 = axes[1, 1].imshow(diff, cmap='Reds', vmin=0, vmax=1)
        axes[1, 1].set_title('é¢„æµ‹è¯¯å·®', fontsize=14, fontweight='bold')
        axes[1, 1].axis('off')
    
    # æ·»åŠ å›¾ä¾‹
    legend_elements = [
        mpatches.Patch(color='red', label='å¯é©¾é©¶åŒºåŸŸ'),
        mpatches.Patch(color='blue', label='ä¸å¯é©¾é©¶åŒºåŸŸ')
    ]
    fig.legend(handles=legend_elements, loc='upper center', ncol=2, 
              bbox_to_anchor=(0.5, 0.95), fontsize=12)
    
    # æ·»åŠ æ€§èƒ½æŒ‡æ ‡æ–‡å­—
    if metrics:
        metrics_text = f"""æ€§èƒ½æŒ‡æ ‡:
åƒç´ å‡†ç¡®ç‡: {metrics['pixel_accuracy']:.3f}
å¹³å‡IoU: {metrics['mean_iou']:.3f}
ä¸å¯é©¾é©¶IoU: {metrics['class_ious'][0]:.3f}
å¯é©¾é©¶IoU: {metrics['class_ious'][1]:.3f}"""
        
        plt.figtext(0.02, 0.02, metrics_text, fontsize=11, 
                   bbox=dict(boxstyle="round,pad=0.5", facecolor="lightgray"))
    
    plt.tight_layout()
    plt.subplots_adjust(top=0.9, bottom=0.1)
    
    save_file = os.path.join(save_path, f'{filename}_comparison.png')
    plt.savefig(save_file, dpi=150, bbox_inches='tight')
    plt.close()
    
    print(f"  âœ… å¯è§†åŒ–å¯¹æ¯”å›¾å·²ä¿å­˜: {save_file}")
    return save_file

def create_visualization_grid(model, dataset, device, save_path, num_samples=6):
    """åˆ›å»ºå¤šä¸ªæ ·æœ¬çš„å¯è§†åŒ–ç½‘æ ¼"""
    fig, axes = plt.subplots(4, num_samples, figsize=(num_samples * 4, 16))
    
    row_titles = ['åŸå§‹å›¾åƒ', 'çœŸå®æ ‡ç­¾', 'é¢„æµ‹ç»“æœ', 'é¢„æµ‹è¯¯å·®']
    
    for i in range(num_samples):
        if i >= len(dataset):
            break
            
        # è·å–æ•°æ®
        image_tensor, mask_true = dataset[i]
        
        # è½¬æ¢ä¸ºå¯æ˜¾ç¤ºæ ¼å¼
        image_np = image_tensor.permute(1, 2, 0).numpy()
        
        # é¢„æµ‹
        image_tensor_batch = image_tensor.unsqueeze(0).to(device)
        with torch.no_grad():
            outputs = model(image_tensor_batch)
            if isinstance(outputs, (list, tuple)):
                output = outputs[0]
            else:
                output = outputs
            
            pred = F.softmax(output, dim=1)
            pred = torch.argmax(pred, dim=1).squeeze().cpu().numpy()
        
        # è®¡ç®—å·®å¼‚
        diff = np.abs(mask_true.numpy().astype(float) - pred.astype(float))
        
        # ç»˜åˆ¶
        axes[0, i].imshow(image_np)
        axes[0, i].axis('off')
        if i == 0:
            axes[0, i].set_ylabel(row_titles[0], fontsize=12, fontweight='bold')
        
        axes[1, i].imshow(mask_true.numpy(), cmap='RdYlBu_r', vmin=0, vmax=1)
        axes[1, i].axis('off')
        if i == 0:
            axes[1, i].set_ylabel(row_titles[1], fontsize=12, fontweight='bold')
        
        axes[2, i].imshow(pred, cmap='RdYlBu_r', vmin=0, vmax=1)
        axes[2, i].axis('off')
        if i == 0:
            axes[2, i].set_ylabel(row_titles[2], fontsize=12, fontweight='bold')
        
        axes[3, i].imshow(diff, cmap='Reds', vmin=0, vmax=1)
        axes[3, i].axis('off')
        if i == 0:
            axes[3, i].set_ylabel(row_titles[3], fontsize=12, fontweight='bold')
        
        # è®¡ç®—å¹¶æ˜¾ç¤ºæŒ‡æ ‡
        metrics = calculate_metrics(mask_true.numpy(), pred)
        axes[3, i].set_title(f'mIoU: {metrics["mean_iou"]:.3f}', fontsize=10)
    
    plt.tight_layout()
    grid_file = os.path.join(save_path, 'comparison_grid.png')
    plt.savefig(grid_file, dpi=150, bbox_inches='tight')
    plt.close()
    
    print(f"  âœ… å¯¹æ¯”ç½‘æ ¼å›¾å·²ä¿å­˜: {grid_file}")
    return grid_file

def main():
    # é…ç½®
    model_path = 'weights/custom_finetune/best_model.pth'
    data_folder = 'data/custom'
    output_folder = 'custom_finetune_results'
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    print("ğŸ¨ ç”Ÿæˆè‡ªå®šä¹‰æ•°æ®é›†å¾®è°ƒæ¨¡å‹å¯è§†åŒ–æ•ˆæœå¯¹æ¯”")
    print("=" * 60)
    print(f"ğŸ“± ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_folder, exist_ok=True)
    
    # æ£€æŸ¥å¿…è¦æ–‡ä»¶
    if not os.path.exists(model_path):
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        return
    
    if not os.path.exists(data_folder):
        print(f"âŒ æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_folder}")
        return
    
    # åŠ è½½æ¨¡å‹
    model = load_model(model_path, device)
    
    # åŠ è½½æ•°æ®é›†
    print(f"ğŸ“‚ åŠ è½½æ•°æ®é›†: {data_folder}")
    try:
        dataset = CustomDataset(
            root=data_folder,
            split='val',
            mode='val',
            original_size=True
        )
        print(f"ğŸ“Š æ•°æ®é›†å¤§å°: {len(dataset)}")
    except Exception as e:
        print(f"âŒ åŠ è½½æ•°æ®é›†å¤±è´¥: {e}")
        return
    
    if len(dataset) == 0:
        print("âŒ æ•°æ®é›†ä¸ºç©º")
        return
    
    # ç”Ÿæˆå¯¹æ¯”ç½‘æ ¼å›¾
    print("\nğŸ“Š ç”Ÿæˆå¤šæ ·æœ¬å¯¹æ¯”ç½‘æ ¼...")
    try:
        num_samples = min(6, len(dataset))
        grid_file = create_visualization_grid(model, dataset, device, output_folder, num_samples)
    except Exception as e:
        print(f"âŒ ç”Ÿæˆç½‘æ ¼å›¾å¤±è´¥: {e}")
    
    # ç”Ÿæˆè¯¦ç»†çš„å•æ ·æœ¬å¯¹æ¯”å›¾
    print("\nğŸ” ç”Ÿæˆè¯¦ç»†å•æ ·æœ¬å¯¹æ¯”å›¾...")
    sample_indices = [0]
    if len(dataset) > 5:
        sample_indices.append(5)
    if len(dataset) > 10:
        sample_indices.append(10)
    
    for idx in sample_indices:
        if idx >= len(dataset):
            continue
            
        try:
            # è·å–æ•°æ®
            image_tensor, mask_true = dataset[idx]
            
            # è½¬æ¢å›¾åƒæ ¼å¼
            image_np = image_tensor.permute(1, 2, 0).numpy()
            
            # é¢„æµ‹
            image_tensor_batch = image_tensor.unsqueeze(0).to(device)
            with torch.no_grad():
                outputs = model(image_tensor_batch)
                if isinstance(outputs, (list, tuple)):
                    output = outputs[0]
                else:
                    output = outputs
                
                pred = F.softmax(output, dim=1)
                pred = torch.argmax(pred, dim=1).squeeze().cpu().numpy()
            
            # è®¡ç®—æŒ‡æ ‡
            metrics = calculate_metrics(mask_true.numpy(), pred)
            
            # ç”Ÿæˆå¯è§†åŒ–
            visualize_comparison(image_np, mask_true.numpy(), pred, 
                               output_folder, f"sample_{idx:02d}", metrics)
            
        except Exception as e:
            print(f"âŒ å¤„ç†æ ·æœ¬ {idx} å¤±è´¥: {e}")
    
    print("\nâœ… å¯è§†åŒ–ç”Ÿæˆå®Œæˆ!")
    print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {output_folder}")
    print("\nç”Ÿæˆçš„æ–‡ä»¶:")
    print(f"  - comparison_grid.png: å¤šæ ·æœ¬å¯¹æ¯”ç½‘æ ¼")
    for idx in sample_indices:
        if idx < len(dataset):
            print(f"  - sample_{idx:02d}_comparison.png: è¯¦ç»†å¯¹æ¯”å›¾")

if __name__ == '__main__':
    main()
