#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
è®­ç»ƒè¿‡ç¨‹å¯è§†åŒ–å’Œåˆ†æå·¥å…·
ç”¨äºç›‘æ§è®­ç»ƒè¿‡ç¨‹ã€åˆ†ææ€§èƒ½ã€ä¾¿äºè°ƒå‚
"""

import os
import json
import matplotlib.pyplot as plt
import numpy as np
from datetime import datetime
import torch
from collections import defaultdict

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

class TrainingMonitor:
    """è®­ç»ƒè¿‡ç¨‹ç›‘æ§å™¨"""
    
    def __init__(self, save_dir='./logs', experiment_name=None):
        self.save_dir = save_dir
        if experiment_name is None:
            experiment_name = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.experiment_name = experiment_name
        self.log_file = os.path.join(save_dir, f"{experiment_name}_training_log.json")
        
        # åˆ›å»ºä¿å­˜ç›®å½•
        os.makedirs(save_dir, exist_ok=True)
        
        # è®­ç»ƒæ•°æ®å­˜å‚¨
        self.data = {
            'train_loss': [],
            'val_loss': [],
            'val_miou': [],
            'val_pixacc': [],
            'learning_rates': [],
            'epoch_times': [],
            'config': {},
            'best_metrics': {},
            'timestamps': []
        }
        
        print(f"ğŸ“Š è®­ç»ƒç›‘æ§å™¨å·²å¯åŠ¨: {self.experiment_name}")
        print(f"ğŸ“ æ—¥å¿—ä¿å­˜åˆ°: {self.log_file}")

    def log_config(self, args):
        """è®°å½•è®­ç»ƒé…ç½®"""
        config_dict = vars(args) if hasattr(args, '__dict__') else args
        # è½¬æ¢deviceç­‰ä¸å¯åºåˆ—åŒ–çš„å¯¹è±¡
        serializable_config = {}
        for k, v in config_dict.items():
            if isinstance(v, torch.device):
                serializable_config[k] = str(v)
            else:
                serializable_config[k] = v
        
        self.data['config'] = serializable_config
        self.save_log()

    def log_epoch(self, epoch, train_loss, val_loss=None, val_miou=None, 
                  val_pixacc=None, learning_rate=None, epoch_time=None):
        """è®°å½•æ¯ä¸ªepochçš„æ•°æ®"""
        self.data['train_loss'].append(train_loss)
        if val_loss is not None:
            self.data['val_loss'].append(val_loss)
        if val_miou is not None:
            self.data['val_miou'].append(val_miou)
        if val_pixacc is not None:
            self.data['val_pixacc'].append(val_pixacc)
        if learning_rate is not None:
            self.data['learning_rates'].append(learning_rate)
        if epoch_time is not None:
            self.data['epoch_times'].append(epoch_time)
        
        self.data['timestamps'].append(datetime.now().isoformat())
        
        # æ›´æ–°æœ€ä½³æŒ‡æ ‡
        if val_miou is not None:
            if 'best_miou' not in self.data['best_metrics'] or val_miou > self.data['best_metrics']['best_miou']:
                self.data['best_metrics']['best_miou'] = val_miou
                self.data['best_metrics']['best_miou_epoch'] = epoch
        
        if val_pixacc is not None:
            if 'best_pixacc' not in self.data['best_metrics'] or val_pixacc > self.data['best_metrics']['best_pixacc']:
                self.data['best_metrics']['best_pixacc'] = val_pixacc
                self.data['best_metrics']['best_pixacc_epoch'] = epoch
        
        self.save_log()

    def save_log(self):
        """ä¿å­˜æ—¥å¿—åˆ°æ–‡ä»¶"""
        with open(self.log_file, 'w', encoding='utf-8') as f:
            json.dump(self.data, f, ensure_ascii=False, indent=2)

    def plot_training_curves(self, save_plot=True):
        """ç»˜åˆ¶è®­ç»ƒæ›²çº¿"""
        epochs = list(range(1, len(self.data['train_loss']) + 1))
        
        # åˆ›å»ºå­å›¾
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        fig.suptitle(f'è®­ç»ƒè¿‡ç¨‹åˆ†æ - {self.experiment_name}', fontsize=16, fontweight='bold')
        
        # 1. æŸå¤±æ›²çº¿
        ax1 = axes[0, 0]
        ax1.plot(epochs, self.data['train_loss'], 'b-', label='è®­ç»ƒæŸå¤±', linewidth=2)
        if self.data['val_loss']:
            val_epochs = list(range(1, len(self.data['val_loss']) + 1))
            ax1.plot(val_epochs, self.data['val_loss'], 'r-', label='éªŒè¯æŸå¤±', linewidth=2)
        ax1.set_xlabel('Epoch')
        ax1.set_ylabel('Loss')
        ax1.set_title('æŸå¤±æ›²çº¿')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # 2. mIoUæ›²çº¿
        ax2 = axes[0, 1]
        if self.data['val_miou']:
            val_epochs = list(range(1, len(self.data['val_miou']) + 1))
            ax2.plot(val_epochs, [x*100 for x in self.data['val_miou']], 'g-', 
                    label='éªŒè¯mIoU', linewidth=2, marker='o', markersize=4)
            if 'best_miou' in self.data['best_metrics']:
                best_epoch = self.data['best_metrics']['best_miou_epoch']
                best_miou = self.data['best_metrics']['best_miou'] * 100
                ax2.axhline(y=best_miou, color='g', linestyle='--', alpha=0.7, 
                           label=f'æœ€ä½³mIoU: {best_miou:.2f}%')
        ax2.set_xlabel('Epoch')
        ax2.set_ylabel('mIoU (%)')
        ax2.set_title('Mean IoUæ›²çº¿')
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        
        # 3. åƒç´ å‡†ç¡®ç‡æ›²çº¿
        ax3 = axes[1, 0]
        if self.data['val_pixacc']:
            val_epochs = list(range(1, len(self.data['val_pixacc']) + 1))
            ax3.plot(val_epochs, [x*100 for x in self.data['val_pixacc']], 'm-', 
                    label='åƒç´ å‡†ç¡®ç‡', linewidth=2, marker='s', markersize=4)
            if 'best_pixacc' in self.data['best_metrics']:
                best_pixacc = self.data['best_metrics']['best_pixacc'] * 100
                ax3.axhline(y=best_pixacc, color='m', linestyle='--', alpha=0.7,
                           label=f'æœ€ä½³PixAcc: {best_pixacc:.2f}%')
        ax3.set_xlabel('Epoch')
        ax3.set_ylabel('Pixel Accuracy (%)')
        ax3.set_title('åƒç´ å‡†ç¡®ç‡æ›²çº¿')
        ax3.legend()
        ax3.grid(True, alpha=0.3)
        
        # 4. å­¦ä¹ ç‡æ›²çº¿
        ax4 = axes[1, 1]
        if self.data['learning_rates']:
            lr_epochs = list(range(1, len(self.data['learning_rates']) + 1))
            ax4.semilogy(lr_epochs, self.data['learning_rates'], 'orange', 
                        label='å­¦ä¹ ç‡', linewidth=2)
        ax4.set_xlabel('Epoch')
        ax4.set_ylabel('Learning Rate (log scale)')
        ax4.set_title('å­¦ä¹ ç‡å˜åŒ–')
        ax4.legend()
        ax4.grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        if save_plot:
            plot_path = os.path.join(self.save_dir, f"{self.experiment_name}_training_curves.png")
            plt.savefig(plot_path, dpi=300, bbox_inches='tight')
            print(f"ğŸ“ˆ è®­ç»ƒæ›²çº¿å·²ä¿å­˜: {plot_path}")
        
        plt.show()
        return fig

    def generate_report(self):
        """ç”Ÿæˆè®­ç»ƒæŠ¥å‘Š"""
        if not self.data['train_loss']:
            print("âŒ æ²¡æœ‰è®­ç»ƒæ•°æ®å¯åˆ†æ")
            return
        
        report = []
        report.append("=" * 60)
        report.append(f"ğŸš— BDD100Kå¯é©¾é©¶åŒºåŸŸåˆ†å‰²è®­ç»ƒæŠ¥å‘Š")
        report.append(f"ğŸ“… å®éªŒåç§°: {self.experiment_name}")
        report.append(f"ğŸ“… ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append("=" * 60)
        
        # è®­ç»ƒé…ç½®
        if self.data['config']:
            report.append("\nğŸ“‹ è®­ç»ƒé…ç½®:")
            config = self.data['config']
            report.append(f"   æ•°æ®é›†: {config.get('dataset', 'N/A')}")
            report.append(f"   æ¨¡å‹: {config.get('model', 'N/A')}")
            report.append(f"   æ ‡ç­¾ç±»å‹: {config.get('label_type', 'N/A')}")
            report.append(f"   æ‰¹æ¬¡å¤§å°: {config.get('batch_size', 'N/A')}")
            report.append(f"   å­¦ä¹ ç‡: {config.get('lr', 'N/A')}")
            report.append(f"   è®­ç»ƒè½®æ•°: {config.get('epochs', 'N/A')}")
            report.append(f"   æŸå¤±å‡½æ•°: {config.get('loss_type', 'N/A')}")
            report.append(f"   æ•°æ®é‡‡æ ·: {config.get('sample_ratio', 'N/A')}")
            report.append(f"   ä¿æŒåŸå°ºå¯¸: {config.get('keep_original_size', False)}")
            report.append(f"   å¤šå°ºåº¦è®­ç»ƒ: {config.get('multi_scale', False)}")
        
        # è®­ç»ƒç»“æœ
        report.append(f"\nğŸ“Š è®­ç»ƒç»“æœ:")
        report.append(f"   æ€»è®­ç»ƒè½®æ•°: {len(self.data['train_loss'])}")
        report.append(f"   åˆå§‹è®­ç»ƒæŸå¤±: {self.data['train_loss'][0]:.4f}")
        report.append(f"   æœ€ç»ˆè®­ç»ƒæŸå¤±: {self.data['train_loss'][-1]:.4f}")
        report.append(f"   æœ€ä½è®­ç»ƒæŸå¤±: {min(self.data['train_loss']):.4f}")
        
        if self.data['val_miou']:
            report.append(f"   æœ€ç»ˆéªŒè¯mIoU: {self.data['val_miou'][-1]*100:.2f}%")
            report.append(f"   æœ€ä½³éªŒè¯mIoU: {max(self.data['val_miou'])*100:.2f}%")
        
        if self.data['val_pixacc']:
            report.append(f"   æœ€ç»ˆåƒç´ å‡†ç¡®ç‡: {self.data['val_pixacc'][-1]*100:.2f}%")
            report.append(f"   æœ€ä½³åƒç´ å‡†ç¡®ç‡: {max(self.data['val_pixacc'])*100:.2f}%")
        
        # è®­ç»ƒæ—¶é—´åˆ†æ
        if self.data['epoch_times']:
            total_time = sum(self.data['epoch_times'])
            avg_time = np.mean(self.data['epoch_times'])
            report.append(f"\nâ±ï¸  è®­ç»ƒæ—¶é—´åˆ†æ:")
            report.append(f"   æ€»è®­ç»ƒæ—¶é—´: {total_time/3600:.2f} å°æ—¶")
            report.append(f"   å¹³å‡æ¯è½®æ—¶é—´: {avg_time:.1f} ç§’")
            report.append(f"   æœ€å¿«ä¸€è½®: {min(self.data['epoch_times']):.1f} ç§’")
            report.append(f"   æœ€æ…¢ä¸€è½®: {max(self.data['epoch_times']):.1f} ç§’")
        
        # æ”¶æ•›åˆ†æ
        if len(self.data['train_loss']) >= 5:
            recent_losses = self.data['train_loss'][-5:]
            loss_trend = (recent_losses[-1] - recent_losses[0]) / len(recent_losses)
            report.append(f"\nğŸ“ˆ æ”¶æ•›åˆ†æ (æœ€è¿‘5è½®):")
            report.append(f"   æŸå¤±è¶‹åŠ¿: {loss_trend:.6f} æ¯è½®")
            if abs(loss_trend) < 0.001:
                report.append("   âœ… æ¨¡å‹å·²æ”¶æ•›")
            elif loss_trend < 0:
                report.append("   ğŸ“‰ æ¨¡å‹ä»åœ¨æ”¹å–„")
            else:
                report.append("   âš ï¸  æ¨¡å‹å¯èƒ½è¿‡æ‹Ÿåˆ")
        
        # è°ƒå‚å»ºè®®
        report.append(f"\nğŸ’¡ è°ƒå‚å»ºè®®:")
        if self.data['val_miou']:
            final_miou = self.data['val_miou'][-1] * 100
            if final_miou < 50:
                report.append("   ğŸ“Œ mIoUè¾ƒä½ï¼Œå»ºè®®:")
                report.append("      - å¢åŠ è®­ç»ƒè½®æ•°")
                report.append("      - è°ƒæ•´å­¦ä¹ ç‡")
                report.append("      - æ£€æŸ¥æ•°æ®è´¨é‡")
            elif final_miou < 70:
                report.append("   ğŸ“Œ mIoUä¸­ç­‰ï¼Œå»ºè®®:")
                report.append("      - å¾®è°ƒå­¦ä¹ ç‡è°ƒåº¦")
                report.append("      - å°è¯•ä¸åŒçš„æ•°æ®å¢å¼º")
                report.append("      - å¢åŠ è®­ç»ƒæ•°æ®")
            else:
                report.append("   âœ… mIoUè¡¨ç°è‰¯å¥½ï¼")
                report.append("      - å¯ä»¥å°è¯•å¢åŠ æ•°æ®é‡è¿›ä¸€æ­¥æå‡")
                report.append("      - å¯ä»¥è¿›è¡Œå¤šå°ºåº¦è®­ç»ƒ")
        
        report_text = "\n".join(report)
        print(report_text)
        
        # ä¿å­˜æŠ¥å‘Š
        report_path = os.path.join(self.save_dir, f"{self.experiment_name}_report.txt")
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report_text)
        print(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: {report_path}")
        
        return report_text

def load_and_analyze_training(log_file):
    """åŠ è½½å¹¶åˆ†æå·²æœ‰çš„è®­ç»ƒæ—¥å¿—"""
    if not os.path.exists(log_file):
        print(f"âŒ æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨: {log_file}")
        return None
    
    with open(log_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    # åˆ›å»ºç›‘æ§å™¨å®ä¾‹
    experiment_name = os.path.splitext(os.path.basename(log_file))[0].replace('_training_log', '')
    monitor = TrainingMonitor(save_dir=os.path.dirname(log_file), experiment_name=experiment_name)
    monitor.data = data
    
    return monitor

if __name__ == '__main__':
    # ç¤ºä¾‹ï¼šåˆ†æç°æœ‰çš„è®­ç»ƒæ—¥å¿—
    print("ğŸ” è®­ç»ƒåˆ†æå·¥å…·")
    print("è¯·å°†æ­¤è„šæœ¬é›†æˆåˆ°train.pyä¸­ï¼Œæˆ–æä¾›æ—¥å¿—æ–‡ä»¶è·¯å¾„è¿›è¡Œåˆ†æ")
    
    # æœç´¢ç°æœ‰çš„æ—¥å¿—æ–‡ä»¶
    log_dir = './logs'
    if os.path.exists(log_dir):
        log_files = [f for f in os.listdir(log_dir) if f.endswith('_training_log.json')]
        if log_files:
            print(f"\næ‰¾åˆ° {len(log_files)} ä¸ªè®­ç»ƒæ—¥å¿—:")
            for i, log_file in enumerate(log_files, 1):
                print(f"  {i}. {log_file}")
            
            # å¯ä»¥é€‰æ‹©åˆ†æç‰¹å®šçš„æ—¥å¿—æ–‡ä»¶
            # latest_log = os.path.join(log_dir, log_files[-1])
            # monitor = load_and_analyze_training(latest_log)
            # if monitor:
            #     monitor.plot_training_curves()
            #     monitor.generate_report()
    else:
        print("æ²¡æœ‰æ‰¾åˆ°æ—¥å¿—ç›®å½•ï¼Œè¯·å…ˆè¿›è¡Œè®­ç»ƒ")
