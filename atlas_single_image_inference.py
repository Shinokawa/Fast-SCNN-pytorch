#!/usr/bin/env python3
"""
Atlas NPU å•å¼ å›¾ç‰‡è½¦é“çº¿åˆ†å‰²æ¨ç†è„šæœ¬

åŠŸèƒ½ç‰¹æ€§ï¼š
- æ”¯æŒAtlas NPUçš„.omæ¨¡å‹æ¨ç†
- è¾“å…¥/è¾“å‡ºå°ºå¯¸ï¼š640Ã—360ï¼ˆä¸æ‘„åƒå¤´è„šæœ¬å®Œå…¨ä¸€è‡´ï¼‰
- æç®€é¢„å¤„ç†ï¼šBGRâ†’RGB + Float16 + CHWï¼Œæ— resize
- æç®€åå¤„ç†ï¼šç›´æ¥argmax + å¯è§†åŒ–
- æ”¯æŒFP16è¾“å…¥ï¼Œæ€§èƒ½æœ€ä¼˜
- å¯è¾“å‡ºåˆ†å‰²æ©ç æˆ–å¯è§†åŒ–ç»“æœ

ä½¿ç”¨æ–¹æ³•ï¼š
python atlas_single_image_inference.py --input image.jpg --output result.jpg
python atlas_single_image_inference.py --input image.jpg --output result.jpg --save_mask mask.png
python atlas_single_image_inference.py --input image.jpg --output result.jpg --device 1

ä½œè€…ï¼šåŸºäºlane_dashboard_e2e.pyæ¨ç†æµç¨‹æ”¹ç¼–
"""

import os
import sys
import cv2
import time
import numpy as np
import argparse
from pathlib import Path

# å¯¼å…¥Atlasæ¨ç†æ¥å£
try:
    from ais_bench.infer.interface import InferSession
except ImportError:
    print("âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ°ais_benchåº“ï¼Œè¯·ç¡®ä¿å·²æ­£ç¡®å®‰è£…Atlaså¼€å‘ç¯å¢ƒ")
    print("å®‰è£…å‘½ä»¤: pip install ais_bench")
    sys.exit(1)

# ---------------------------------------------------------------------------------
# --- ğŸš€ğŸš€ğŸš€ å®Œç¾åŒ¹é…çš„é¢„å¤„ç† (640Ã—360 = 640Ã—360) ğŸš€ğŸš€ğŸš€ ---
# ---------------------------------------------------------------------------------

def preprocess_matched_resolution(img_bgr, target_width=640, target_height=360, dtype=np.float16):
    """
    å›¾ç‰‡é¢„å¤„ç†ï¼Œä¸lane_dashboard_e2e.pyå®Œå…¨ä¸€è‡´
    
    è¾“å…¥ï¼šBGRå›¾åƒ (ä»»æ„å°ºå¯¸)
    è¾“å‡ºï¼šFloat16 NCHWå¼ é‡ (1, 3, 360, 640)
    
    å¤„ç†æµç¨‹ï¼š
    1. å¦‚æœè¾“å…¥å°ºå¯¸ä¸æ˜¯640Ã—360ï¼Œå…ˆresizeåˆ°640Ã—360
    2. BGR â†’ RGB
    3. uint8 â†’ float16 (ä¿æŒ[0-255]èŒƒå›´)
    4. HWC â†’ CHWï¼Œæ·»åŠ batchç»´åº¦
    """
    # 1. è°ƒæ•´å°ºå¯¸åˆ°æ¨¡å‹è¾“å…¥è¦æ±‚
    height, width = img_bgr.shape[:2]
    if width != target_width or height != target_height:
        print(f"ğŸ“ Resize: {width}Ã—{height} â†’ {target_width}Ã—{target_height}")
        img_bgr = cv2.resize(img_bgr, (target_width, target_height), interpolation=cv2.INTER_LINEAR)
    else:
        print(f"ğŸ¯ å®Œç¾åŒ¹é…: {width}Ã—{height} = {target_width}Ã—{target_height}ï¼Œæ— éœ€resize!")
    
    # 2. è½¬æ¢é¢œè‰²é€šé“ (BGR â†’ RGB)
    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)
    
    # 3. è½¬æ¢æ•°æ®ç±»å‹ (uint8 â†’ float16ï¼Œä¿æŒ[0-255]èŒƒå›´)
    img_typed = img_rgb.astype(dtype)
    
    # 4. è½¬æ¢ä¸ºCHWæ ¼å¼å¹¶æ·»åŠ batchç»´åº¦ (H,W,C) â†’ (1,C,H,W)
    img_transposed = np.transpose(img_typed, (2, 0, 1))
    return np.ascontiguousarray(img_transposed[np.newaxis, :, :, :])

# ---------------------------------------------------------------------------------
# --- ğŸš€ğŸš€ğŸš€ æç®€åå¤„ç† (å°ºå¯¸å®Œç¾åŒ¹é…) ğŸš€ğŸš€ğŸš€ ---
# ---------------------------------------------------------------------------------

def postprocess_matched_resolution(output_tensor, original_width, original_height):
    """
    åå¤„ç†ï¼Œä¸lane_dashboard_e2e.pyå®Œå…¨ä¸€è‡´
    
    è¾“å…¥ï¼šæ¨¡å‹è¾“å‡ºå¼ é‡ (1, num_classes, 360, 640)
    è¾“å‡ºï¼šåˆ†å‰²æ©ç  (original_height, original_width)
    
    å¤„ç†æµç¨‹ï¼š
    1. Argmaxè·å–åˆ†å‰²æ©ç 
    2. è½¬æ¢ä¸ºå¯è§†åŒ–æ ¼å¼
    3. å¦‚éœ€è¦ï¼Œresizeå›åŸå§‹å°ºå¯¸
    """
    # 1. Argmaxè·å–åˆ†å‰²æ©ç  (1, num_classes, H, W) â†’ (H, W)
    pred_mask = np.argmax(output_tensor, axis=1).squeeze()
    
    # 2. è½¬æ¢ä¸ºå¯è§†åŒ–æ ¼å¼ (0/1 â†’ 0/255)
    vis_mask = (pred_mask * 255).astype(np.uint8)
    
    # 3. å¦‚æœéœ€è¦ï¼Œresizeå›åŸå§‹å°ºå¯¸
    model_height, model_width = vis_mask.shape
    if original_width != model_width or original_height != model_height:
        print(f"ğŸ“ Resize back: {model_width}Ã—{model_height} â†’ {original_width}Ã—{original_height}")
        vis_mask = cv2.resize(vis_mask, (original_width, original_height), interpolation=cv2.INTER_NEAREST)
    else:
        print(f"ğŸ¯ è¾“å‡ºå°ºå¯¸åŒ¹é…: {model_width}Ã—{model_height} = {original_width}Ã—{original_height}")
    
    return vis_mask

# ---------------------------------------------------------------------------------
# --- ğŸ¨ å¯è§†åŒ–ç”Ÿæˆ ---
# ---------------------------------------------------------------------------------

def create_visualization(original_img, mask, alpha=0.5):
    """
    åˆ›å»ºè½¦é“çº¿åˆ†å‰²å¯è§†åŒ–å›¾åƒ
    
    å‚æ•°ï¼š
        original_img: åŸå§‹BGRå›¾åƒ
        mask: åˆ†å‰²æ©ç  (0/255)
        alpha: é€æ˜åº¦
    
    è¿”å›ï¼š
        å¯è§†åŒ–å›¾åƒ (BGRæ ¼å¼)
    """
    # åˆ›å»ºç»¿è‰²è¦†ç›–å±‚
    green_overlay = np.zeros_like(original_img, dtype=np.uint8)
    green_overlay[mask > 0] = [0, 255, 0]  # BGRæ ¼å¼çš„ç»¿è‰²
    
    # èåˆåŸå›¾å’Œè¦†ç›–å±‚
    vis_img = cv2.addWeighted(original_img, 1.0, green_overlay, alpha, 0)
    
    return vis_img

# ---------------------------------------------------------------------------------
# --- ğŸ“Š æ€§èƒ½åˆ†æ ---
# ---------------------------------------------------------------------------------

def print_performance_analysis(times_dict, input_shape, model_path):
    """æ‰“å°è¯¦ç»†çš„æ€§èƒ½åˆ†ææŠ¥å‘Š"""
    total_time = sum(times_dict.values())
    
    print("\n" + "="*60)
    print("ğŸš€ Atlas NPU å•å¼ å›¾ç‰‡æ¨ç†æ€§èƒ½åˆ†æ")
    print("="*60)
    print(f"ğŸ§  æ¨¡å‹: {Path(model_path).name}")
    print(f"ğŸ“ è¾“å…¥å°ºå¯¸: {input_shape[3]}Ã—{input_shape[2]} (WÃ—H)")
    print(f"ğŸ¯ æ•°æ®ç±»å‹: {str(input_shape).split('.')[-1].upper()}")
    print("-"*60)
    
    for stage, time_ms in times_dict.items():
        percentage = (time_ms / total_time) * 100
        print(f"â±ï¸  {stage:12}: {time_ms:6.1f}ms ({percentage:5.1f}%)")
    
    print("-"*60)
    print(f"ğŸ æ€»è€—æ—¶: {total_time:.1f}ms")
    print(f"âš¡ ç†è®ºFPS: {1000/total_time:.1f}")
    print("="*60)

# ---------------------------------------------------------------------------------
# --- ğŸ“± ä¸»æ¨ç†å‡½æ•° ---
# ---------------------------------------------------------------------------------

def inference_single_image(image_path, model_path, device_id=0, save_visualization=True, save_mask=False):
    """
    å¯¹å•å¼ å›¾ç‰‡è¿›è¡Œè½¦é“çº¿åˆ†å‰²æ¨ç†
    
    å‚æ•°ï¼š
        image_path: è¾“å…¥å›¾ç‰‡è·¯å¾„
        model_path: Atlas .omæ¨¡å‹è·¯å¾„
        device_id: NPUè®¾å¤‡ID
        save_visualization: æ˜¯å¦ä¿å­˜å¯è§†åŒ–ç»“æœ
        save_mask: æ˜¯å¦ä¿å­˜åˆ†å‰²æ©ç 
    
    è¿”å›ï¼š
        dict: åŒ…å«ç»“æœè·¯å¾„å’Œæ€§èƒ½æ•°æ®
    """
    # éªŒè¯è¾“å…¥æ–‡ä»¶
    if not os.path.exists(image_path):
        raise FileNotFoundError(f"è¾“å…¥å›¾ç‰‡ä¸å­˜åœ¨: {image_path}")
    
    if not os.path.exists(model_path):
        raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
    
    print(f"ğŸ–¼ï¸  åŠ è½½å›¾ç‰‡: {image_path}")
    
    # 1. åŠ è½½å›¾ç‰‡
    load_start = time.time()
    img_bgr = cv2.imread(image_path)
    if img_bgr is None:
        raise ValueError(f"æ— æ³•è¯»å–å›¾ç‰‡: {image_path}")
    
    original_height, original_width = img_bgr.shape[:2]
    load_time = (time.time() - load_start) * 1000
    
    print(f"ğŸ“ åŸå§‹å°ºå¯¸: {original_width}Ã—{original_height}")
    
    # 2. åŠ è½½æ¨¡å‹
    print(f"ğŸ§  åŠ è½½æ¨¡å‹: {model_path}")
    model_start = time.time()
    model = InferSession(device_id, model_path)
    model_load_time = (time.time() - model_start) * 1000
    print(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆ ({model_load_time:.1f}ms)")
    
    # 3. é¢„å¤„ç†
    print("ğŸ”„ å¼€å§‹é¢„å¤„ç†...")
    preprocess_start = time.time()
    input_data = preprocess_matched_resolution(img_bgr, dtype=np.float16)
    preprocess_time = (time.time() - preprocess_start) * 1000
    
    print(f"ğŸ“Š è¾“å…¥å¼ é‡å½¢çŠ¶: {input_data.shape}")
    print(f"ğŸ“Š æ•°æ®ç±»å‹: {input_data.dtype}")
    
    # 4. NPUæ¨ç†
    print("ğŸš€ å¼€å§‹NPUæ¨ç†...")
    inference_start = time.time()
    outputs = model.infer([input_data])
    inference_time = (time.time() - inference_start) * 1000
    
    print(f"ğŸ“Š è¾“å‡ºå¼ é‡å½¢çŠ¶: {outputs[0].shape}")
    
    # 5. åå¤„ç†
    print("ğŸ”„ å¼€å§‹åå¤„ç†...")
    postprocess_start = time.time()
    lane_mask = postprocess_matched_resolution(outputs[0], original_width, original_height)
    postprocess_time = (time.time() - postprocess_start) * 1000
    
    # 6. ä¿å­˜ç»“æœ
    save_start = time.time()
    results = {}
    
    if save_mask:
        mask_path = image_path.replace('.', '_mask.')
        cv2.imwrite(mask_path, lane_mask)
        results['mask_path'] = mask_path
        print(f"ğŸ’¾ åˆ†å‰²æ©ç å·²ä¿å­˜: {mask_path}")
    
    if save_visualization:
        vis_img = create_visualization(img_bgr, lane_mask)
        vis_path = image_path.replace('.', '_result.')
        cv2.imwrite(vis_path, vis_img)
        results['visualization_path'] = vis_path
        print(f"ğŸ’¾ å¯è§†åŒ–ç»“æœå·²ä¿å­˜: {vis_path}")
    
    save_time = (time.time() - save_start) * 1000
    
    # 7. æ€§èƒ½åˆ†æ
    times_dict = {
        "å›¾ç‰‡åŠ è½½": load_time,
        "æ¨¡å‹åŠ è½½": model_load_time,
        "CPUé¢„å¤„ç†": preprocess_time,
        "NPUæ¨ç†": inference_time,
        "CPUåå¤„ç†": postprocess_time,
        "ç»“æœä¿å­˜": save_time
    }
    
    print_performance_analysis(times_dict, input_data.shape, model_path)
    
    # 8. ç»Ÿè®¡è½¦é“çº¿åƒç´ 
    lane_pixels = np.sum(lane_mask > 0)
    total_pixels = lane_mask.shape[0] * lane_mask.shape[1]
    lane_ratio = (lane_pixels / total_pixels) * 100
    
    print(f"\nğŸ“ˆ æ£€æµ‹ç»“æœç»Ÿè®¡:")
    print(f"ğŸ›£ï¸  è½¦é“çº¿åƒç´ : {lane_pixels:,} / {total_pixels:,} ({lane_ratio:.2f}%)")
    
    results.update({
        'lane_pixels': lane_pixels,
        'total_pixels': total_pixels,
        'lane_ratio': lane_ratio,
        'performance': times_dict
    })
    
    return results

# ---------------------------------------------------------------------------------
# --- ğŸ“± å‘½ä»¤è¡Œæ¥å£ ---
# ---------------------------------------------------------------------------------

def main():
    parser = argparse.ArgumentParser(description="Atlas NPUå•å¼ å›¾ç‰‡è½¦é“çº¿åˆ†å‰²æ¨ç†")
    parser.add_argument("--input", "-i", required=True, help="è¾“å…¥å›¾ç‰‡è·¯å¾„")
    parser.add_argument("--output", "-o", help="è¾“å‡ºå¯è§†åŒ–å›¾ç‰‡è·¯å¾„ï¼ˆå¯é€‰ï¼‰")
    parser.add_argument("--save_mask", help="ä¿å­˜åˆ†å‰²æ©ç è·¯å¾„ï¼ˆå¯é€‰ï¼‰")
    parser.add_argument("--model", "-m", 
                       default="./weights/fast_scnn_custom_e2e_360x640_fp16_fixed_simp.om",
                       help="Atlasæ¨¡å‹(.om)è·¯å¾„")
    parser.add_argument("--device", "-d", type=int, default=0, help="NPUè®¾å¤‡ID")
    parser.add_argument("--no_vis", action="store_true", help="ä¸ä¿å­˜å¯è§†åŒ–ç»“æœï¼Œä»…æ¨ç†")
    
    args = parser.parse_args()
    
    try:
        print("ğŸš€ Atlas NPU å•å¼ å›¾ç‰‡è½¦é“çº¿åˆ†å‰²æ¨ç†å·¥å…·")
        print("=" * 50)
        
        # è‡ªåŠ¨ç¡®å®šè¾“å‡ºè·¯å¾„
        save_visualization = not args.no_vis
        save_mask = bool(args.save_mask)
        
        if args.output and save_visualization:
            # å¦‚æœæŒ‡å®šäº†è¾“å‡ºè·¯å¾„ï¼Œé‡å‘½ååŸå›¾ä»¥ä½¿ç”¨æŒ‡å®šè·¯å¾„
            import shutil
            temp_input = args.input + ".temp"
            shutil.copy2(args.input, temp_input)
            target_input = args.output.replace('_result.', '.')
            shutil.copy2(args.input, target_input)
            args.input = target_input
        
        # æ‰§è¡Œæ¨ç†
        results = inference_single_image(
            image_path=args.input,
            model_path=args.model,
            device_id=args.device,
            save_visualization=save_visualization,
            save_mask=save_mask
        )
        
        # å¦‚æœæŒ‡å®šäº†æ©ç ä¿å­˜è·¯å¾„ï¼Œé‡å‘½å
        if args.save_mask and 'mask_path' in results:
            import shutil
            shutil.move(results['mask_path'], args.save_mask)
            results['mask_path'] = args.save_mask
            print(f"ğŸ’¾ åˆ†å‰²æ©ç å·²ä¿å­˜åˆ°æŒ‡å®šè·¯å¾„: {args.save_mask}")
        
        # å¦‚æœæŒ‡å®šäº†è¾“å‡ºè·¯å¾„ï¼Œé‡å‘½åå¯è§†åŒ–ç»“æœ
        if args.output and 'visualization_path' in results:
            import shutil
            shutil.move(results['visualization_path'], args.output)
            results['visualization_path'] = args.output
            print(f"ğŸ’¾ å¯è§†åŒ–ç»“æœå·²ä¿å­˜åˆ°æŒ‡å®šè·¯å¾„: {args.output}")
        
        print("\nâœ… æ¨ç†å®Œæˆï¼")
        
        if 'visualization_path' in results:
            print(f"ğŸ¨ å¯è§†åŒ–ç»“æœ: {results['visualization_path']}")
        if 'mask_path' in results:
            print(f"ğŸ­ åˆ†å‰²æ©ç : {results['mask_path']}")
            
    except Exception as e:
        print(f"âŒ æ¨ç†å¤±è´¥: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
