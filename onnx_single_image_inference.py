#!/usr/bin/env python3
"""
æœ¬åœ°ONNXå•å¼ å›¾ç‰‡è½¦é“çº¿åˆ†å‰²æ¨ç†è„šæœ¬

åŠŸèƒ½ç‰¹æ€§ï¼š
- ä½¿ç”¨ONNX Runtimeè¿›è¡Œæ¨ç† (CPU/GPU)
- è¾“å…¥/è¾“å‡ºå°ºå¯¸ï¼š640Ã—360ï¼ˆä¸Atlasè„šæœ¬å®Œå…¨ä¸€è‡´ï¼‰
- æç®€é¢„å¤„ç†ï¼šBGRâ†’RGB + Float16 + CHWï¼Œæ— resize
- æç®€åå¤„ç†ï¼šç›´æ¥argmax + å¯è§†åŒ–
- æ”¯æŒFP16è¾“å…¥ï¼Œä¸Atlas NPUæ¨ç†æµç¨‹å®Œå…¨ä¸€è‡´
- å¯è¾“å‡ºåˆ†å‰²æ©ç æˆ–å¯è§†åŒ–ç»“æœ

ä½¿ç”¨æ–¹æ³•ï¼š
python onnx_single_image_inference.py --input image.jpg --output result.jpg
python onnx_single_image_inference.py --input image.jpg --output result.jpg --save_mask mask.png
python onnx_single_image_inference.py --input image.jpg --output result.jpg --provider CUDAExecutionProvider

ä½œè€…ï¼šåŸºäºatlas_single_image_inference.pyå’Œlane_dashboard_e2e.pyæ”¹ç¼–
"""

import os
import sys
import cv2
import time
import numpy as np
import argparse
from pathlib import Path

# å¯¼å…¥ONNX Runtime
try:
    import onnxruntime as ort
except ImportError:
    print("âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ°onnxruntimeåº“ï¼Œè¯·å®‰è£…")
    print("CPUç‰ˆæœ¬: pip install onnxruntime")
    print("GPUç‰ˆæœ¬: pip install onnxruntime-gpu")
    sys.exit(1)

# ---------------------------------------------------------------------------------
# --- ğŸš€ğŸš€ğŸš€ å®Œç¾åŒ¹é…çš„é¢„å¤„ç† (640Ã—360 = 640Ã—360ï¼Œä¸Atlaså®Œå…¨ä¸€è‡´) ğŸš€ğŸš€ğŸš€ ---
# ---------------------------------------------------------------------------------

def preprocess_matched_resolution(img_bgr, target_width=640, target_height=360, dtype=np.float32):
    """
    å›¾ç‰‡é¢„å¤„ç†ï¼Œä¸atlas_single_image_inference.pyå’Œlane_dashboard_e2e.pyå®Œå…¨ä¸€è‡´
    
    è¾“å…¥ï¼šBGRå›¾åƒ (ä»»æ„å°ºå¯¸)
    è¾“å‡ºï¼šFloat32/Float16 NCHWå¼ é‡ (1, 3, 360, 640)
    
    å¤„ç†æµç¨‹ï¼š
    1. å¦‚æœè¾“å…¥å°ºå¯¸ä¸æ˜¯640Ã—360ï¼Œå…ˆresizeåˆ°640Ã—360
    2. BGR â†’ RGB
    3. uint8 â†’ float32/float16 (ä¿æŒ[0-255]èŒƒå›´)
    4. HWC â†’ CHWï¼Œæ·»åŠ batchç»´åº¦
    """
    # 1. è°ƒæ•´å°ºå¯¸åˆ°æ¨¡å‹è¾“å…¥è¦æ±‚
    height, width = img_bgr.shape[:2]
    if width != target_width or height != target_height:
        print(f"ğŸ“ Resize: {width}Ã—{height} â†’ {target_width}Ã—{target_height}")
        img_bgr = cv2.resize(img_bgr, (target_width, target_height), interpolation=cv2.INTER_LINEAR)
    else:
        print(f"ğŸ¯ å®Œç¾åŒ¹é…: {width}Ã—{height} = {target_width}Ã—{target_height}ï¼Œæ— éœ€resize!")
    
    # 2. è½¬æ¢é¢œè‰²é€šé“ (BGR â†’ RGB)
    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)
    
    # 3. è½¬æ¢æ•°æ®ç±»å‹ (uint8 â†’ float16ï¼Œä¿æŒ[0-255]èŒƒå›´)
    img_typed = img_rgb.astype(dtype)
    
    # 4. è½¬æ¢ä¸ºCHWæ ¼å¼å¹¶æ·»åŠ batchç»´åº¦ (H,W,C) â†’ (1,C,H,W)
    img_transposed = np.transpose(img_typed, (2, 0, 1))
    return np.ascontiguousarray(img_transposed[np.newaxis, :, :, :])

# ---------------------------------------------------------------------------------
# --- ğŸš€ğŸš€ğŸš€ æç®€åå¤„ç† (å°ºå¯¸å®Œç¾åŒ¹é…ï¼Œä¸Atlaså®Œå…¨ä¸€è‡´) ğŸš€ğŸš€ğŸš€ ---
# ---------------------------------------------------------------------------------

def postprocess_matched_resolution(output_tensor, original_width, original_height):
    """
    åå¤„ç†ï¼Œä¸atlas_single_image_inference.pyå’Œlane_dashboard_e2e.pyå®Œå…¨ä¸€è‡´
    
    è¾“å…¥ï¼šæ¨¡å‹è¾“å‡ºå¼ é‡ (1, num_classes, 360, 640)
    è¾“å‡ºï¼šåˆ†å‰²æ©ç  (original_height, original_width)
    
    å¤„ç†æµç¨‹ï¼š
    1. Argmaxè·å–åˆ†å‰²æ©ç 
    2. è½¬æ¢ä¸ºå¯è§†åŒ–æ ¼å¼
    3. å¦‚éœ€è¦ï¼Œresizeå›åŸå§‹å°ºå¯¸
    """
    # 1. Argmaxè·å–åˆ†å‰²æ©ç  (1, num_classes, H, W) â†’ (H, W)
    pred_mask = np.argmax(output_tensor, axis=1).squeeze()
    
    # 2. è½¬æ¢ä¸ºå¯è§†åŒ–æ ¼å¼ (0/1 â†’ 0/255)
    vis_mask = (pred_mask * 255).astype(np.uint8)
    
    # 3. å¦‚æœéœ€è¦ï¼Œresizeå›åŸå§‹å°ºå¯¸
    model_height, model_width = vis_mask.shape
    if original_width != model_width or original_height != model_height:
        print(f"ğŸ“ Resize back: {model_width}Ã—{model_height} â†’ {original_width}Ã—{original_height}")
        vis_mask = cv2.resize(vis_mask, (original_width, original_height), interpolation=cv2.INTER_NEAREST)
    else:
        print(f"ğŸ¯ è¾“å‡ºå°ºå¯¸åŒ¹é…: {model_width}Ã—{model_height} = {original_width}Ã—{original_height}")
    
    return vis_mask

# ---------------------------------------------------------------------------------
# --- ğŸ¨ å¯è§†åŒ–ç”Ÿæˆ (ä¸Atlaså®Œå…¨ä¸€è‡´) ---
# ---------------------------------------------------------------------------------

def create_visualization(original_img, mask, alpha=0.5):
    """
    åˆ›å»ºè½¦é“çº¿åˆ†å‰²å¯è§†åŒ–å›¾åƒï¼Œä¸atlas_single_image_inference.pyå®Œå…¨ä¸€è‡´
    
    å‚æ•°ï¼š
        original_img: åŸå§‹BGRå›¾åƒ
        mask: åˆ†å‰²æ©ç  (0/255)
        alpha: é€æ˜åº¦
    
    è¿”å›ï¼š
        å¯è§†åŒ–å›¾åƒ (BGRæ ¼å¼)
    """
    # åˆ›å»ºç»¿è‰²è¦†ç›–å±‚
    green_overlay = np.zeros_like(original_img, dtype=np.uint8)
    green_overlay[mask > 0] = [0, 255, 0]  # BGRæ ¼å¼çš„ç»¿è‰²
    
    # èåˆåŸå›¾å’Œè¦†ç›–å±‚
    vis_img = cv2.addWeighted(original_img, 1.0, green_overlay, alpha, 0)
    
    return vis_img

# ---------------------------------------------------------------------------------
# --- ğŸ§  ONNX Runtimeæ¨ç†ä¼šè¯ ---
# ---------------------------------------------------------------------------------

class ONNXInferSession:
    """ONNX Runtimeæ¨ç†ä¼šè¯ï¼Œæ¨¡æ‹ŸAtlas InferSessionæ¥å£"""
    
    def __init__(self, model_path, provider='CPUExecutionProvider'):
        """
        åˆå§‹åŒ–ONNXæ¨ç†ä¼šè¯
        
        å‚æ•°ï¼š
            model_path: ONNXæ¨¡å‹è·¯å¾„
            provider: æ‰§è¡Œæä¾›è€… ('CPUExecutionProvider', 'CUDAExecutionProvider')
        """
        self.model_path = model_path
        self.provider = provider
        
        # è®¾ç½®æ‰§è¡Œæä¾›è€…
        available_providers = ort.get_available_providers()
        if provider not in available_providers:
            print(f"âš ï¸ è­¦å‘Š: {provider} ä¸å¯ç”¨ï¼Œå¯ç”¨æä¾›è€…: {available_providers}")
            provider = 'CPUExecutionProvider'
        
        print(f"ğŸ§  ä½¿ç”¨æ‰§è¡Œæä¾›è€…: {provider}")
        
        # åˆ›å»ºæ¨ç†ä¼šè¯
        self.session = ort.InferenceSession(model_path, providers=[provider])
        
        # è·å–è¾“å…¥è¾“å‡ºä¿¡æ¯
        self.input_name = self.session.get_inputs()[0].name
        self.output_name = self.session.get_outputs()[0].name
        
        print(f"ğŸ“Š è¾“å…¥èŠ‚ç‚¹: {self.input_name}")
        print(f"ğŸ“Š è¾“å‡ºèŠ‚ç‚¹: {self.output_name}")
    
    def infer(self, inputs):
        """
        æ‰§è¡Œæ¨ç†ï¼Œä¸Atlas InferSession.inferæ¥å£ä¸€è‡´
        
        å‚æ•°ï¼š
            inputs: è¾“å…¥å¼ é‡åˆ—è¡¨
        
        è¿”å›ï¼š
            outputs: è¾“å‡ºå¼ é‡åˆ—è¡¨
        """
        input_tensor = inputs[0]
        
        # æ‰§è¡Œæ¨ç†
        outputs = self.session.run([self.output_name], {self.input_name: input_tensor})
        
        return outputs

# ---------------------------------------------------------------------------------
# --- ğŸ“Š æ€§èƒ½åˆ†æ (ä¸Atlaså®Œå…¨ä¸€è‡´) ---
# ---------------------------------------------------------------------------------

def print_performance_analysis(times_dict, input_tensor, model_path, provider):
    """æ‰“å°è¯¦ç»†çš„æ€§èƒ½åˆ†ææŠ¥å‘Š"""
    total_time = sum(times_dict.values())
    
    print("\n" + "="*60)
    print("ğŸ§  ONNX Runtime å•å¼ å›¾ç‰‡æ¨ç†æ€§èƒ½åˆ†æ")
    print("="*60)
    print(f"ğŸ§  æ¨¡å‹: {Path(model_path).name}")
    print(f"âš¡ æ‰§è¡Œæä¾›è€…: {provider}")
    print(f"ğŸ“ è¾“å…¥å°ºå¯¸: {input_tensor.shape[3]}Ã—{input_tensor.shape[2]} (WÃ—H)")
    print(f"ğŸ¯ æ•°æ®ç±»å‹: {str(input_tensor.dtype).upper()}")
    print("-"*60)
    
    for stage, time_ms in times_dict.items():
        percentage = (time_ms / total_time) * 100
        print(f"â±ï¸  {stage:12}: {time_ms:6.1f}ms ({percentage:5.1f}%)")
    
    print("-"*60)
    print(f"ğŸ æ€»è€—æ—¶: {total_time:.1f}ms")
    print(f"âš¡ ç†è®ºFPS: {1000/total_time:.1f}")
    print("="*60)

# ---------------------------------------------------------------------------------
# --- ğŸ“± ä¸»æ¨ç†å‡½æ•° (ä¸Atlasæµç¨‹å®Œå…¨ä¸€è‡´) ---
# ---------------------------------------------------------------------------------

def inference_single_image(image_path, model_path, provider='CPUExecutionProvider', save_visualization=True, save_mask=False):
    """
    å¯¹å•å¼ å›¾ç‰‡è¿›è¡Œè½¦é“çº¿åˆ†å‰²æ¨ç†ï¼Œä¸atlas_single_image_inference.pyæµç¨‹å®Œå…¨ä¸€è‡´
    
    å‚æ•°ï¼š
        image_path: è¾“å…¥å›¾ç‰‡è·¯å¾„
        model_path: ONNXæ¨¡å‹è·¯å¾„
        provider: ONNXæ‰§è¡Œæä¾›è€…
        save_visualization: æ˜¯å¦ä¿å­˜å¯è§†åŒ–ç»“æœ
        save_mask: æ˜¯å¦ä¿å­˜åˆ†å‰²æ©ç 
    
    è¿”å›ï¼š
        dict: åŒ…å«ç»“æœè·¯å¾„å’Œæ€§èƒ½æ•°æ®
    """
    # éªŒè¯è¾“å…¥æ–‡ä»¶
    if not os.path.exists(image_path):
        raise FileNotFoundError(f"è¾“å…¥å›¾ç‰‡ä¸å­˜åœ¨: {image_path}")
    
    if not os.path.exists(model_path):
        raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
    
    print(f"ğŸ–¼ï¸  åŠ è½½å›¾ç‰‡: {image_path}")
    
    # 1. åŠ è½½å›¾ç‰‡
    load_start = time.time()
    img_bgr = cv2.imread(image_path)
    if img_bgr is None:
        raise ValueError(f"æ— æ³•è¯»å–å›¾ç‰‡: {image_path}")
    
    original_height, original_width = img_bgr.shape[:2]
    load_time = (time.time() - load_start) * 1000
    
    print(f"ğŸ“ åŸå§‹å°ºå¯¸: {original_width}Ã—{original_height}")
    
    # 2. åŠ è½½æ¨¡å‹
    print(f"ğŸ§  åŠ è½½ONNXæ¨¡å‹: {model_path}")
    model_start = time.time()
    model = ONNXInferSession(model_path, provider)
    model_load_time = (time.time() - model_start) * 1000
    print(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆ ({model_load_time:.1f}ms)")
    
    # 3. é¢„å¤„ç†
    print("ğŸ”„ å¼€å§‹é¢„å¤„ç†...")
    preprocess_start = time.time()
    input_data = preprocess_matched_resolution(img_bgr, dtype=np.float32)
    preprocess_time = (time.time() - preprocess_start) * 1000
    
    print(f"ğŸ“Š è¾“å…¥å¼ é‡å½¢çŠ¶: {input_data.shape}")
    print(f"ğŸ“Š æ•°æ®ç±»å‹: {input_data.dtype}")
    
    # 4. ONNXæ¨ç†
    print("ğŸš€ å¼€å§‹ONNXæ¨ç†...")
    inference_start = time.time()
    outputs = model.infer([input_data])
    inference_time = (time.time() - inference_start) * 1000
    
    print(f"ğŸ“Š è¾“å‡ºå¼ é‡å½¢çŠ¶: {outputs[0].shape}")
    
    # 5. åå¤„ç†
    print("ğŸ”„ å¼€å§‹åå¤„ç†...")
    postprocess_start = time.time()
    lane_mask = postprocess_matched_resolution(outputs[0], original_width, original_height)
    postprocess_time = (time.time() - postprocess_start) * 1000
    
    # 6. ä¿å­˜ç»“æœ
    save_start = time.time()
    results = {}
    
    if save_mask:
        mask_path = image_path.replace('.', '_onnx_mask.')
        cv2.imwrite(mask_path, lane_mask)
        results['mask_path'] = mask_path
        print(f"ğŸ’¾ åˆ†å‰²æ©ç å·²ä¿å­˜: {mask_path}")
    
    if save_visualization:
        vis_img = create_visualization(img_bgr, lane_mask)
        vis_path = image_path.replace('.', '_onnx_result.')
        cv2.imwrite(vis_path, vis_img)
        results['visualization_path'] = vis_path
        print(f"ğŸ’¾ å¯è§†åŒ–ç»“æœå·²ä¿å­˜: {vis_path}")
    
    save_time = (time.time() - save_start) * 1000
    
    # 7. æ€§èƒ½åˆ†æ
    times_dict = {
        "å›¾ç‰‡åŠ è½½": load_time,
        "æ¨¡å‹åŠ è½½": model_load_time,
        "CPUé¢„å¤„ç†": preprocess_time,
        "ONNXæ¨ç†": inference_time,
        "CPUåå¤„ç†": postprocess_time,
        "ç»“æœä¿å­˜": save_time
    }
    
    print_performance_analysis(times_dict, input_data, model_path, provider)
    
    # 8. ç»Ÿè®¡è½¦é“çº¿åƒç´ 
    lane_pixels = np.sum(lane_mask > 0)
    total_pixels = lane_mask.shape[0] * lane_mask.shape[1]
    lane_ratio = (lane_pixels / total_pixels) * 100
    
    print(f"\nğŸ“ˆ æ£€æµ‹ç»“æœç»Ÿè®¡:")
    print(f"ğŸ›£ï¸  è½¦é“çº¿åƒç´ : {lane_pixels:,} / {total_pixels:,} ({lane_ratio:.2f}%)")
    
    results.update({
        'lane_pixels': lane_pixels,
        'total_pixels': total_pixels,
        'lane_ratio': lane_ratio,
        'performance': times_dict,
        'provider': provider
    })
    
    return results

# ---------------------------------------------------------------------------------
# --- ğŸ“± å‘½ä»¤è¡Œæ¥å£ ---
# ---------------------------------------------------------------------------------

def main():
    parser = argparse.ArgumentParser(description="ONNX Runtimeå•å¼ å›¾ç‰‡è½¦é“çº¿åˆ†å‰²æ¨ç†")
    parser.add_argument("--input", "-i", required=True, help="è¾“å…¥å›¾ç‰‡è·¯å¾„")
    parser.add_argument("--output", "-o", help="è¾“å‡ºå¯è§†åŒ–å›¾ç‰‡è·¯å¾„ï¼ˆå¯é€‰ï¼‰")
    parser.add_argument("--save_mask", help="ä¿å­˜åˆ†å‰²æ©ç è·¯å¾„ï¼ˆå¯é€‰ï¼‰")
    parser.add_argument("--model", "-m", 
                       default="./weights/fast_scnn_custom_e2e_640x360_fixed_simplified.onnx",
                       help="ONNXæ¨¡å‹è·¯å¾„")
    parser.add_argument("--provider", "-p", 
                       default="CPUExecutionProvider",
                       choices=["CPUExecutionProvider", "CUDAExecutionProvider"],
                       help="ONNXæ‰§è¡Œæä¾›è€…")
    parser.add_argument("--no_vis", action="store_true", help="ä¸ä¿å­˜å¯è§†åŒ–ç»“æœï¼Œä»…æ¨ç†")
    
    args = parser.parse_args()
    
    try:
        print("ğŸ§  ONNX Runtime å•å¼ å›¾ç‰‡è½¦é“çº¿åˆ†å‰²æ¨ç†å·¥å…·")
        print("=" * 50)
        print("ğŸ“ ä¸Atlas NPUæ¨ç†æµç¨‹å®Œå…¨ä¸€è‡´ï¼Œç”¨äºæœ¬åœ°éªŒè¯å’Œå¯¹æ¯”")
        print("=" * 50)
        
        # æ£€æŸ¥å¯ç”¨çš„æ‰§è¡Œæä¾›è€…
        available_providers = ort.get_available_providers()
        print(f"ğŸ”§ å¯ç”¨æ‰§è¡Œæä¾›è€…: {available_providers}")
        
        # è‡ªåŠ¨ç¡®å®šè¾“å‡ºè·¯å¾„
        save_visualization = not args.no_vis
        save_mask = bool(args.save_mask)
        
        # éªŒè¯è¾“å…¥æ–‡ä»¶å­˜åœ¨
        if not os.path.exists(args.input):
            print(f"âŒ é”™è¯¯ï¼šè¾“å…¥å›¾ç‰‡ä¸å­˜åœ¨: {args.input}")
            sys.exit(1)
        
        # æ‰§è¡Œæ¨ç†
        results = inference_single_image(
            image_path=args.input,
            model_path=args.model,
            provider=args.provider,
            save_visualization=save_visualization,
            save_mask=save_mask
        )
        
        # å¤„ç†è¾“å‡ºè·¯å¾„é‡å‘½å
        if args.output and 'visualization_path' in results:
            import shutil
            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            output_dir = os.path.dirname(args.output)
            if output_dir and not os.path.exists(output_dir):
                os.makedirs(output_dir)
            
            # ç§»åŠ¨å¯è§†åŒ–ç»“æœåˆ°æŒ‡å®šè·¯å¾„
            shutil.move(results['visualization_path'], args.output)
            results['visualization_path'] = args.output
            print(f"ğŸ’¾ å¯è§†åŒ–ç»“æœå·²ç§»åŠ¨åˆ°æŒ‡å®šè·¯å¾„: {args.output}")
        
        # å¤„ç†æ©ç è·¯å¾„é‡å‘½å
        if args.save_mask and 'mask_path' in results:
            import shutil
            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            mask_dir = os.path.dirname(args.save_mask)
            if mask_dir and not os.path.exists(mask_dir):
                os.makedirs(mask_dir)
            
            # ç§»åŠ¨åˆ†å‰²æ©ç åˆ°æŒ‡å®šè·¯å¾„
            shutil.move(results['mask_path'], args.save_mask)
            results['mask_path'] = args.save_mask
            print(f"ğŸ’¾ åˆ†å‰²æ©ç å·²ç§»åŠ¨åˆ°æŒ‡å®šè·¯å¾„: {args.save_mask}")
        
        print("\nâœ… ONNXæ¨ç†å®Œæˆï¼")
        print("ğŸ”§ æ­¤ç»“æœå¯ä¸Atlas NPUæ¨ç†ç»“æœè¿›è¡Œå¯¹æ¯”éªŒè¯")
        
        if 'visualization_path' in results:
            print(f"ğŸ¨ å¯è§†åŒ–ç»“æœ: {results['visualization_path']}")
        if 'mask_path' in results:
            print(f"ğŸ­ åˆ†å‰²æ©ç : {results['mask_path']}")
            
    except Exception as e:
        print(f"âŒ æ¨ç†å¤±è´¥: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
