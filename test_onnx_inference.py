"""
TUSimple Lane Segmentation - ONNX Model Inference Test
ä½¿ç”¨å¯¼å‡ºçš„ONNXæ¨¡å‹åœ¨æµ‹è¯•é›†ä¸Šè¿›è¡Œæ¨ç†å¹¶éªŒè¯ç»“æœã€‚
"""
import os
os.environ['KMP_DUPLICATE_LIB_OK']='TRUE'
import random
import time
import numpy as np
import onnxruntime as ort
import torch
from torchvision import transforms
from PIL import Image
import matplotlib.pyplot as plt
import cv2

plt.rcParams['font.sans-serif'] = ['SimHei'] # è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['axes.unicode_minus'] = False # è§£å†³è´Ÿå·æ˜¾ç¤ºé—®é¢˜

class ONNXInferenceTester:
    def __init__(self, onnx_model_path):
        self.onnx_model_path = onnx_model_path
        self.device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
        
        # æ£€æŸ¥CUDAå¹¶è®¾ç½®ONNX Runtimeçš„æ‰§è¡Œæä¾›è€…
        if self.device.type == 'cuda' and ort.get_device() == 'GPU':
            self.providers = ['CUDAExecutionProvider', 'CPUExecutionProvider']
            print("ONNX Runtime å°†ä½¿ç”¨ CUDAExecutionProviderã€‚")
        else:
            self.providers = ['CPUExecutionProvider']
            print("ONNX Runtime å°†ä½¿ç”¨ CPUExecutionProviderã€‚")

        # åŠ è½½ONNXæ¨¡å‹
        print(f"æ­£åœ¨ä» {self.onnx_model_path} åŠ è½½ONNXæ¨¡å‹...")
        self.ort_session = ort.InferenceSession(self.onnx_model_path, providers=self.providers)
        self.input_name = self.ort_session.get_inputs()[0].name
        input_shape = self.ort_session.get_inputs()[0].shape
        print(f"æ¨¡å‹åŠ è½½å®Œæ¯•ã€‚è¾“å…¥åç§°: '{self.input_name}', è¾“å…¥å½¢çŠ¶: {input_shape}")

        # å›¾åƒå˜æ¢
        self.input_transform = transforms.Compose([
            transforms.Resize((640, 640), interpolation=transforms.InterpolationMode.BILINEAR), # è°ƒæ•´ä¸ºæ¨¡å‹è¾“å…¥å°ºå¯¸
            transforms.ToTensor(),
            transforms.Normalize([.485, .456, .406], [.229, .224, .225]),
        ])

        # æ•°æ®è·¯å¾„
        self.root = './manideep1108/tusimple/versions/5/TUSimple'
        self.test_clips_root = os.path.join(self.root, 'test_set', 'clips')
        self.seg_label_root = os.path.join(self.root, 'train_set', 'seg_label')

    def find_test_images(self, num_images=5):
        """ä»æµ‹è¯•é›†ä¸­æŸ¥æ‰¾éšæœºå›¾åƒ"""
        image_paths = []
        mask_paths = []
        
        if not os.path.exists(self.test_clips_root):
            print(f"é”™è¯¯: æµ‹è¯•é›†å›¾åƒç›®å½•æœªæ‰¾åˆ° {self.test_clips_root}")
            return [], []

        # æ”¶é›†æ‰€æœ‰æœ‰æ•ˆçš„å›¾åƒ/maskå¯¹
        for date_folder in os.listdir(self.test_clips_root):
            date_path = os.path.join(self.test_clips_root, date_folder)
            if os.path.isdir(date_path):
                for video_folder in os.listdir(date_path):
                    video_path = os.path.join(date_path, video_folder)
                    if os.path.isdir(video_path):
                        for i in range(1, 21): # æ£€æŸ¥ 1.jpg åˆ° 20.jpg
                            img_file = os.path.join(video_path, f'{i}.jpg')
                            if os.path.exists(img_file):
                                mask_file = os.path.join(self.seg_label_root, date_folder, video_folder, f'{i}.png')
                                if os.path.exists(mask_file):
                                    image_paths.append(img_file)
                                    mask_paths.append(mask_file)
        
        print(f"åœ¨æµ‹è¯•é›†ä¸­å…±æ‰¾åˆ° {len(image_paths)} å¼ å›¾åƒã€‚")
        
        # éšæœºé€‰æ‹© num_images å¼ 
        if len(image_paths) >= num_images:
            selected_pairs = random.sample(list(zip(image_paths, mask_paths)), num_images)
            image_paths, mask_paths = zip(*selected_pairs)
            return list(image_paths), list(mask_paths)
        else:
            print(f"è­¦å‘Š: å›¾åƒæ•°é‡ä¸è¶³ã€‚æ‰¾åˆ° {len(image_paths)} å¼ , éœ€è¦ {num_images} å¼ ã€‚")
            return image_paths, mask_paths

    def load_image(self, image_path):
        """åŠ è½½å¹¶é¢„å¤„ç†å›¾åƒ"""
        image = Image.open(image_path).convert('RGB')
        image_tensor = self.input_transform(image).unsqueeze(0)
        return image_tensor, image

    def load_mask(self, mask_path):
        """åŠ è½½å¹¶äºŒå€¼åŒ–mask"""
        mask = Image.open(mask_path).convert('L')
        mask_array = np.array(mask)
        mask_binary = (mask_array > 0).astype(np.uint8)
        return mask_binary

    def predict(self, image_tensor):
        """ä½¿ç”¨ONNXæ¨¡å‹è¿›è¡Œæ¨ç†"""
        image_np = image_tensor.numpy()
        
        start_time = time.time()
        ort_inputs = {self.input_name: image_np}
        ort_outs = self.ort_session.run(None, ort_inputs)
        inference_time = time.time() - start_time
        
        pred_logits = ort_outs[0]
        pred_mask = np.argmax(pred_logits, axis=1).squeeze().astype(np.uint8)
        
        return pred_mask, inference_time

    def create_comparison_plot(self, original_img, gt_mask, pred_mask, save_path, inference_time):
        """åˆ›å»ºå¯¹æ¯”å›¾"""
        fig, axes = plt.subplots(1, 3, figsize=(18, 6))
        fig.suptitle(f'ONNX æ¨¡å‹æ¨ç†\næ¨ç†æ—¶é—´: {inference_time*1000:.2f} ms', fontsize=16)
        
        axes[0].imshow(original_img)
        axes[0].set_title('åŸå§‹å›¾åƒ')
        axes[0].axis('off')
        
        axes[1].imshow(gt_mask, cmap='gray')
        axes[1].set_title('çœŸå®Mask')
        axes[1].axis('off')
        
        axes[2].imshow(pred_mask, cmap='gray')
        axes[2].set_title('ONNX é¢„æµ‹Mask')
        axes[2].axis('off')
        
        plt.tight_layout(rect=[0, 0.03, 1, 0.95])
        plt.savefig(save_path, dpi=150)
        plt.close()
        print(f"å¯¹æ¯”å›¾å·²ä¿å­˜è‡³ {save_path}")

    def run_test(self, num_images=5):
        """è¿è¡Œå®Œæ•´çš„æµ‹è¯•æµç¨‹"""
        print("\nğŸš€ å¼€å§‹ ONNX æ¨ç†æµ‹è¯•...")
        
        image_paths, mask_paths = self.find_test_images(num_images)
        
        if not image_paths:
            print("âŒ æœªæ‰¾åˆ°å¯ä¾›æµ‹è¯•çš„å›¾åƒï¼Œç¨‹åºé€€å‡ºã€‚")
            return
            
        output_dir = './onnx_inference_results'
        os.makedirs(output_dir, exist_ok=True)
        
        for i, (img_path, mask_path) in enumerate(zip(image_paths, mask_paths)):
            print(f"\n--- æ­£åœ¨å¤„ç†å›¾åƒ {i+1}/{num_images}: {img_path} ---")
            
            # åŠ è½½æ•°æ®
            image_tensor, original_img = self.load_image(img_path)
            gt_mask = self.load_mask(mask_path)
            
            # é¢„æµ‹
            pred_mask, inference_time = self.predict(image_tensor)
            
            # å¦‚æœéœ€è¦ï¼Œå°†é¢„æµ‹ç»“æœå°ºå¯¸è°ƒæ•´ä¸ºä¸çœŸå®maskä¸€è‡´
            if pred_mask.shape != gt_mask.shape:
                pred_mask = cv2.resize(pred_mask, (gt_mask.shape[1], gt_mask.shape[0]), interpolation=cv2.INTER_NEAREST)

            # å¯è§†åŒ–
            save_path = os.path.join(output_dir, f'onnx_test_{i+1}.png')
            self.create_comparison_plot(original_img, gt_mask, pred_mask, save_path, inference_time)

        print(f"\nâœ… {len(image_paths)} å¼ å›¾åƒçš„ ONNX æ¨ç†æµ‹è¯•å®Œæˆã€‚")
        print(f"ç»“æœä¿å­˜åœ¨: {output_dir}")

def main():
    # ç”¨æˆ·è¦æ±‚æµ‹è¯•æœªç®€åŒ–çš„æ¨¡å‹
    onnx_model_path = './weights/fast_scnn_tusimple_fixed.onnx'
    
    if not os.path.exists(onnx_model_path):
        print(f"âŒ é”™è¯¯: ONNX æ¨¡å‹æ–‡ä»¶æœªæ‰¾åˆ° '{onnx_model_path}'")
        print("è¯·å…ˆè¿è¡Œ `export_onnx.py` æ¥ç”Ÿæˆæ¨¡å‹ã€‚")
        return

    tester = ONNXInferenceTester(onnx_model_path)
    tester.run_test(num_images=5)

if __name__ == '__main__':
    main()
